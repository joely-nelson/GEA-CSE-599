03/13/2022 05:13:03 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False
03/13/2022 05:13:03 - INFO - transformers.configuration_utils -   loading configuration file /home/mexposit/cg/gea/dnabert/model/pretrained/6-new-12w-0/config.json
03/13/2022 05:13:03 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnageaall",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 1313,
  "num_return_sequences": 1,
  "num_rnn_layer": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 10,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

03/13/2022 05:13:03 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /home/mexposit/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e
03/13/2022 05:13:03 - INFO - transformers.modeling_utils -   loading weights file /home/mexposit/cg/gea/dnabert/model/pretrained/6-new-12w-0/pytorch_model.bin
03/13/2022 05:13:06 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
03/13/2022 05:13:06 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
03/13/2022 05:13:06 - INFO - __main__ -   finish loading model
03/13/2022 05:13:06 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/home/mexposit/cg/gea/transformers/7_gea500/in_data', device=device(type='cpu'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=0, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0002, local_rank=-1, logging_steps=20, max_grad_norm=1.0, max_seq_length=512, max_steps=-1, model_name_or_path='/home/mexposit/cg/gea/dnabert/model/pretrained/6-new-12w-0', model_type='dna', multiclass=True, n_gpu=0, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=5.0, output_dir='/home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=32, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=32, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_eval_probs=True, save_steps=20, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, task_name='dnageaall', tokenizer_name='dna6', visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)
03/13/2022 05:13:06 - INFO - __main__ -   Creating features from dataset file at /home/mexposit/cg/gea/transformers/7_gea500/in_data
03/13/2022 05:13:06 - INFO - transformers.data.processors.glue -   LOOKING AT /home/mexposit/cg/gea/transformers/7_gea500/in_data/train.tsv
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   Writing example 0/876
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-1
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 3460 1537 2038 4043 3870 3178 410 1627 2400 1393 1461 1733 2824 3091 62 234 921 3672 2385 1334 1226 796 3169 374 1481 1816 3156 321 1271 973 3880 3220 578 2297 981 3910 3340 1060 130 506 2012 3938 3451 1502 1900 3492 1666 2553 2005 3909 3333 1032 20 65 247 973 3880 3220 580 2307 1023 4077 4006 3723 2592 2163 447 1773 2981 3718 2570 2076 100 385 1528 2002 3897 3286 842 3354 1114 348 1378 1402 1500 1889 3446 1481 1813 3142 268 1060 130 507 2014 3948 3491 1662 2537 1944 3666 2362 1244 865 3445 1479 1808 3123 190 746 2971 3679 2413 1446 1675 2590 2154 411 1629 2405 1414 1548 2082 122 476 1890 3452 1506 1915 3550 1897 3477 1606 2314 1050 90 348 1377 1397 1480 1810 3130 217 853 3399 1294 1066 154 604 2401 1398 1482 1819 3167 365 1446 1674 2587 2142 362 1434 1626 2396 1378 1402 1498 1884 3426 1403 1502 1900 3491 1663 2541 1958 3724 2593 2166 460 1826 3193 470 1865 3351 1101 294 1162 540 2146 380 1506 1916 3553 1912 3538 1850 3289 854 3401 1304 1106 314 1244 866 3449 1495 1870 3371 1183 621 2469 1670 2570 2074 92 354 1404 1506 1915 3551 1901 3493 1672 2577 2101 198 780 3106 122 474 1883 3423 1389 1446 1675 2590 2154 411 1630 2410 1434 1625 2389 1349 1285 1030 11 29 101 390 1545 2071 79 302 1194 666 2650 2393 1365 1351 1294 1067 160 625 2486 1738 2843 3166 361 1430 1610 2329 1109 327 1293 1061 136 532 2116 258 1017 4054 3915 3357 1127 399 1582 2218 667 2653 2405 1413 1543 2062 42 156 609 2423 1486 1834 3227 605 2408 1427 1597 2279 912 3634 2236 738 2939 3550 1898 3484 1634 2425 1496 1874 3386 1243 863 3439 1456 1714 2747 2781 2918 3467 1566 2154 410 1628 2401 1397 1477 1797 3077 6 9 22 73 280 1106 314 1243 862 3434 1434 1627 2399 1390 1452 1698 2681 2519 1869 3366 1161 533 2119 271 1070 170 667 2656 2420 1476 1795 3069 4070 3980 3620 2179 509 2023 3982 3627 2206 618 2460 1633 2421 1477 1797 3077 8 18 59 221 870 3468 1571 2174 492 1954 3706 2522 1883 3421 1382 1417 1558 2124 289 1142 459 1822 3180 420 1668 2562 2041 4054 3915 3358 1130 412 1635 2429 1509 1925 3592 2067 61 231 909 3622 2185 533 2120 273 1079 207 813 3238 649 2581 2119 271 1072 177 693 2757 2824 3090 57 216 850 3388 1249 887 3533 1829 3208 530 2108 226 890 3548 1892 3459 1535 2029 4006 3724 2596 2177 501 1991 3853 3112 148 578 2297 984 3922 3386 1242 858 3419 1375 1389 1448 1682 2617 2264 850 3388 1251 893 3557 1925 3590 2057 21 69 262 1034 26 89 341 1352 1300 1092 258 1017 4053 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   Writing example 0/876
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 429 (id = 429)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-2
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 848 3378 1212 739 2942 3563 1952 3699 2494 1771 2976 3697 2486 1740 2851 3200 497 1974 3788 2850 3194 474 1883 3424 1395 1470 1770 2972 3684 2434 1532 2020 3970 3579 2016 3953 3509 1734 2828 3108 132 515 2045 4072 3988 3650 2297 984 3923 3391 1264 948 3777 2806 3019 3869 3173 392 1555 2112 242 953 3798 2892 3363 1149 488 1939 3647 2288 947 3775 2800 2995 3773 2790 2954 3612 2147 381 1510 1931 3613 2152 403 1599 2285 934 3724 2593 2166 460 1828 3201 502 1993 3863 3150 298 1178 603 2398 1387 1440 1652 2499 1789 3048 3988 3649 2296 979 3901 3301 904 3604 2114 252 993 3960 3537 1846 3276 801 3191 461 1832 3220 577 2296 977 3894 3275 799 3182 428 1699 2687 2543 1967 3760 2740 2755 2813 3047 3982 3626 2203 608 2419 1471 1775 2989 3749 2694 2569 2072 83 317 1256 915 3647 2285 936 3730 2619 2271 879 3502 1706 2715 2655 2415 1456 1715 2750 2794 2971 3677 2408 1426 1596 2273 887 3533 1829 3207 528 2098 187 736 2929 3512 1747 2877 3303 909 3624 2195 574 2284 931 3712 2547 1981 3813 2952 3604 2113 245 967 3856 3123 191 751 2992 3762 2747 2784 2930 3516 1764 2947 3583 2029 4008 3731 2623 2285 935 3728 2609 2230 713 2840 3155 319 1264 947 3776 2803 3006 3820 2979 3711 2542 1963 3744 2674 2491 1758 2922 3484 1635 2429 1512 1938 3642 2267 861 3430 1418 1563 2141 360 1428 1604 2307 1021 4071 3983 3632 2228 705 2807 3021 3880 3220 578 2299 992 3956 3522 1787 3038 3946 3484 1633 2423 1485 1829 3205 517 2053 8 17 53 199 783 3120 180 708 2819 3072 4083 4031 3823 2991 3758 2732 2723 2688 2547 1982 3820 2977 3703 2509 1832 3219 575 2288 948 3777 2805 3015 3853 3111 144 564 2243 768 3060 4035 3837 3046 3979 3613 2152 401 1592 2259 829 3304 915 3647 2288 945 3766 2762 2844 3170 379 1502 1900 3490 1658 2524 1890 3452 1507 1919 3567 1965 3752 2706 2619 2269 870 3465 1560 2131 319 1264 945 3765 2758 2825 3096 83 319 1262 939 3742 2667 2463 1645 2471 1679 2607 2221 677 2696 2579 2112 244 963 3839 3056 4020 3777 2808 3025 3893 3271 783 3118 172 675 2688 2546 1980 3811 2941 3557 1926 3595 2079 109 422 1675 2590 2154 412 1634 2426 1499 1885 3429 1414 1547 2077 102 396 1571 2176 497 1973 3781 2823 3088 49 182 715 2847 3182 427 1693 2662 2443 1567 2158 428 1698 2683 2526 1899 3486 1642 2460 1633 2422 1483 1824 3185 438 1739 2846 3178 410 1628 2403 1405 1509 1925 3589 2056 19 63 238 937 3736 2644 2371 1279 1006 4011 3743 2669 2469 1669 2565 2053 5 8 19 63 238 939 3743 2670 2475 1693 2663 2446 1577 2199 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 643 (id = 643)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-3
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 2915 3454 1516 1956 3715 2560 2034 4026 3802 2906 3418 1371 1375 1389 1446 1673 2584 2132 323 1278 1003 3999 3696 2483 1727 2799 2991 3759 2735 2734 2732 2721 2679 2512 1841 3256 723 2877 3302 907 3613 2151 397 1573 2181 517 2053 6 11 32 113 439 1744 2867 3262 747 2973 3685 2440 1554 2107 221 872 3473 1592 2260 834 3324 996 3971 3584 2033 4021 3781 2823 3087 47 176 689 2743 2765 2856 3220 577 2295 974 3881 3222 585 2325 1093 264 1041 54 201 791 3151 301 1192 660 2627 2304 1010 4026 3802 2907 3423 1391 1455 1711 2734 2732 2724 2689 2549 1992 3859 3134 235 927 3695 2478 1707 2720 2674 2492 1763 2944 3571 1982 3819 2974 3691 2463 1646 2476 1698 2682 2523 1887 3440 1457 1719 2767 2863 3246 684 2723 2687 2544 1971 3774 2794 2969 3671 2383 1328 1204 705 2806 3017 3863 3151 302 1196 674 2683 2527 1904 3507 1727 2798 2986 3738 2651 2398 1387 1439 1647 2478 1706 2715 2656 2420 1476 1793 3061 4040 3859 3136 242 956 3812 2947 3584 2035 4030 3818 2970 3675 2398 1387 1437 1638 2441 1560 2131 318 1259 925 3687 2448 1587 2238 748 2978 3705 2520 1876 3394 1273 982 3915 3358 1131 413 1640 2450 1594 2267 864 3444 1474 1788 3042 3961 3544 1876 3394 1275 992 3954 3514 1755 2912 3443 1470 1771 2975 3693 2469 1672 2579 2110 236 932 3716 2563 2046 4076 4002 3708 2530 1916 3555 1917 3559 1936 3633 2229 711 2831 3119 175 687 2735 2736 2738 2746 2779 2909 3432 1427 1599 2287 944 3761 2743 2767 2864 3251 702 2796 2979 3712 2547 1983 3822 2986 3737 2646 2379 1311 1136 436 1730 2809 3029 3911 3342 1065 150 587 2336 1138 443 1758 2922 3484 1633 2424 1490 1851 3295 877 3493 1671 2575 2095 176 692 2754 2809 3029 3912 3345 1079 205 807 3216 561 2231 718 2858 3225 598 2379 1312 1139 447 1773 2983 3726 2604 2212 643 2557 2024 3987 3645 2280 915 3647 2285 935 3726 2604 2212 642 2553 2005 3911 3341 1064 148 577 2294 970 3865 3160 339 1341 1256 913 3640 2259 832 3313 952 3796 2882 3321 982 3916 3362 1145 472 1876 3395 1280 1012 4034 3836 3043 3966 3561 1943 3661 2344 1169 568 2258 826 3291 862 3434 1436 1633 2421 1480 1810 3132 228 898 3580 2020 3971 3583 2030 4009 3733 2631 2318 1065 151 592 2356 1219 766 3049 3991 3661 2343 1166 553 2200 593 2357 1224 788 3137 247 973 3880 3218 569 2262 842 3354 1116 356 1410 1529 2006 3915 3358 1132 419 1664 2547 1982 3819 2974 3692 2467 1662 2540 1953 3701 2504 1811 3135 237 936 3730 2618 2265 855 3407 1326 1194 667 2656 2420 1473 1781 3013 3845 3077 8 17 56 210 826 3292 868 3458 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 347 (id = 347)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-877
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 707 2813 3048 3987 3645 2277 903 3600 2099 191 749 2983 3727 2606 2217 663 2639 2349 1191 656 2612 2241 760 3027 3902 3305 917 3653 2312 1044 67 256 1009 4021 3783 2829 3111 141 551 2190 554 2203 607 2413 1448 1684 2625 2293 965 3848 3089 54 204 803 3199 493 1958 3724 2593 2167 461 1832 3219 574 2283 925 3685 2437 1541 2055 13 39 142 556 2212 641 2549 1990 3850 3098 91 349 1381 1415 1550 2090 154 604 2402 1401 1494 1865 3352 1108 321 1269 966 3850 3099 94 362 1433 1622 2380 1316 1154 508 2019 3968 3571 1983 3823 2992 3763 2750 2796 2977 3701 2504 1809 3127 205 806 3211 541 2149 389 1543 2061 39 141 549 2183 527 2093 168 660 2626 2298 986 3931 3421 1384 1427 1597 2279 909 3624 2195 575 2285 936 3730 2619 2271 879 3501 1703 2701 2600 2196 577 2296 979 3903 3311 941 3752 2707 2621 2280 913 3637 2245 773 3080 17 54 202 793 3159 336 1329 1208 721 2871 3279 814 3241 663 2639 2349 1192 659 2623 2285 934 3722 2586 2139 349 1384 1425 1589 2246 778 3099 95 365 1447 1677 2597 2184 529 2101 197 774 3082 25 87 336 1329 1206 716 2849 3192 466 1851 3295 878 3498 1691 2654 2410 1435 1632 2417 1464 1748 2881 3319 975 3885 3240 660 2626 2299 991 3949 3495 1679 2605 2214 651 2592 2163 447 1775 2990 3755 2719 2671 2480 1715 2751 2797 2984 3731 2624 2289 952 3794 2873 3287 845 3367 1167 557 2214 652 2595 2173 487 1935 3630 2220 676 2692 2562 2043 4062 3947 3485 1637 2440 1554 2107 223 877 3495 1679 2608 2228 707 2813 3045 3975 3598 2089 151 592 2354 1210 732 2913 3447 1486 1834 3227 606 2409 1431 1614 2347 1181 616 2451 1598 2284 931 3711 2543 1968 3762 2747 2783 2927 3502 1705 2711 2637 2344 1170 572 2273 885 3527 1806 3116 161 629 2503 1806 3113 150 588 2337 1141 453 1799 3088 49 184 723 2879 3309 935 3726 2601 2199 591 2351 1200 692 2755 2815 3054 4011 3743 2671 2479 1711 2736 2737 2743 2766 2859 3231 622 2476 1700 2692 2562 2044 4066 3964 3553 1912 3537 1847 3279 815 3245 680 2707 2622 2282 922 3675 2398 1386 1436 1634 2425 1495 1869 3365 1157 520 2066 58 220 868 3459 1533 2022 3978 3609 2134 329 1301 1096 273 1077 197 776 3091 61 230 906 3612 2147 382 1514 1945 3670 2379 1309 1125 390 1546 2074 92 354 1402 1500 1891 3453 1509 1927 3600 2097 181 711 2829 3112 148 578 2299 989 3943 3470 1577 2198 587 2333 1128 402 1595 2269 869 3461 1541 2054 9 21 69 261 1030 11 29 102 394 1561 2134 330 1306 1116 355 1407 1517 1958 3723 2591 2157 424 1683 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 650 (id = 650)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-4
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 395 1565 2150 396 1569 2165 455 1805 3109 134 521 2069 69 261 1031 14 44 162 635 2526 1900 3491 1662 2538 1945 3671 2381 1318 1161 533 2117 263 1037 40 146 569 2261 838 3337 1047 77 293 1160 532 2116 260 1026 4092 4066 3962 3545 1878 3404 1313 1144 467 1855 3309 934 3721 2582 2122 283 1117 357 1415 1552 2100 196 769 3061 4037 3847 3088 50 187 736 2929 3512 1748 2883 3327 1008 4019 3776 2801 2998 3786 2841 3157 325 1286 1034 27 95 365 1445 1671 2573 2086 140 548 2177 502 1996 3875 3198 492 1953 3702 2506 1818 3161 342 1353 1302 1100 292 1156 514 2041 4054 3913 3349 1093 262 1036 36 132 515 2046 4075 4000 3699 2496 1777 2998 3785 2837 3142 268 1058 123 480 1908 3524 1795 3069 4069 3974 3595 2077 104 404 1602 2300 995 3968 3569 1975 3789 2853 3206 523 2078 105 406 1611 2336 1139 446 1770 2972 3682 2425 1494 1868 3364 1156 513 2037 4040 3859 3135 239 944 3761 2742 2764 2851 3200 499 1983 3821 2984 3729 2616 2258 826 3292 866 3450 1498 1883 3422 1388 1441 1653 2501 1799 3085 38 140 548 2179 509 2021 3973 3592 2068 66 249 984 3923 3392 1266 954 3804 2915 3455 1517 1957 3718 2572 2081 118 460 1826 3194 473 1879 3405 1320 1169 566 2252 801 3192 465 1846 3276 804 3202 507 2013 3944 3473 1591 2254 809 3221 581 2311 1038 44 164 643 2558 2028 4001 3703 2512 1844 3265 757 3014 3850 3098 89 342 1356 1315 1151 494 1963 3742 2666 2459 1631 2416 1457 1719 2767 2861 3238 651 2589 2149 392 1555 2109 230 906 3610 2138 345 1366 1355 1311 1136 434 1721 2775 2894 3371 1183 622 2476 1697 2678 2508 1825 3190 460 1827 3197 486 1932 3620 2178 506 2009 3927 3406 1323 1181 615 2447 1581 2215 654 2604 2211 640 2545 1974 3787 2847 3183 431 1712 2740 2753 2805 3013 3845 3077 7 13 40 147 573 2278 906 3611 2143 365 1448 1684 2626 2297 982 3914 3353 1112 337 1333 1224 785 3125 198 777 3094 75 287 1134 428 1697 2678 2506 1819 3165 360 1428 1602 2300 993 3957 3525 1797 3078 9 22 74 284 1122 378 1500 1889 3446 1484 1827 3200 499 1982 3820 2980 3715 2557 2024 3986 3644 2274 890 3547 1887 3438 1452 1699 2688 2547 1983 3824 2996 3778 2810 3036 3939 3453 1510 1930 3611 2144 369 1462 1738 2843 3167 366 1452 1698 2682 2522 1884 3426 1401 1493 1862 3338 1052 98 379 1503 1902 3498 1690 2650 2393 1365 1351 1293 1064 147 576 2289 950 3787 2848 3187 448 1778 3001 3798 2890 3354 1115 352 1394 1467 1758 2923 3488 1651 2494 1771 2973 3688 2452 1603 2304 1011 4029 3813 2950 3595 2077 103 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 198 (id = 198)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-5
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 3240 658 2618 2268 866 3452 1507 1917 3557 1928 3601 2103 208 818 3258 730 2905 3413 1350 1291 1054 106 410 1627 2398 1386 1434 1628 2403 1405 1511 1933 3623 2190 555 2206 620 2467 1661 2533 1925 3590 2058 27 93 360 1426 1596 2275 896 3570 1980 3810 2938 3546 1882 3420 1379 1405 1512 1940 3649 2293 966 3852 3107 125 487 1934 3628 2209 631 2511 1837 3239 655 2608 2227 701 2792 2961 3640 2257 822 3273 790 3145 278 1100 291 1149 486 1929 3606 2124 291 1151 494 1961 3734 2633 2325 1096 273 1077 199 783 3118 169 661 2629 2312 1044 66 250 988 3938 3452 1506 1916 3556 1923 3584 2033 4024 3793 2871 3277 805 3207 526 2090 154 603 2399 1391 1454 1706 2714 2652 2403 1405 1512 1939 3648 2290 956 3810 2940 3555 1919 3566 1964 3746 2682 2524 1891 3454 1514 1945 3672 2385 1333 1223 782 3116 163 637 2533 1928 3604 2116 257 1013 4037 3845 3078 10 25 85 327 1295 1069 165 646 2569 2070 73 280 1105 311 1229 807 3214 554 2202 601 2389 1350 1290 1049 86 332 1315 1150 492 1955 3709 2534 1929 3606 2124 291 1149 487 1935 3630 2217 663 2637 2344 1170 569 2264 849 3381 1224 785 3125 200 785 3125 197 775 3087 45 165 646 2572 2081 117 456 1809 3126 201 790 3146 282 1114 345 1365 1349 1285 1032 18 60 226 890 3545 1877 3398 1290 1051 96 370 1466 1756 2914 3450 1497 1879 3407 1326 1196 674 2684 2530 1915 3549 1895 3469 1573 2184 531 2111 240 946 3770 2780 2914 3452 1506 1916 3553 1909 3525 1798 3081 24 81 309 1221 773 3077 7 14 41 149 581 2312 1043 61 231 909 3622 2185 534 2122 284 1124 388 1537 2037 4037 3848 3092 67 253 999 3984 3635 2238 746 2971 3677 2407 1421 1573 2181 517 2055 14 41 149 581 2310 1033 21 71 271 1069 168 658 2620 2276 897 3573 1992 3860 3140 258 1019 4064 3954 3514 1756 2915 3454 1514 1945 3671 2381 1319 1166 556 2211 638 2540 1956 3713 2551 1997 3877 3207 525 2086 140 547 2173 486 1932 3620 2177 501 1992 3857 3127 206 810 3228 610 2426 1497 1879 3407 1327 1198 681 2709 2629 2309 1032 19 62 233 918 3659 2336 1140 449 1782 3019 3871 3184 434 1723 2784 2929 3512 1748 2881 3317 966 3850 3099 93 359 1422 1579 2207 622 2475 1693 2664 2452 1602 2300 995 3965 3560 1940 3651 2302 1004 4003 3711 2542 1961 3734 2635 2333 1128 401 1589 2248 788 3138 252 996 3970 3580 2020 3971 3582 2028 4004 3714 2556 2018 3964 3556 1923 3583 2029 4005 3718 2572 2083 127 495 1966 3756 2724 2691 2558 2027 3997 3687 2445 1573 2181 518 2057 23 79 301 1191 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 332 (id = 332)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   Writing example 0/876
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-1753
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 2635 2334 1131 413 1640 2451 1600 2289 950 3787 2846 3180 418 1659 2526 1897 3478 1610 2330 1115 352 1394 1466 1755 2909 3430 1419 1567 2157 422 1673 2584 2130 314 1244 867 3455 1518 1964 3745 2679 2510 1835 3231 623 2479 1712 2738 2747 2784 2930 3516 1762 2937 3544 1873 3382 1225 789 3143 270 1065 151 592 2353 1206 713 2839 3152 308 1220 769 3064 4052 3908 3331 1022 4074 3993 3671 2383 1325 1190 651 2590 2156 420 1667 2559 2031 4015 3757 2728 2706 2620 2275 894 3564 1955 3709 2533 1926 3596 2081 118 457 1815 3151 304 1203 704 2801 3000 3793 2871 3279 815 3245 679 2704 2611 2238 747 2973 3687 2447 1584 2228 707 2814 3051 3999 3693 2472 1681 2614 2250 794 3161 342 1355 1309 1128 403 1597 2277 902 3593 2069 69 263 1039 45 168 659 2623 2285 936 3731 2623 2288 948 3777 2805 3016 3860 3140 259 1023 4080 4017 3768 2771 2880 3315 957 3816 2961 3637 2248 786 3132 228 898 3579 2015 3950 3500 1699 2685 2533 1927 3598 2090 154 601 2390 1355 1311 1136 435 1727 2798 2987 3743 2669 2470 1675 2591 2157 424 1682 2619 2270 873 3478 1610 2329 1109 326 1290 1052 98 378 1500 1891 3455 1520 1972 3780 2817 3061 4040 3859 3134 233 920 3665 2360 1234 825 3285 840 3346 1081 216 852 3394 1276 993 3960 3539 1856 3315 958 3819 2973 3687 2447 1584 2227 704 2803 3006 3819 2976 3699 2495 1773 2984 3732 2627 2302 1003 4000 3699 2496 1780 3011 3839 3056 4019 3776 2804 3011 3839 3056 4019 3773 2789 2949 3591 2061 40 147 573 2280 914 3642 2266 857 3414 1353 1301 1094 268 1059 125 486 1930 3610 2138 346 1370 1372 1379 1407 1519 1966 3755 2720 2674 2490 1753 2902 3403 1310 1129 408 1617 2360 1235 831 3311 941 3749 2693 2565 2053 5 5 7 16 52 196 770 3065 4054 3916 3364 1153 504 2001 3893 3269 775 3085 40 146 569 2264 849 3384 1233 824 3282 826 3292 867 3456 1521 1974 3785 2837 3141 261 1029 8 19 64 242 955 3805 2920 3476 1602 2297 984 3923 3389 1254 907 3615 2160 435 1726 2793 2965 3654 2315 1054 106 409 1622 2380 1316 1153 502 1993 3861 3141 261 1029 6 12 35 126 489 1942 3660 2340 1155 509 2022 3977 3608 2131 317 1253 901 3592 2066 60 226 892 3553 1911 3536 1843 3263 752 2994 3772 2787 2941 3557 1925 3590 2057 21 70 267 1053 101 390 1548 2082 124 484 1921 3575 1998 3882 3226 602 2395 1374 1388 1443 1663 2544 1970 3772 2785 2934 3530 1817 3158 329 1304 1105 311 1229 807 3214 554 2202 602 2396 1378 1402 1497 1879 3408 1331 1216 754 3002 3802 2906 3418 1372 1378 1403 1501 1894 3468 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 62 (id = 62)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   Writing example 0/876
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-878
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 2799 2992 3761 2741 2757 2823 3088 49 182 715 2847 3184 433 1719 2765 2856 3219 576 2291 960 3827 3007 3823 2989 3752 2707 2621 2279 909 3624 2196 578 2300 995 3968 3571 1981 3816 2964 3651 2301 997 3973 3590 2058 28 99 381 1511 1935 3629 2213 647 2576 2099 189 742 2953 3607 2125 296 1171 576 2291 959 3821 2984 3731 2621 2280 913 3637 2246 780 3107 127 493 1958 3721 2584 2130 316 1252 900 3587 2048 4084 4034 3836 3041 3959 3536 1842 3259 736 2930 3514 1755 2912 3441 1464 1746 2876 3297 885 3527 1807 3117 168 657 2614 2251 800 3187 448 1779 3005 3816 2964 3649 2296 980 3907 3327 1007 4016 3764 2755 2813 3048 3987 3645 2279 911 3632 2228 707 2813 3046 3977 3605 2118 267 1053 104 404 1603 2303 1008 4017 3766 2764 2851 3199 496 1969 3767 2765 2856 3219 576 2290 955 3808 2929 3512 1747 2880 3315 960 3825 2999 3789 2856 3218 572 2275 894 3563 1949 3688 2449 1589 2246 778 3097 87 336 1329 1206 715 2845 3176 404 1604 2308 1026 4089 4054 3916 3362 1146 476 1892 3460 1538 2042 4058 3931 3421 1383 1424 1586 2235 734 2924 3492 1667 2559 2030 4011 3743 2672 2484 1729 2807 3023 3885 3240 659 2623 2286 939 3743 2672 2483 1726 2796 2980 3714 2555 2015 3952 3505 1718 2762 2844 3169 373 1479 1808 3123 192 755 3008 3828 3009 3830 3018 3867 3166 362 1434 1625 2390 1355 1309 1127 398 1580 2209 630 2505 1813 3144 274 1082 220 868 3458 1532 2020 3969 3575 1997 3878 3209 534 2122 281 1110 332 1314 1146 474 1881 3414 1355 1309 1128 402 1596 2273 886 3529 1813 3141 264 1042 60 226 891 3549 1893 3464 1555 2109 230 908 3617 2167 461 1829 3205 520 2066 58 220 867 3453 1512 1939 3647 2288 945 3765 2758 2825 3095 77 296 1170 572 2273 886 3531 1823 3184 434 1724 2787 2943 3568 1971 3775 2799 2990 3756 2724 2689 2551 1999 3886 3244 674 2682 2524 1889 3445 1479 1808 3121 184 724 2882 3323 992 3956 3523 1792 3058 4025 3800 2897 3383 1232 820 3266 763 3038 3948 3489 1655 2512 1841 3255 717 2855 3216 563 2237 741 2949 3591 2062 44 164 643 2560 2036 4033 3829 3015 3856 3124 194 762 3036 3940 3460 1540 2052 4098 4090 4059 3933 3432 1427 1597 2280 915 3647 2288 948 3779 2816 3059 4030 3818 2970 3673 2391 1358 1324 1188 643 2557 2023 3982 3626 2203 605 2408 1428 1601 2293 967 3853 3109 136 531 2112 244 964 3843 3072 4083 4030 3820 2979 3710 2539 1952 3697 2487 1744 2867 3261 743 2958 3628 2212 643 2559 2032 4017 3765 2760 2835 3135 237 934 3724 2595 2174 492 1956 3715 2560 2036 4033 3832 3025 3893 3270 779 3101 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 865 (id = 865)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-2629
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 146 569 2262 844 3362 1145 469 1861 3334 1036 34 124 484 1921 3576 2003 3902 3308 930 3708 2529 1911 3534 1834 3228 611 2429 1512 1937 3640 2260 834 3322 985 3927 3407 1326 1195 669 2661 2439 1550 2092 161 631 2510 1835 3232 625 2487 1744 2867 3264 754 3003 3806 2924 3491 1661 2536 1937 3637 2248 787 3134 234 923 3678 2409 1432 1617 2358 1225 789 3144 274 1081 213 838 3340 1057 118 459 1821 3174 393 1557 2118 267 1053 104 403 1599 2285 934 3721 2582 2123 285 1127 397 1574 2187 542 2156 418 1657 2520 1873 3384 1236 834 3322 986 3930 3417 1367 1358 1322 1180 611 2430 1514 1946 3673 2389 1349 1285 1029 5 7 15 46 171 671 2671 2477 1703 2701 2599 2191 558 2219 671 2671 2479 1711 2734 2732 2721 2677 2503 1807 3118 172 673 2677 2501 1799 3085 38 137 533 2117 261 1030 12 33 117 454 1804 3107 125 485 1926 3594 2076 98 378 1500 1890 3450 1500 1890 3450 1497 1877 3399 1294 1066 156 610 2426 1498 1881 3414 1354 1308 1123 381 1512 1939 3646 2282 921 3670 2377 1301 1094 268 1060 130 506 2009 3927 3405 1317 1157 518 2057 21 69 264 1043 61 229 902 3593 2072 83 317 1254 907 3613 2151 397 1573 2181 518 2058 26 91 349 1383 1421 1573 2181 518 2057 21 69 264 1043 61 230 906 3610 2138 346 1370 1370 1371 1373 1383 1422 1580 2211 637 2534 1930 3611 2142 361 1432 1618 2362 1244 866 3452 1508 1922 3578 2010 3932 3426 1403 1503 1901 3493 1669 2567 2062 43 157 614 2443 1565 2149 390 1548 2082 121 470 1867 3358 1130 409 1622 2379 1309 1126 396 1570 2171 478 1900 3492 1665 2550 1995 3870 3180 419 1663 2544 1972 3778 2811 3038 3947 3487 1647 2478 1705 2710 2633 2328 1106 316 1249 888 3538 1851 3296 882 3513 1750 2890 3353 1109 326 1290 1050 91 352 1393 1462 1737 2837 3144 275 1087 237 936 3732 2626 2298 985 3925 3399 1295 1070 172 675 2685 2534 1930 3609 2133 326 1292 1057 117 454 1803 3104 116 451 1791 3053 4005 3719 2576 2099 192 755 3008 3828 3012 3844 3073 4088 4049 3896 3284 835 3328 1012 4034 3834 3034 3932 3427 1408 1522 1977 3798 2890 3356 1124 388 1539 2048 4083 4030 3819 2974 3690 2459 1631 2416 1459 1726 2794 2971 3679 2414 1451 1696 2675 2494 1771 2973 3687 2446 1580 2209 631 2510 1835 3232 627 2494 1772 2979 3712 2547 1982 3819 2976 3700 2498 1787 3040 3954 3514 1755 2912 3444 1475 1790 3052 4003 3712 2548 1987 3840 3057 4024 3795 2880 3316 962 3833 3030 3915 3357 1128 403 1598 2283 925 3687 2446 1579 2205 613 2437 1544 2068 67 256 1012 4034 3833 3029 3910 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 421 (id = 421)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-1754
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 2996 3780 2817 3062 4043 3869 3175 398 1579 2206 619 2464 1652 2499 1789 3046 3980 3620 2177 503 2000 3889 3256 723 2878 3308 930 3705 2519 1869 3365 1160 532 2116 258 1020 4068 3971 3581 2024 3987 3648 2292 962 3836 3044 3971 3581 2022 3980 3620 2178 508 2017 3960 3539 1853 3301 904 3604 2116 259 1024 4081 4024 3796 2881 3320 979 3902 3308 930 3706 2523 1885 3431 1423 1584 2228 708 2820 3074 4092 4068 3970 3580 2019 3967 3567 1965 3750 2699 2591 2158 428 1700 2690 2555 2016 3953 3512 1747 2878 3308 932 3713 2551 2000 3892 3267 768 3057 4023 3792 2866 3257 725 2885 3335 1040 52 195 767 3053 4007 3725 2597 2184 530 2106 219 861 3432 1427 1600 2290 956 3810 2939 3551 1904 3508 1731 2816 3057 4024 3796 2884 3331 1024 4081 4024 3796 2884 3331 1024 4081 4022 3788 2851 3199 493 1959 3727 2606 2217 663 2640 2356 1219 765 3045 3976 3603 2110 236 929 3703 2511 1839 3246 684 2721 2677 2504 1811 3134 236 929 3702 2507 1822 3180 419 1661 2535 1935 3629 2215 655 2608 2228 707 2813 3045 3976 3603 2110 236 931 3711 2543 1968 3762 2748 2787 2943 3567 1966 3756 2724 2691 2559 2031 4013 3751 2703 2607 2222 683 2720 2674 2492 1761 2935 3535 1837 3239 655 2607 2222 684 2724 2692 2563 2046 4073 3991 3664 2356 1219 767 3054 4012 3745 2678 2508 1826 3196 483 1918 3562 1947 3680 2419 1471 1775 2992 3763 2750 2793 2967 3663 2351 1199 688 2737 2743 2767 2861 3239 653 2598 2188 545 2165 456 1811 3133 232 915 3645 2279 912 3633 2231 718 2858 3227 606 2410 1435 1629 2405 1416 1554 2107 223 880 3507 1727 2797 2982 3724 2595 2175 495 1968 3761 2741 2760 2836 3139 254 1001 3991 3664 2354 1211 735 2925 3496 1684 2625 2296 979 3904 3315 957 3815 2959 3629 2214 651 2590 2154 411 1630 2410 1435 1629 2405 1416 1556 2113 247 976 3889 3255 720 2868 3267 765 3045 3975 3598 2089 151 589 2341 1160 529 2103 207 815 3248 691 2752 2803 3007 3824 2993 3768 2772 2882 3324 993 3957 3528 1810 3130 219 864 3441 1464 1748 2884 3331 1024 4081 4023 3789 2855 3215 559 2222 684 2724 2690 2556 2017 3957 3527 1807 3120 179 701 2790 2955 3616 2161 440 1747 2878 3308 929 3701 2504 1812 3140 259 1021 4070 3979 3616 2161 439 1742 2858 3227 605 2405 1416 1556 2113 248 980 3905 3319 976 3892 3267 765 3045 3975 3597 2086 139 543 2158 428 1700 2692 2564 2051 4093 4071 3981 3621 2184 531 2110 236 932 3713 2552 2002 3897 3287 845 3365 1159 526 2089 151 589 2341 1159 525 2088 147 575 2285 935 3725 2597 2183 528 2098 187 734 2921 3478 1609 2326 1099 285 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 210 (id = 210)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-879
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 424 1683 2622 2284 929 3702 2505 1814 3147 287 1135 431 1710 2729 2710 2633 2328 1106 316 1249 888 3538 1851 3296 882 3513 1750 2890 3353 1111 333 1318 1164 548 2178 507 2013 3942 3465 1560 2131 318 1260 930 3706 2522 1883 3423 1390 1452 1700 2691 2557 2024 3987 3646 2283 926 3692 2468 1667 2559 2031 4016 3762 2748 2786 2939 3550 1899 3485 1637 2437 1541 2054 11 30 107 414 1644 2465 1654 2508 1826 3194 473 1879 3405 1318 1162 540 2147 381 1511 1933 3621 2184 529 2102 201 789 3141 261 1029 6 9 22 73 278 1099 285 1126 395 1565 2150 396 1569 2165 455 1805 3109 134 521 2069 69 261 1031 14 44 162 635 2526 1900 3491 1662 2538 1945 3671 2381 1318 1161 533 2117 263 1037 40 146 569 2261 838 3337 1047 77 293 1160 532 2116 260 1026 4092 4066 3962 3545 1878 3404 1313 1144 467 1855 3309 934 3721 2582 2122 283 1117 357 1415 1552 2100 196 769 3061 4037 3847 3088 50 187 736 2929 3512 1748 2883 3327 1008 4019 3776 2801 2998 3786 2841 3157 325 1286 1034 27 95 365 1445 1671 2573 2086 140 548 2177 502 1996 3875 3198 492 1953 3702 2506 1818 3161 342 1353 1302 1100 292 1156 514 2041 4054 3913 3349 1093 262 1036 36 132 515 2046 4075 4000 3699 2496 1777 2998 3785 2837 3142 268 1058 123 480 1908 3524 1795 3069 4069 3974 3595 2077 104 404 1602 2300 995 3968 3569 1975 3789 2853 3206 523 2078 105 406 1611 2336 1139 446 1770 2972 3682 2425 1494 1868 3364 1156 513 2037 4040 3859 3135 239 944 3761 2742 2764 2851 3200 499 1983 3821 2984 3729 2616 2258 826 3292 866 3450 1498 1883 3422 1388 1441 1653 2501 1799 3085 38 140 548 2179 509 2021 3973 3592 2068 66 249 984 3923 3392 1266 954 3804 2915 3455 1517 1957 3718 2572 2081 118 460 1826 3194 473 1879 3405 1320 1169 566 2252 801 3192 465 1846 3276 804 3202 507 2013 3944 3473 1591 2254 809 3221 581 2311 1038 44 164 643 2558 2028 4001 3703 2512 1844 3265 757 3014 3850 3098 89 342 1356 1315 1151 494 1963 3742 2666 2459 1631 2416 1457 1719 2767 2861 3238 651 2589 2149 392 1555 2109 230 906 3610 2138 345 1366 1355 1311 1136 434 1721 2775 2894 3371 1183 622 2476 1697 2678 2508 1825 3190 460 1827 3197 486 1932 3620 2178 506 2009 3927 3406 1323 1181 615 2447 1581 2215 654 2604 2211 640 2545 1974 3787 2847 3183 431 1712 2740 2753 2805 3013 3845 3077 7 13 40 147 573 2278 906 3611 2143 365 1448 1684 2626 2297 982 3914 3353 1112 337 1333 1224 785 3125 198 777 3094 75 287 1134 428 1697 2678 2506 1819 3165 360 1428 1602 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 548 (id = 548)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   Writing example 0/876
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-1755
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 4082 4027 3808 2929 3512 1747 2880 3315 960 3828 3011 3840 3057 4024 3795 2878 3307 928 3699 2496 1779 3006 3819 2976 3700 2499 1789 3047 3984 3635 2238 747 2975 3695 2480 1716 2755 2815 3056 4019 3775 2800 2994 3771 2784 2932 3521 1783 3021 3878 3211 541 2152 403 1600 2292 964 3841 3061 4039 3853 3112 146 570 2267 864 3444 1474 1785 3031 3920 3379 1213 743 2959 3631 2223 687 2736 2738 2748 2788 2947 3584 2033 4021 3783 2830 3115 159 622 2476 1699 2687 2541 1959 3726 2603 2208 626 2490 1755 2912 3443 1472 1780 3012 3841 3064 4051 3903 3310 939 3743 2672 2484 1731 2813 3048 3987 3648 2291 960 3828 3011 3840 3059 4032 3827 3005 3815 2959 3630 2218 667 2654 2411 1439 1646 2475 1696 2674 2491 1760 2931 3519 1775 2992 3763 2751 2800 2995 3775 2800 2995 3776 2801 3000 3795 2879 3311 944 3764 2753 2807 3021 3880 3219 573 2280 916 3652 2306 1019 4064 3955 3520 1778 3001 3799 2894 3372 1186 635 2528 1908 3524 1795 3072 4081 4023 3792 2868 3267 767 3054 4011 3743 2672 2483 1727 2797 2983 3727 2606 2219 671 2672 2484 1732 2819 3070 4076 4004 3714 2556 2017 3960 3539 1853 3303 909 3622 2187 544 2162 443 1759 2926 3499 1695 2669 2469 1671 2576 2100 194 764 3043 3966 3563 1951 3696 2484 1732 2817 3061 4038 3852 3107 128 500 1987 3838 3051 3997 3688 2451 1597 2279 911 3629 2216 660 2626 2297 983 3920 3380 1219 768 3060 4035 3838 3051 4000 3698 2491 1759 2928 3506 1724 2787 2943 3567 1966 3756 2724 2692 2563 2048 4083 4031 3824 2995 3775 2799 2990 3755 2720 2676 2497 1783 3021 3880 3219 576 2292 963 3838 3052 4003 3712 2548 1987 3840 3058 4028 3811 2944 3569 1973 3781 2823 3087 47 176 689 2744 2772 2882 3323 992 3953 3510 1739 2847 3183 432 1716 2755 2813 3045 3976 3601 2104 211 832 3315 960 3827 3005 3816 2964 3649 2295 976 3890 3259 735 2928 3507 1727 2799 2990 3756 2723 2687 2544 1972 3780 2819 3069 4072 3985 3639 2256 820 3266 763 3040 3956 3523 1792 3060 4035 3839 3056 4019 3775 2799 2992 3764 2756 2818 3068 4067 3968 3572 1988 3843 3072 4081 4021 3784 2835 3133 232 913 3639 2255 813 3239 655 2607 2224 692 2754 2812 3043 3968 3569 1974 3787 2847 3184 433 1718 2763 2845 3175 399 1581 2215 653 2598 2188 548 2178 508 2020 3969 3573 1991 3854 3116 163 639 2543 1967 3758 2731 2720 2674 2492 1764 2945 3575 2000 3892 3267 768 3057 4024 3794 2875 3295 880 3507 1727 2799 2989 3751 2704 2612 2242 764 3042 3963 3551 1903 3503 1712 2740 2756 2819 3069 4072 3988 3649 2296 979 3903 3312 948 3779 2814 3051 3997 3688 2451 1597 2280 913 3638 2251 800 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 618 (id = 618)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-2630
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 1637 2440 1555 2109 229 904 3604 2114 250 986 3930 3419 1373 1384 1426 1593 2262 841 3349 1094 268 1058 122 473 1879 3405 1318 1164 547 2176 498 1977 3799 2893 3367 1168 563 2240 754 3003 3806 2924 3490 1657 2519 1869 3368 1169 565 2245 773 3077 5 5 5 8 17 53 197 773 3077 6 10 26 92 353 1397 1477 1798 3081 22 73 277 1093 262 1033 21 71 272 1074 186 731 2910 3434 1433 1621 2374 1289 1047 78 297 1173 583 2317 1062 137 533 2119 270 1065 150 585 2325 1093 261 1029 5 5 6 9 21 69 262 1033 24 84 324 1281 1015 4047 3886 3241 664 2641 2359 1230 810 3227 605 2408 1428 1602 2298 988 3938 3451 1502 1897 3477 1607 2318 1067 159 622 2474 1691 2655 2414 1450 1690 2650 2395 1376 1396 1474 1786 3033 3928 3409 1336 1235 832 3316 961 3830 3020 3874 3196 484 1924 3588 2052 4100 4097 4088 4052 3908 3331 1024 4082 4028 3809 2933 3526 1804 3106 121 469 1864 3347 1088 242 956 3809 2935 3533 1830 3209 533 2119 270 1065 149 582 2314 1049 87 333 1318 1164 545 2166 457 1814 3147 288 1137 439 1741 2853 3205 520 2068 65 245 965 3845 3080 20 68 260 1028 4097 4087 4048 3892 3265 758 3019 3870 3179 415 1648 2481 1720 2772 2883 3327 1006 4011 3744 2676 2497 1783 3023 3887 3248 690 2747 2784 2932 3524 1795 3071 4080 4019 3775 2800 2994 3771 2784 2932 3521 1783 3024 3889 3253 712 2835 3134 235 925 3687 2445 1575 2191 558 2218 667 2655 2414 1451 1694 2666 2459 1630 2410 1435 1630 2410 1436 1636 2436 1540 2050 4091 4061 3944 3475 1599 2287 942 3756 2723 2686 2540 1954 3707 2526 1899 3487 1645 2471 1679 2608 2225 696 2771 2878 3308 929 3704 2513 1848 3281 824 3284 834 3323 992 3953 3510 1738 2843 3166 362 1436 1634 2426 1498 1883 3421 1382 1417 1560 2129 312 1235 831 3311 943 3760 2738 2745 2773 2886 3338 1052 97 375 1486 1836 3233 630 2508 1825 3189 454 1803 3101 104 402 1596 2274 892 3556 1923 3584 2034 4027 3807 2925 3496 1684 2625 2295 975 3886 3243 671 2670 2474 1690 2652 2402 1401 1496 1873 3384 1236 834 3324 994 3961 3543 1871 3376 1203 702 2794 2970 3675 2398 1388 1442 1659 2526 1897 3478 1612 2340 1154 508 2020 3970 3580 2018 3963 3552 1905 3509 1736 2834 3129 215 846 3370 1180 609 2421 1480 1812 3139 254 1004 4003 3709 2536 1940 3651 2304 1011 4032 3827 3007 3823 2989 3749 2696 2578 2106 220 868 3458 1531 2013 3944 3473 1592 2258 825 3285 837 3335 1037 37 136 530 2108 228 897 3574 1993 3861 3142 268 1058 122 474 1882 3419 1374 1388 1443 1663 2542 1964 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 555 (id = 555)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-3505
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 3859 3134 235 927 3695 2478 1707 2720 2674 2492 1763 2944 3571 1982 3819 2974 3691 2463 1646 2476 1698 2682 2523 1887 3440 1457 1719 2767 2863 3246 684 2723 2687 2544 1971 3774 2794 2969 3671 2383 1328 1204 705 2806 3017 3863 3151 302 1196 674 2683 2527 1904 3507 1727 2798 2986 3738 2651 2398 1387 1439 1647 2478 1706 2715 2656 2420 1476 1793 3061 4040 3859 3136 242 956 3812 2947 3584 2035 4030 3818 2970 3675 2398 1387 1437 1638 2441 1560 2131 318 1259 925 3687 2448 1587 2238 748 2978 3705 2520 1876 3394 1273 982 3915 3358 1131 413 1640 2450 1594 2267 864 3444 1474 1788 3042 3961 3544 1876 3394 1275 992 3954 3514 1755 2912 3443 1470 1771 2975 3693 2469 1672 2579 2110 236 932 3716 2563 2046 4076 4002 3708 2530 1916 3555 1917 3559 1936 3633 2229 711 2831 3119 175 687 2735 2736 2738 2746 2779 2909 3432 1427 1599 2287 944 3761 2743 2767 2864 3251 702 2796 2979 3712 2547 1983 3822 2986 3737 2646 2379 1311 1136 436 1730 2809 3029 3911 3342 1065 150 587 2336 1138 443 1758 2922 3484 1633 2424 1490 1851 3295 877 3493 1671 2575 2095 176 692 2754 2809 3029 3912 3345 1079 205 807 3216 561 2231 718 2858 3225 598 2379 1312 1139 447 1773 2983 3726 2604 2212 643 2557 2024 3987 3645 2280 915 3647 2285 935 3726 2604 2212 642 2553 2005 3911 3341 1064 148 577 2294 970 3865 3160 339 1341 1256 913 3640 2259 832 3313 952 3796 2882 3321 982 3916 3362 1145 472 1876 3395 1280 1012 4034 3836 3043 3966 3561 1943 3661 2344 1169 568 2258 826 3291 862 3434 1436 1633 2421 1480 1810 3132 228 898 3580 2020 3971 3583 2030 4009 3733 2631 2318 1065 151 592 2356 1219 766 3049 3991 3661 2343 1166 553 2200 593 2357 1224 788 3137 247 973 3880 3218 569 2262 842 3354 1116 356 1410 1529 2006 3915 3358 1132 419 1664 2547 1982 3819 2974 3692 2467 1662 2540 1953 3701 2504 1811 3135 237 936 3730 2618 2265 855 3407 1326 1194 667 2656 2420 1473 1781 3013 3845 3077 8 17 56 210 826 3292 868 3458 1529 2008 3923 3390 1259 926 3690 2460 1633 2422 1483 1823 3184 436 1731 2813 3045 3973 3591 2061 37 133 519 2063 45 167 655 2608 2227 702 2796 2980 3714 2553 2008 3923 3392 1268 962 3836 3044 3970 3578 2010 3930 3418 1370 1370 1372 1378 1402 1498 1884 3427 1405 1509 1928 3603 2109 232 915 3645 2280 913 3638 2250 793 3159 336 1331 1216 755 3005 3816 2961 3637 2245 773 3077 5 5 8 20 65 246 971 3870 3179 413 1637 2440 1553 2101 200 785 3126 203 799 3182 426 1690 2652 2401 1398 1483 1822 3178 410 1626 2395 1374 1385 1431 1616 2356 1220 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 238 (id = 238)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-880
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 1204 705 2806 3017 3861 3144 276 1091 256 1011 4029 3816 2963 3648 2292 962 3835 3040 3956 3524 1795 3070 4076 4001 3701 2503 1808 3124 196 772 3076 4100 4098 4090 4059 3936 3442 1468 1763 2941 3559 1933 3623 2189 552 2195 575 2287 941 3752 2707 2622 2282 924 3684 2433 1528 2003 3904 3313 949 3783 2832 3121 183 719 2862 3241 663 2637 2343 1167 560 2225 693 2759 2830 3116 161 632 2513 1846 3273 791 3151 302 1193 663 2637 2344 1171 576 2290 956 3809 2936 3539 1854 3305 918 3660 2337 1144 465 1845 3269 776 3091 64 243 959 3821 2983 3728 2611 2238 746 2971 3679 2415 1456 1713 2741 2760 2836 3140 257 1016 4049 3893 3269 776 3092 67 256 1012 4033 3831 3021 3880 3220 578 2297 982 3915 3359 1136 436 1730 2809 3029 3912 3347 1088 244 963 3837 3048 3988 3652 2306 1019 4064 3956 3521 1781 3015 3853 3112 148 577 2296 977 3896 3283 832 3315 957 3815 2960 3633 2232 724 2884 3329 1016 4051 3902 3306 923 3679 2413 1448 1684 2628 2308 1028 4097 4085 4037 3847 3088 51 191 750 2988 3748 2690 2553 2006 3915 3358 1130 410 1625 2390 1353 1304 1106 315 1247 878 3500 1698 2683 2528 1908 3524 1794 3066 4058 3931 3424 1395 1471 1773 2983 3727 2606 2219 670 2668 2465 1655 2510 1834 3228 609 2424 1491 1856 3314 955 3808 2929 3510 1738 2842 3162 346 1372 1378 1404 1505 1910 3532 1827 3198 491 1952 3698 2491 1757 2920 3476 1604 2308 1028 4100 4099 4096 4084 4033 3832 3027 3903 3310 937 3734 2636 2340 1153 501 1989 3845 3077 7 16 51 191 749 2984 3731 2621 2277 903 3600 2099 192 756 3011 3839 3054 4010 3738 2650 2394 1369 1367 1360 1332 1218 762 3035 3935 3438 1452 1700 2691 2559 2030 4010 3738 2650 2396 1379 1406 1516 1956 3715 2559 2030 4010 3738 2650 2396 1379 1406 1515 1949 3687 2445 1574 2188 546 2170 475 1886 3434 1434 1627 2399 1390 1452 1699 2688 2546 1978 3801 2902 3403 1311 1135 431 1710 2732 2721 2678 2506 1819 3166 364 1442 1660 2532 1921 3574 1993 3861 3143 271 1072 178 697 2774 2890 3353 1111 335 1328 1203 703 2798 2986 3738 2652 2401 1400 1490 1852 3297 888 3539 1854 3308 929 3702 2505 1815 3151 304 1203 702 2795 2976 3699 2495 1776 2995 3773 2792 2963 3647 2288 945 3765 2759 2832 3121 183 719 2864 3249 696 2771 2880 3315 957 3816 2963 3648 2289 952 3794 2875 3293 872 3474 1596 2273 888 3539 1856 3313 952 3796 2881 3317 968 3859 3136 244 961 3829 3016 3857 3128 211 832 3315 959 3823 2989 3749 2694 2569 2071 80 307 1213 741 2949 3591 2063 48 179 703 2798 2987 3742 2667 2463 1647 2479 1712 2739 2752 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 181 (id = 181)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   Writing example 0/876
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-2631
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 3455 1517 1960 3731 2622 2284 931 3711 2544 1971 3773 2792 2963 3645 2280 915 3645 2280 915 3645 2280 914 3644 2275 895 3567 1965 3752 2707 2621 2279 911 3629 2215 656 2609 2232 722 2874 3291 862 3436 1443 1661 2535 1933 3621 2184 532 2114 251 991 3951 3503 1711 2733 2728 2706 2617 2261 837 3333 1030 12 33 118 457 1814 3145 279 1101 294 1162 540 2145 375 1485 1831 3215 557 2216 658 2620 2273 885 3528 1809 3126 204 803 3200 500 1987 3839 3056 4018 3771 2784 2931 3518 1769 2968 3665 2360 1233 824 3281 824 3283 830 3308 931 3712 2547 1982 3820 2980 3715 2560 2033 4023 3792 2867 3262 748 2978 3705 2520 1874 3387 1246 874 3483 1629 2408 1425 1592 2257 822 3276 804 3204 516 2049 4086 4044 3875 3198 492 1954 3706 2524 1889 3446 1482 1820 3170 377 1496 1875 3391 1264 946 3770 2780 2915 3454 1515 1950 3690 2458 1627 2397 1381 1414 1548 2081 120 468 1860 3330 1020 4068 3969 3574 1994 3867 3166 362 1435 1630 2410 1436 1633 2424 1489 1847 3277 805 3205 520 2068 67 254 1002 3996 3684 2435 1535 2029 4006 3724 2596 2178 506 2010 3929 3416 1362 1338 1243 863 3438 1451 1693 2663 2447 1582 2218 668 2658 2427 1504 1906 3513 1750 2890 3353 1110 329 1303 1102 297 1174 588 2339 1151 496 1969 3766 2761 2838 3145 279 1102 297 1174 588 2339 1151 496 1969 3766 2764 2849 3190 458 1817 3157 326 1290 1052 98 379 1501 1893 3463 1549 2087 144 562 2236 739 2942 3564 1953 3702 2507 1821 3176 401 1590 2251 799 3184 433 1717 2757 2821 3078 12 36 129 502 1993 3862 3145 279 1101 293 1160 531 2110 235 927 3695 2480 1716 2756 2817 3064 4051 3902 3306 922 3674 2394 1372 1379 1405 1509 1925 3589 2056 19 63 238 937 3736 2644 2371 1279 1006 4011 3743 2669 2469 1669 2565 2053 5 8 19 63 238 939 3743 2670 2475 1693 2663 2446 1577 2199 590 2346 1179 606 2412 1444 1665 2549 1990 3849 3096 83 318 1259 925 3688 2449 1592 2260 835 3325 1000 3985 3640 2260 835 3328 1012 4035 3839 3054 4011 3744 2676 2499 1791 3054 4011 3742 2668 2467 1661 2534 1929 3605 2117 262 1033 21 69 261 1029 5 5 5 6 10 25 88 338 1339 1245 872 3475 1599 2285 934 3724 2596 2180 516 2051 4096 4084 4033 3832 3025 3893 3270 780 3108 132 515 2048 4084 4033 3829 3015 3854 3116 164 644 2563 2048 4084 4033 3832 3026 3898 3289 856 3412 1348 1284 1027 4096 4084 4036 3841 3062 4044 3876 3204 515 2048 4084 4033 3832 3026 3898 3289 856 3412 1348 1284 1027 4096 4084 4036 3841 3063 4046 3881 3222 588 2340 1154 506 2012 3939 3454 1516 1953 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-4381
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 1084 227 896 3569 1974 3787 2848 3187 446 1771 2976 3697 2488 1745 2871 3280 819 3264 754 3002 3803 2911 3438 1452 1697 2679 2511 1837 3238 650 2587 2141 358 1419 1567 2158 427 1694 2666 2458 1627 2398 1386 1434 1626 2394 1371 1375 1390 1452 1699 2685 2536 1940 3651 2302 1002 3996 3682 2428 1508 1921 3573 1992 3857 3125 197 774 3084 36 132 513 2039 4047 3887 3246 684 2723 2686 2540 1955 3710 2540 1955 3710 2540 1956 3713 2552 2001 3895 3280 820 3267 767 3053 4007 3726 2604 2211 638 2539 1951 3695 2478 1708 2721 2680 2514 1852 3298 891 3551 1903 3504 1714 2747 2783 2927 3502 1708 2724 2692 2564 2051 4094 4075 3999 3694 2476 1699 2686 2538 1947 3679 2415 1455 1709 2726 2699 2591 2159 432 1716 2753 2808 3026 3898 3291 862 3435 1439 1646 2476 1699 2686 2539 1951 3695 2479 1709 2727 2703 2606 2219 671 2670 2476 1698 2683 2528 1906 3515 1759 2926 3500 1699 2687 2542 1964 3748 2691 2559 2030 4011 3743 2669 2472 1683 2623 2287 944 3761 2744 2770 2875 3296 882 3515 1757 2918 3467 1567 2159 431 1712 2740 2753 2808 3026 3899 3295 879 3502 1705 2710 2633 2327 1101 296 1169 568 2260 834 3323 991 3950 3500 1699 2687 2541 1958 3724 2596 2177 501 1991 3855 3118 170 667 2655 2415 1455 1710 2731 2719 2671 2479 1712 2738 2748 2787 2944 3571 1982 3819 2974 3692 2468 1668 2564 2049 4087 4046 3884 3233 632 2515 1855 3311 941 3750 2700 2593 2167 461 1831 3215 557 2213 645 2567 2063 46 172 675 2687 2543 1967 3758 2730 2716 2660 2435 1534 2028 4003 3710 2539 1950 3691 2464 1652 2497 1783 3022 3883 3231 623 2478 1705 2711 2639 2351 1199 685 2725 2695 2575 2095 175 685 2728 2708 2628 2305 1015 4046 3884 3235 637 2536 1940 3650 2298 988 3938 3452 1507 1919 3567 1966 3756 2722 2684 2532 1923 3582 2028 4003 3711 2542 1964 3747 2685 2535 1935 3631 2223 685 2728 2708 2625 2293 965 3848 3092 65 248 980 3908 3332 1028 4099 4094 4075 3997 3688 2452 1603 2303 1005 4006 3723 2591 2157 424 1683 2623 2285 935 3727 2605 2215 655 2606 2217 663 2637 2344 1171 575 2287 941 3752 2706 2620 2276 900 3588 2050 4091 4064 3953 3512 1748 2881 3317 966 3850 3099 93 359 1422 1579 2207 622 2475 1693 2664 2452 1602 2300 995 3965 3560 1940 3651 2302 1004 4003 3711 2542 1961 3734 2635 2333 1128 401 1589 2248 788 3138 252 996 3970 3580 2020 3971 3582 2028 4004 3714 2556 2018 3964 3556 1923 3583 2029 4005 3718 2572 2083 127 495 1966 3756 2724 2691 2558 2027 3997 3687 2445 1573 2181 518 2057 23 79 301 1191 654 2604 2209 632 2513 1846 3275 798 3178 410 1626 2394 1371 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 946 (id = 946)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-881
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-3506
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 502 1996 3874 3195 479 1904 3505 1720 2772 2881 3320 978 3898 3291 863 3438 1452 1700 2692 2563 2046 4076 4002 3706 2524 1891 3454 1515 1950 3691 2462 1644 2465 1656 2513 1848 3284 836 3331 1022 4075 3999 3695 2478 1707 2717 2663 2447 1581 2213 647 2573 2086 139 541 2149 392 1554 2107 222 873 3480 1620 2369 1269 966 3851 3103 111 431 1712 2740 2753 2808 3027 3901 3303 910 3628 2209 629 2504 1809 3125 197 775 3087 46 170 668 2658 2428 1506 1913 3544 1876 3394 1275 991 3950 3498 1691 2653 2407 1422 1579 2206 618 2460 1636 2433 1528 2004 3906 3321 981 3909 3335 1038 44 162 635 2527 1903 3504 1716 2753 2806 3019 3871 3182 427 1695 2672 2483 1725 2790 2955 3616 2163 447 1774 2988 3748 2689 2552 2004 3908 3332 1025 4088 4052 3907 3326 1003 3997 3686 2442 1564 2145 373 1480 1810 3129 216 852 3396 1284 1028 4100 4099 4094 4075 4000 3699 2495 1773 2982 3723 2589 2149 390 1547 2077 102 394 1562 2139 350 1385 1430 1611 2333 1127 399 1581 2214 652 2593 2166 459 1823 3183 432 1713 2744 2772 2884 3329 1015 4047 3885 3240 657 2614 2252 802 3195 479 1901 3495 1679 2606 2219 670 2668 2466 1659 2527 1903 3501 1702 2697 2581 2120 276 1090 249 984 3923 3391 1262 937 3736 2641 2357 1221 774 3083 29 103 399 1582 2219 669 2664 2452 1604 2308 1027 4095 4077 4006 3723 2591 2157 424 1682 2617 2264 852 3396 1281 1016 4050 3900 3299 895 3565 1957 3719 2575 2093 165 646 2572 2081 118 458 1818 3163 351 1390 1451 1694 2666 2459 1632 2420 1475 1789 3047 3983 3630 2219 670 2666 2458 1628 2404 1409 1525 1989 3847 3086 42 156 609 2424 1491 1853 3303 909 3624 2193 565 2245 775 3087 45 165 645 2565 2054 11 29 104 401 1591 2253 805 3207 526 2090 154 601 2390 1355 1311 1136 436 1731 2815 3053 4006 3723 2592 2163 446 1770 2972 3682 2427 1501 1896 3476 1601 2296 980 3905 3318 972 3876 3201 504 2002 3899 3293 871 3470 1578 2202 602 2394 1369 1366 1356 1314 1147 479 1903 3502 1708 2722 2684 2529 1909 3526 1803 3101 103 398 1579 2207 622 2474 1692 2660 2434 1530 2009 3926 3404 1313 1141 456 1812 3138 249 984 3924 3393 1272 977 3896 3281 824 3283 830 3307 926 3691 2461 1640 2449 1589 2247 782 3116 161 631 2509 1832 3220 579 2301 1000 3985 3639 2253 808 3218 569 2264 851 3390 1257 918 3659 2334 1132 418 1658 2523 1886 3434 1435 1629 2406 1418 1563 2141 358 1418 1563 2142 364 1442 1658 2524 1890 3452 1505 1912 3538 1851 3293 871 3469 1573 2182 524 2082 123 478 1900 3490 1659 2525 1893 3464 1556 2115 253 999 3983 3629 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 77 (id = 77)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-1756
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 3307 928 3700 2497 1782 3019 3871 3184 435 1727 2797 2983 3727 2605 2214 652 2596 2177 504 2003 3902 3306 921 3671 2383 1327 1197 680 2707 2623 2286 940 3747 2685 2536 1937 3637 2248 785 3127 207 814 3243 669 2662 2443 1567 2157 424 1681 2615 2255 815 3245 680 2707 2621 2280 913 3639 2255 815 3247 686 2732 2723 2687 2542 1963 3741 2664 2449 1589 2247 782 3114 156 612 2436 1540 2049 4087 4047 3887 3246 684 2721 2677 2504 1809 3127 207 815 3247 688 2740 2753 2808 3025 3896 3284 833 3320 980 3907 3326 1004 4003 3712 2548 1985 3830 3020 3876 3203 510 2027 3997 3688 2449 1591 2253 807 3214 556 2210 636 2532 1922 3579 2015 3950 3499 1693 2664 2450 1595 2270 875 3486 1642 2458 1627 2399 1391 1454 1708 2723 2688 2547 1983 3823 2991 3758 2732 2721 2680 2515 1855 3310 940 3746 2684 2529 1909 3526 1803 3103 110 428 1697 2677 2503 1807 3120 180 705 2806 3020 3875 3199 493 1960 3730 2620 2274 890 3546 1883 3423 1390 1451 1694 2667 2463 1645 2471 1677 2600 2196 580 2307 1021 4072 3987 3646 2283 927 3695 2478 1708 2721 2677 2504 1811 3133 231 910 3627 2207 621 2471 1679 2605 2215 654 2603 2206 619 2461 1639 2447 1581 2213 647 2575 2096 180 707 2813 3048 3987 3648 2289 952 3796 2884 3329 1013 4039 3856 3121 184 724 2882 3324 994 3963 3549 1896 3475 1598 2283 926 3692 2467 1663 2544 1972 3779 2815 3053 4007 3727 2607 2222 681 2712 2641 2359 1230 811 3231 623 2478 1708 2722 2683 2527 1901 3494 1675 2591 2157 423 1679 2605 2216 659 2622 2283 928 3699 2493 1768 2963 3645 2279 909 3624 2196 580 2308 1028 4097 4088 4051 3902 3308 932 3713 2551 1999 3885 3240 659 2622 2284 929 3701 2504 1812 3137 248 979 3901 3302 906 3610 2140 355 1408 1524 1985 3829 3013 3848 3092 66 252 993 3959 3533 1829 3207 527 2094 171 672 2674 2491 1757 2917 3463 1549 2085 136 531 2111 237 936 3729 2615 2256 817 3256 723 2880 3315 960 3828 3011 3838 3050 3995 3677 2407 1423 1583 2223 687 2735 2734 2731 2717 2662 2443 1566 2156 420 1668 2563 2047 4078 4011 3743 2672 2483 1727 2798 2986 3738 2652 2404 1409 1528 2001 3896 3281 822 3274 796 3169 376 1489 1847 3279 816 3250 698 2779 2912 3443 1470 1770 2971 3679 2414 1452 1699 2686 2540 1956 3713 2552 2002 3900 3300 900 3588 2050 4092 4067 3967 3568 1969 3767 2767 2863 3247 687 2733 2727 2701 2598 2187 543 2158 428 1700 2691 2557 2021 3973 3589 2056 17 56 211 832 3313 952 3793 2872 3281 824 3283 832 3315 959 3823 2990 3756 2722 2683 2528 1907 3518 1772 2980 3715 2559 2029 4008 3731 2621 2279 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 217 (id = 217)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 377 (id = 377)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-4382
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 3824 2996 3779 2815 3055 4015 3759 2734 2731 2720 2675 2493 1767 2957 3624 2193 567 2254 810 3228 610 2428 1508 1924 3585 2040 4049 3893 3272 787 3134 235 928 3700 2499 1790 3049 3991 3662 2347 1183 623 2479 1710 2732 2723 2687 2543 1967 3760 2740 2754 2810 3033 3925 3398 1290 1050 92 355 1405 1510 1929 3606 2121 277 1094 265 1046 74 282 1115 351 1390 1449 1688 2642 2361 1237 839 3342 1065 150 585 2328 1105 312 1236 835 3326 1002 3993 3669 2374 1292 1058 124 483 1920 3569 1974 3785 2837 3141 261 1032 17 55 205 808 3217 566 2249 789 3142 267 1054 108 418 1658 2523 1886 3434 1434 1626 2394 1369 1365 1350 1289 1047 78 297 1176 595 2366 1257 919 3661 2342 1162 538 2138 345 1367 1357 1318 1164 545 2166 457 1816 3156 323 1278 1002 3996 3684 2433 1526 1994 3866 3163 350 1385 1430 1609 2325 1096 273 1080 209 822 3273 791 3149 293 1157 518 2057 23 78 297 1173 581 2310 1034 25 86 330 1305 1110 330 1306 1114 345 1365 1349 1285 1029 5 7 13 40 147 573 2279 909 3621 2181 517 2056 20 65 245 965 3847 3086 43 157 615 2447 1583 2222 681 2709 2631 2318 1068 162 633 2517 1861 3336 1042 57 213 838 3338 1052 98 380 1506 1916 3554 1914 3546 1882 3420 1377 1400 1489 1847 3278 809 3222 585 2325 1093 262 1033 22 75 287 1135 430 1706 2716 2660 2433 1528 2001 3893 3269 773 3080 19 63 238 938 3740 2658 2426 1498 1884 3425 1399 1488 1844 3267 768 3059 4030 3817 2968 3668 2369 1270 971 3869 3174 395 1565 2149 391 1550 2092 163 637 2533 1927 3598 2090 153 600 2386 1338 1242 858 3420 1378 1404 1507 1917 3557 1926 3593 2071 77 293 1160 530 2105 214 842 3355 1118 364 1444 1666 2555 2013 3943 3469 1576 2193 565 2246 777 3095 77 293 1159 526 2092 163 637 2533 1927 3598 2090 153 600 2386 1338 1242 858 3420 1378 1404 1507 1917 3557 1926 3593 2071 77 293 1160 529 2102 204 801 3190 459 1823 3182 425 1688 2643 2368 1267 959 3824 2994 3771 2782 2922 3482 1626 2394 1370 1372 1377 1397 1478 1802 3099 96 369 1462 1737 2838 3147 285 1125 392 1555 2110 234 923 3678 2411 1440 1649 2488 1748 2883 3326 1001 3992 3666 2363 1246 875 3488 1650 2492 1761 2934 3531 1824 3185 438 1737 2837 3141 261 1030 10 26 90 348 1377 1397 1478 1802 3098 90 346 1372 1378 1401 1493 1862 3338 1050 92 354 1402 1498 1882 3418 1372 1378 1401 1493 1862 3338 1051 94 362 1434 1625 2392 1362 1338 1242 860 3426 1401 1494 1868 3362 1147 478 1900 3490 1658 2524 1891 3454 1513 1942 3658 2329 1110 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 79 (id = 79)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   Writing example 0/876
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-3507
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 4051 3901 3304 915 3645 2280 916 3649 2293 968 3859 3133 231 910 3625 2198 588 2340 1156 515 2048 4083 4029 3816 2963 3648 2290 955 3805 2917 3462 1548 2081 119 464 1843 3262 748 2977 3703 2512 1844 3266 761 3031 3917 3368 1172 579 2303 1005 4008 3729 2615 2253 805 3206 522 2073 86 330 1308 1122 379 1502 1900 3492 1666 2553 2006 3913 3352 1106 316 1251 893 3560 1939 3645 2280 915 3645 2280 913 3637 2247 781 3109 134 522 2074 92 355 1406 1516 1953 3704 2516 1860 3331 1022 4073 3990 3658 2332 1121 376 1492 1859 3328 1011 4029 3813 2951 3597 2088 147 573 2278 907 3614 2156 418 1658 2524 1891 3453 1509 1927 3598 2091 157 615 2445 1576 2194 571 2270 876 3492 1668 2564 2051 4093 4070 3979 3613 2149 392 1555 2109 232 915 3646 2283 927 3693 2472 1684 2627 2301 997 3976 3601 2101 198 779 3103 110 428 1700 2691 2558 2028 4002 3708 2532 1921 3573 1989 3848 3089 54 201 791 3151 302 1193 661 2629 2312 1044 65 246 971 3869 3173 391 1549 2088 147 574 2283 927 3694 2476 1700 2692 2564 2049 4086 4042 3866 3164 356 1412 1540 2050 4090 4060 3939 3454 1515 1950 3692 2468 1665 2549 1989 3845 3079 14 43 157 614 2442 1562 2140 355 1405 1511 1935 3629 2215 654 2604 2211 638 2540 1954 3708 2531 1919 3566 1962 3740 2660 2433 1525 1990 3852 3107 126 489 1944 3666 2362 1244 868 3457 1528 2002 3897 3285 838 3337 1045 69 262 1035 30 107 414 1644 2468 1665 2549 1991 3853 3112 145 566 2250 794 3164 356 1409 1525 1990 3851 3101 103 397 1575 2192 561 2231 719 2862 3244 676 2689 2550 1996 3876 3201 504 2002 3900 3300 900 3585 2039 4045 3880 3217 568 2257 821 3269 774 3082 25 85 327 1293 1061 134 522 2073 87 333 1319 1165 549 2184 531 2110 234 921 3669 2374 1289 1047 77 295 1166 555 2207 622 2474 1689 2645 2374 1290 1052 97 373 1480 1809 3125 198 779 3104 115 445 1765 2949 3589 2055 15 45 168 659 2621 2277 904 3601 2101 197 773 3080 17 53 198 780 3105 117 455 1805 3109 136 529 2101 198 778 3097 86 330 1308 1124 385 1525 1990 3850 3097 88 337 1334 1225 789 3141 262 1036 36 132 515 2045 4069 3976 3602 2106 218 860 3426 1404 1508 1921 3573 1990 3850 3100 100 386 1530 2010 3929 3413 1351 1293 1062 137 533 2119 269 1061 133 518 2058 28 100 387 1534 2028 4002 3708 2532 1922 3577 2006 3913 3350 1097 277 1093 261 1030 10 25 86 330 1307 1117 358 1417 1557 2118 268 1057 118 457 1816 3154 313 1240 852 3393 1272 980 3907 3326 1002 3996 3684 2434 1529 2008 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 966 (id = 966)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-2632
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 1619 2366 1257 918 3659 2335 1134 426 1689 2646 2380 1313 1143 464 1842 3260 739 2943 3566 1964 3745 2679 2510 1833 3222 588 2339 1151 493 1960 3731 2623 2286 940 3748 2692 2561 2040 4052 3905 3319 975 3886 3242 667 2654 2409 1432 1617 2357 1222 780 3108 132 516 2052 4097 4088 4051 3903 3312 948 3779 2814 3052 4004 3716 2564 2050 4090 4060 3939 3455 1520 1972 3779 2813 3047 3983 3629 2214 652 2596 2177 504 2002 3899 3293 871 3471 1582 2218 666 2650 2393 1368 1363 1343 1263 944 3764 2756 2817 3063 4046 3883 3230 618 2458 1627 2397 1383 1421 1576 2196 579 2302 1004 4004 3713 2550 1996 3873 3189 456 1809 3126 202 796 3172 388 1537 2038 4042 3867 3166 364 1443 1662 2539 1950 3691 2462 1642 2458 1628 2403 1406 1516 1953 3701 2503 1806 3115 160 628 2498 1786 3033 3926 3402 1306 1115 349 1383 1421 1576 2193 567 2253 807 3214 556 2209 630 2508 1825 3192 467 1854 3308 931 3709 2533 1926 3594 2076 100 385 1525 1992 3859 3133 232 915 3645 2277 901 3590 2060 33 120 465 1847 3280 818 3257 726 2892 3361 1141 453 1797 3079 13 37 134 522 2074 90 348 1377 1398 1481 1813 3142 267 1054 106 412 1633 2422 1482 1818 3162 348 1377 1398 1482 1818 3164 356 1409 1526 1994 3866 3164 354 1402 1497 1879 3407 1326 1194 668 2660 2436 1537 2040 4050 3899 3293 872 3473 1591 2253 806 3210 538 2140 356 1412 1537 2039 4045 3878 3211 541 2149 391 1549 2085 135 527 2093 165 645 2566 2059 30 108 418 1657 2519 1869 3368 1170 570 2265 853 3397 1288 1041 54 201 790 3146 281 1109 328 1300 1091 253 1000 3985 3637 2247 783 3119 175 685 2728 2707 2623 2285 935 3726 2602 2202 603 2398 1387 1439 1645 2472 1683 2623 2286 939 3743 2670 2475 1693 2661 2440 1554 2106 217 854 3402 1307 1117 360 1426 1595 2270 875 3485 1638 2443 1566 2155 415 1646 2475 1696 2676 2498 1787 3037 3944 3474 1596 2276 897 3575 1998 3883 3230 618 2457 1622 2378 1307 1118 362 1435 1629 2405 1415 1550 2091 157 616 2451 1597 2278 908 3618 2170 475 1887 3438 1452 1697 2680 2516 1857 3320 978 3898 3292 868 3457 1526 1994 3866 3164 354 1403 1502 1898 3483 1630 2409 1432 1618 2362 1243 862 3435 1437 1640 2449 1590 2252 802 3195 478 1899 3487 1647 2479 1710 2730 2714 2651 2399 1390 1450 1689 2646 2377 1302 1100 292 1154 508 2017 3957 3525 1797 3079 14 43 158 617 2453 1606 2313 1048 82 315 1246 875 3486 1643 2462 1642 2459 1629 2407 1423 1584 2228 705 2808 3027 3903 3309 935 3726 2604 2209 629 2504 1812 3137 245 968 3857 3126 201 789 3144 275 1087 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 137 (id = 137)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-4383
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 1006 4012 3745 2678 2506 1817 3160 339 1341 1254 906 3612 2145 376 1491 1854 3308 930 3705 2517 1864 3347 1088 243 959 3822 2986 3739 2654 2409 1429 1606 2314 1049 86 331 1310 1130 412 1633 2422 1484 1825 3192 467 1854 3307 925 3687 2446 1579 2205 614 2444 1570 2170 476 1889 3447 1485 1830 3212 548 2178 507 2013 3944 3476 1602 2297 983 3917 3365 1160 532 2113 245 967 3854 3114 154 604 2402 1402 1498 1882 3417 1366 1355 1311 1133 424 1681 2613 2247 781 3112 148 577 2293 968 3859 3134 236 931 3710 2538 1947 3678 2411 1437 1639 2447 1583 2222 682 2716 2658 2425 1494 1867 3360 1138 442 1755 2910 3433 1430 1610 2329 1110 331 1309 1127 399 1584 2228 708 2817 3062 4042 3866 3162 348 1380 1410 1530 2012 3940 3457 1526 1996 3875 3198 492 1955 3710 2539 1950 3691 2464 1649 2485 1734 2825 3093 72 274 1083 224 884 3521 1783 3021 3878 3211 542 2154 411 1630 2409 1431 1614 2347 1182 618 2458 1628 2402 1402 1499 1888 3441 1461 1736 2836 3138 252 995 3968 3572 1987 3840 3059 4030 3820 2979 3710 2538 1948 3681 2421 1480 1812 3138 251 990 3946 3483 1630 2411 1439 1648 2481 1719 2768 2868 3267 765 3046 3977 3608 2129 310 1227 798 3180 417 1656 2514 1851 3295 880 3508 1729 2808 3026 3898 3292 868 3459 1535 2030 4010 3739 2654 2411 1440 1652 2500 1795 3069 4072 3988 3650 2299 992 3955 3518 1772 2978 3705 2519 1871 3376 1204 708 2819 3071 4077 4007 3728 2611 2238 748 2980 3715 2559 2030 4011 3744 2674 2489 1751 2893 3368 1171 574 2283 928 3697 2485 1736 2834 3129 215 846 3371 1184 626 2491 1759 2926 3498 1691 2654 2410 1435 1630 2410 1435 1631 2416 1459 1725 2792 2963 3645 2278 907 3614 2156 420 1665 2552 2003 3903 3312 948 3777 2806 3020 3874 3195 480 1908 3522 1788 3041 3957 3528 1810 3132 228 897 3573 1992 3859 3135 240 948 3780 2819 3069 4070 3980 3620 2178 507 2013 3944 3476 1604 2307 1024 4083 4032 3827 3005 3815 2960 3636 2243 767 3054 4010 3739 2654 2410 1436 1635 2430 1515 1951 3696 2484 1730 2809 3032 3923 3390 1260 932 3714 2556 2018 3961 3544 1874 3388 1252 898 3580 2020 3971 3581 2024 3985 3638 2251 797 3176 404 1602 2300 995 3967 3568 1972 3778 2811 3040 3955 3519 1775 2989 3751 2703 2606 2218 667 2653 2408 1428 1604 2307 1023 4077 4006 3723 2589 2151 400 1586 2234 731 2911 3440 1460 1731 2815 3056 4019 3773 2791 2957 3624 2195 573 2279 912 3635 2239 752 2994 3770 2779 2910 3435 1440 1652 2500 1796 3074 4089 4055 3917 3367 1167 557 2215 655 2606 2219 672 2676 2498 1788 3043 3966 3564 1956 3716 2563 2046 4075 3999 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 272 (id = 272)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-1757
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 682 2716 2660 2436 1539 2045 4071 3982 3628 2211 637 2535 1936 3635 2240 755 3007 3821 2984 3731 2622 2284 931 3712 2548 1987 3837 3047 3984 3633 2232 723 2877 3303 911 3630 2220 675 2685 2536 1939 3645 2279 910 3626 2204 611 2432 1521 1976 3793 2870 3275 800 3186 443 1758 2923 3488 1652 2500 1794 3068 4067 3967 3566 1962 3740 2660 2436 1539 2048 4081 4021 3782 2827 3103 110 428 1699 2686 2538 1948 3684 2434 1532 2017 3959 3533 1832 3219 573 2278 906 3610 2138 347 1373 1384 1427 1599 2285 934 3721 2582 2124 290 1145 470 1865 3350 1099 286 1131 415 1646 2474 1691 2654 2410 1433 1621 2374 1290 1049 85 328 1299 1085 230 908 3619 2176 500 1985 3830 3019 3872 3186 444 1763 2942 3563 1949 3686 2442 1562 2139 352 1396 1476 1795 3072 4084 4035 3840 3057 4021 3782 2827 3102 107 414 1643 2464 1652 2499 1792 3058 4027 3808 2929 3509 1733 2822 3084 33 118 460 1826 3193 470 1868 3363 1151 496 1970 3772 2787 2942 3564 1956 3714 2555 2016 3954 3513 1751 2893 3367 1165 551 2192 564 2244 770 3065 4055 3918 3371 1183 623 2477 1704 2705 2616 2259 831 3310 937 3734 2635 2334 1129 406 1611 2333 1127 398 1580 2209 630 2505 1816 3156 324 1281 1016 4052 3905 3319 973 3877 3205 519 2062 43 158 617 2454 1611 2333 1127 398 1580 2209 630 2505 1816 3156 324 1281 1016 4050 3898 3291 862 3435 1439 1647 2480 1715 2750 2795 2976 3698 2491 1757 2920 3473 1592 2257 823 3279 815 3246 682 2715 2654 2411 1437 1639 2445 1575 2191 560 2228 708 2819 3071 4078 4012 3746 2684 2531 1920 3570 1980 3811 2944 3569 1973 3783 2832 3123 189 743 2957 3624 2193 566 2251 797 3173 391 1552 2099 191 752 2996 3780 2817 3062 4044 3876 3203 512 2034 4025 3800 2897 3384 1235 830 3307 925 3687 2446 1580 2211 640 2547 1981 3816 2963 3645 2279 911 3632 2226 700 2788 2948 3588 2049 4086 4044 3875 3200 500 1987 3839 3056 4017 3766 2763 2845 3174 395 1565 2151 400 1586 2235 736 2931 3520 1780 3009 3830 3019 3872 3186 444 1763 2943 3568 1971 3775 2798 2987 3743 2671 2477 1703 2704 2612 2243 767 3056 4018 3772 2785 2935 3536 1844 3266 764 3043 3967 3568 1969 3767 2768 2865 3254 715 2847 3181 421 1670 2569 2070 74 282 1115 350 1385 1432 1617 2360 1234 826 3290 857 3413 1349 1287 1037 40 146 569 2262 842 3353 1109 325 1287 1040 51 189 741 2949 3589 2053 8 20 67 255 1005 4006 3723 2591 2160 434 1723 2781 2920 3476 1601 2294 972 3876 3203 511 2030 4010 3739 2654 2412 1443 1662 2538 1945 3672 2387 1342 1257 917 3654 2315 1053 101 391 1550 2089 152 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-5257
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 1689 2647 2384 1331 1213 742 2955 3614 2156 418 1660 2531 1920 3572 1986 3833 3030 3914 3354 1115 349 1383 1421 1575 2191 560 2227 701 2790 2953 3606 2124 292 1154 508 2019 3965 3559 1934 3627 2206 619 2461 1640 2450 1593 2263 845 3365 1158 523 2078 108 419 1662 2539 1950 3692 2465 1654 2508 1827 3199 496 1971 3773 2790 2953 3608 2130 314 1241 853 3400 1299 1087 237 936 3731 2623 2287 943 3760 2737 2743 2765 2855 3215 559 2224 691 2751 2797 2981 3719 2573 2087 143 559 2224 691 2750 2796 2977 3703 2512 1843 3264 755 3007 3823 2990 3756 2721 2679 2512 1844 3268 771 3070 4074 3996 3682 2427 1502 1900 3491 1662 2539 1951 3695 2480 1716 2755 2813 3046 3979 3615 2160 435 1726 2794 2969 3671 2381 1320 1169 567 2253 805 3208 531 2110 236 930 3708 2529 1911 3535 1840 3250 699 2782 2923 3487 1648 2484 1732 2817 3064 4051 3902 3308 931 3709 2534 1932 3618 2172 482 1915 3549 1896 3473 1592 2260 834 3322 986 3930 3419 1373 1383 1423 1584 2226 699 2781 2918 3467 1565 2151 399 1584 2225 693 2757 2823 3088 51 192 755 3008 3825 3000 3793 2871 3280 817 3253 709 2824 3092 68 259 1023 4078 4011 3744 2674 2492 1761 2934 3529 1815 3152 307 1215 750 2985 3734 2634 2330 1114 346 1369 1366 1353 1304 1108 322 1274 985 3925 3398 1292 1058 123 477 1894 3468 1569 2166 457 1813 3142 265 1045 70 268 1060 130 506 2010 3931 3422 1386 1433 1624 2385 1335 1232 818 3259 733 2920 3476 1602 2300 996 3971 3581 2023 3982 3626 2202 602 2395 1376 1396 1476 1796 3073 4085 4037 3846 3084 34 124 483 1920 3571 1984 3828 3009 3829 3015 3855 3119 175 686 2729 2710 2634 2330 1116 354 1402 1498 1881 3414 1354 1306 1114 346 1371 1374 1385 1429 1605 2310 1033 23 77 294 1162 539 2141 357 1413 1542 2057 22 76 290 1145 470 1867 3359 1136 435 1726 2795 2973 3686 2444 1569 2168 465 1847 3277 805 3206 521 2069 71 271 1071 174 684 2721 2678 2505 1813 3141 262 1036 35 126 490 1947 3677 2405 1414 1545 2069 70 265 1046 74 284 1121 373 1477 1797 3077 8 20 65 245 968 3857 3128 210 825 3286 844 3361 1144 466 1849 3286 842 3355 1117 357 1415 1549 2086 138 538 2139 351 1392 1458 1724 2786 2939 3552 1907 3519 1775 2990 3754 2713 2646 2378 1307 1119 367 1454 1706 2714 2650 2394 1370 1372 1379 1408 1524 1987 3837 3046 3978 3610 2138 348 1379 1407 1518 1962 3739 2655 2414 1452 1698 2682 2522 1882 3418 1372 1379 1406 1515 1949 3687 2447 1583 2221 680 2705 2613 2245 775 3088 51 190 748 2980 3714 2556 2017 3957 3525 1800 3090 57 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 813 (id = 813)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-3508
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 3533 1831 3214 555 2208 628 2498 1787 3039 3949 3493 1671 2576 2100 193 760 3025 3896 3284 835 3325 999 3983 3629 2216 659 2624 2292 962 3836 3044 3969 3575 1999 3886 3244 676 2692 2564 2052 4099 4093 4072 3987 3647 2288 945 3767 2767 2862 3242 668 2659 2431 1519 1965 3751 2704 2610 2235 735 2925 3496 1683 2621 2280 915 3645 2280 915 3645 2277 903 3597 2088 147 573 2280 916 3651 2303 1007 4014 3756 2723 2685 2536 1940 3650 2300 996 3971 3581 2021 3976 3604 2115 253 1000 3987 3646 2283 927 3694 2475 1695 2670 2474 1691 2653 2408 1427 1597 2280 915 3645 2280 915 3645 2277 903 3597 2088 147 573 2280 915 3645 2280 915 3645 2280 915 3645 2277 903 3597 2088 147 573 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2277 903 3597 2088 147 573 2280 915 3645 2277 903 3597 2088 147 573 2280 915 3645 2280 915 3645 2277 903 3597 2085 135 525 2088 147 573 2280 915 3645 2280 915 3645 2280 915 3645 2277 903 3597 2088 147 573 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2277 904 3602 2106 217 856 3410 1340 1252 897 3574 1994 3865 3157 325 1288 1042 59 222 875 3487 1647 2477 1701 2696 2577 2104 212 833 3317 966 3852 3105 119 461 1829 3208 531 2109 229 903 3599 2093 168 659 2622 2283 926 3690 2459 1629 2408 1428 1602 2298 987 3935 3439 1456 1714 2748 2786 2939 3549 1896 3474 1596 2276 899 3582 2025 3990 3660 2337 1142 460 1825 3191 461 1831 3215 558 2219 669 2664 2452 1602 2298 985 3926 3403 1309 1127 398 1579 2207 622 2475 1693 2661 2439 1549 2085 133 518 2060 35 125 488 1939 3645 2280 913 3638 2251 799 3182 427 1695 2669 2472 1683 2621 2280 915 3645 2280 916 3650 2300 995 3966 3564 1953 3704 2515 1855 3311 943 3759 2733 2728 2707 2621 2280 915 3646 2283 927 3693 2472 1684 2626 2298 987 3934 3435 1439 1646 2475 1695 2669 2472 1683 2621 2280 915 3645 2280 915 3645 2280 916 3651 2303 1007 4014 3755 2717 2662 2444 1571 2174 490 1947 3677 2405 1415 1549 2088 147 573 2280 915 3645 2280 915 3646 2282 923 3677 2405 1416 1553 2101 198 778 3098 90 345 1366 1353 1301 1093 261 1029 5 7 13 37 135 525 2088 148 577 2293 967 3853 3112 146 570 2268 867 3453 1512 1939 3646 2282 923 3677 2405 1415 1550 2090 155 606 2411 1439 1645 2469 1671 2573 2088 147 573 2277 903 3597 2086 140 547 2174 492 1956 3713 2549 1989 3845 3079 13 40 147 575 2288 945 3765 2757 2824 3089 56 211 829 3304 915 3645 2280 915 3645 2280 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 81 (id = 81)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 2280 915 3645 2280 915 3645 2280 916 3649 2293 965 3845 3080 17 54 203 797 3173 392 1555 2111 239 941 3749 2693 2568 2066 60 225 888 3540 1858 3323 992 3953 3511 1741 2856 3218 571 2272 883 3520 1779 3005 3816 2963 3645 2278 907 3613 2151 400 1585 2229 712 2835 3136 243 958 3820 2980 3714 2556 2020 3972 3586 2043 4061 3942 3468 1572 2180 514 2042 4058 3929 3415 1357 1319 1165 550 2188 547 2175 495 1965 3751 2701 2598 2187 544 2162 441 1752 2899 3391 1262 938 3740 2658 2427 1504 1907 3517 1768 2963 3645 2279 911 3631 2222 684 2723 2685 2536 1939 3647 2287 942 3754 2716 2660 2435 1533 2023 3984 3636 2242 763 3040 3955 3519 1776 2994 3771 2781 2917 3464 1554 2105 215 847 3373 1192 660 2625 2295 973 3878 3212 545 2166 458 1820 3171 384 1524 1987 3840 3058 4026 3804 2915 3455 1520 1972 3777 2805 3016 3859 3135 237 935 3725 2599 2189 550 2188 545 2168 468 1859 3328 1009 4022 3787 2848 3186 443 1760 2932 3522 1788 3042 3964 3556 1924 3588 2049 4085 4037 3847 3085 40 146 572 2276 897 3576 2003 3904 3316 961 3832 3027 3903 3311 944 3761 2744 2771 2880 3315 958 3818 2972 3681 2424 1492 1859 3327 1007 4014 3756 2722 2682 2524 1889 3447 1488 1844 3266 763 3040 3955 3520 1780 3012 3841 3064 4049 3896 3283 830 3308 929 3704 2513 1848 3284 836 3331 1023 4078 4011 3743 2671 2479 1710 2730 2715 2653 2408 1427 1598 2284 932 3713 2551 1997 3879 3216 564 2244 771 3071 4077 4008 3730 2618 2268 867 3454 1516 1953 3701 2504 1809 3126 203 800 3187 448 1777 2997 3784 2835 3136 244 964 3844 3073 4088 4052 3905 3320 978 3899 3293 871 3472 1588 2243 768 3060 4034 3835 3040 3953 3512 1748 2883 3328 1012 4034 3836 3043 3965 3559 1936 3635 2240 754 3004 3812 2947 3584 2035 4029 3813 2950 3596 2083 128 499 1982 3819 2973 3687 2448 1588 2244 769 3064 4051 3901 3303 911 3631 2223 686 2731 2717 2661 2439 1551 2094 172 673 2679 2511 1840 3249 696 2769 2871 3280 820 3266 761 3031 3917 3366 1164 545 2165 453 1799 3088 51 189 742 2956 3620 2179 509 2023 3984 3636 2243 768 3058 4027 3806 2923 3485 1637 2439 1550 2091 157 615 2448 1587 2239 750 2988 3745 2680 2515 1853 3304 916 3650 2297 984 3922 3388 1252 899 3582 2025 3990 3658 2332 1123 381 1510 1931 3615 2157 421 1670 2569 2069 71 272 1076 196 772 3076 4099 4093 4072 3985 3639 2255 815 3248 691 2749 2791 2958 3628 2212 641 2552 2002 3899 3293 869 3462 1547 2080 114 444 1764 2947 3583 2031 4013 3752 2707 2622 2282 922 3675 2400 1393 1464 1748 2883 3327 1008 4020 3777 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 221 (id = 221)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-3509
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 2060 33 117 454 1801 3093 71 272 1073 181 709 2822 3084 33 120 465 1847 3277 805 3205 520 2065 53 200 785 3128 209 821 3271 783 3117 165 646 2570 2074 90 346 1369 1367 1357 1317 1160 531 2109 230 908 3620 2180 516 2049 4088 4051 3904 3315 958 3820 2977 3702 2506 1819 3166 363 1438 1642 2458 1626 2396 1380 1410 1529 2007 3920 3379 1214 746 2971 3679 2415 1453 1702 2699 2591 2157 424 1683 2621 2278 906 3610 2139 350 1388 1442 1657 2518 1867 3358 1130 410 1627 2397 1383 1423 1582 2218 667 2653 2405 1415 1551 2094 170 665 2648 2388 1345 1270 971 3870 3179 414 1641 2455 1615 2351 1198 682 2716 2660 2435 1536 2033 4021 3781 2821 3080 18 59 223 878 3499 1694 2668 2467 1663 2541 1957 3719 2573 2085 134 524 2081 118 460 1825 3190 457 1814 3147 286 1132 417 1654 2507 1823 3181 423 1679 2605 2215 654 2602 2201 599 2381 1317 1159 526 2090 155 608 2418 1467 1760 2929 3511 1744 2868 3266 762 3035 3934 3436 1442 1657 2519 1870 3372 1187 638 2540 1953 3703 2511 1839 3245 677 2694 2572 2083 125 486 1931 3616 2163 447 1774 2986 3738 2652 2402 1403 1504 1906 3515 1758 2921 3477 1605 2311 1039 46 169 663 2637 2343 1167 558 2220 676 2692 2564 2050 4091 4061 3942 3468 1569 2166 458 1817 3160 339 1343 1261 933 3718 2571 2077 101 389 1543 2063 47 174 682 2715 2654 2410 1435 1630 2411 1438 1642 2459 1631 2414 1451 1695 2671 2477 1702 2697 2582 2123 288 1138 442 1755 2910 3436 1441 1656 2515 1853 3301 902 3596 2081 117 455 1807 3119 173 677 2694 2569 2069 71 272 1073 181 709 2822 3083 30 106 410 1625 2390 1355 1309 1127 398 1579 2206 618 2458 1628 2403 1405 1509 1926 3593 2070 75 285 1125 391 1552 2100 194 761 3031 3919 3375 1198 682 2713 2648 2386 1337 1238 841 3350 1098 283 1117 359 1423 1584 2226 700 2786 2940 3555 1918 3561 1944 3665 2360 1233 821 3271 783 3119 174 682 2716 2660 2433 1525 1992 3857 3126 201 789 3142 266 1051 93 360 1427 1597 2277 904 3603 2109 230 907 3613 2149 390 1545 2069 70 267 1055 111 431 1710 2730 2716 2660 2434 1530 2011 3934 3434 1434 1628 2404 1410 1532 2017 3959 3535 1838 3243 670 2666 2460 1635 2432 1523 1981 3815 2959 3630 2218 668 2658 2426 1498 1883 3421 1381 1416 1555 2111 237 936 3731 2621 2277 903 3597 2085 134 521 2071 79 301 1192 659 2621 2279 911 3629 2216 658 2617 2261 839 3343 1071 175 688 2738 2748 2788 2948 3587 2048 4082 4026 3804 2916 3458 1532 2017 3958 3529 1814 3147 285 1128 401 1591 2255 813 3238 650 2587 2142 364 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 957 (id = 957)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 65 (id = 65)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-5258
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 3767 2765 2854 3212 548 2179 511 2031 4014 3756 2721 2677 2504 1811 3134 235 928 3698 2492 1764 2948 3587 2048 4084 4036 3844 3076 4099 4095 4077 4007 3727 2606 2220 673 2678 2507 1822 3180 419 1661 2533 1927 3598 2090 156 609 2421 1480 1809 3127 207 813 3239 653 2598 2185 535 2125 296 1169 566 2251 799 3181 421 1672 2577 2101 197 775 3087 47 176 691 2750 2793 2965 3656 2321 1077 199 783 3118 171 669 2661 2440 1553 2102 204 803 3199 495 1968 3764 2755 2816 3058 4027 3806 2921 3479 1614 2345 1174 588 2338 1148 484 1921 3575 1997 3880 3217 565 2248 785 3127 206 812 3236 641 2549 1989 3848 3089 53 198 779 3101 101 392 1556 2113 248 980 3907 3327 1008 4017 3767 2765 2853 3205 520 2065 56 209 823 3279 814 3241 663 2640 2354 1211 736 2929 3512 1747 2877 3304 915 3645 2279 912 3633 2232 724 2882 3324 996 3971 3582 2028 4002 3708 2532 1923 3583 2029 4008 3729 2614 2249 791 3150 300 1187 640 2545 1975 3791 2862 3243 671 2671 2478 1705 2712 2643 2365 1253 901 3591 2062 44 164 644 2564 2051 4093 4071 3981 3624 2193 566 2252 801 3192 466 1851 3296 881 3511 1744 2868 3267 768 3059 4032 3827 3007 3823 2991 3758 2732 2723 2685 2536 1940 3652 2305 1013 4038 3850 3099 96 369 1462 1737 2838 3147 285 1125 392 1555 2110 234 921 3670 2379 1312 1137 438 1737 2837 3142 267 1053 101 391 1551 2094 171 670 2668 2468 1665 2550 1994 3865 3159 333 1317 1157 517 2054 10 26 92 354 1404 1505 1909 3525 1800 3089 54 202 796 3169 375 1486 1836 3236 642 2553 2006 3914 3355 1118 362 1433 1621 2375 1294 1065 150 588 2338 1146 476 1891 3454 1515 1951 3694 2474 1690 2650 2393 1367 1360 1331 1214 745 2966 3660 2338 1148 484 1921 3574 1993 3863 3152 307 1214 748 2979 3710 2538 1946 3673 2389 1350 1292 1059 127 494 1962 3738 2652 2402 1401 1494 1867 3357 1126 396 1571 2174 489 1942 3658 2332 1123 382 1514 1947 3679 2415 1456 1714 2745 2774 2892 3364 1155 510 2026 3994 3675 2397 1382 1418 1562 2138 347 1374 1387 1439 1646 2475 1695 2670 2474 1692 2658 2425 1494 1865 3349 1093 262 1035 31 110 428 1700 2690 2554 2012 3939 3454 1516 1954 3707 2526 1899 3486 1642 2458 1625 2390 1356 1313 1144 468 1857 3320 978 3898 3292 866 3452 1508 1923 3583 2031 4016 3762 2746 2780 2914 3451 1501 1896 3476 1603 2301 997 3975 3600 2098 188 740 2947 3584 2034 4028 3812 2946 3580 2018 3964 3555 1917 3559 1934 3628 2210 636 2530 1914 3546 1884 3427 1406 1516 1953 3703 2512 1843 3261 741 2951 3599 2095 175 687 2733 2727 2702 2604 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 367 (id = 367)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   Writing example 0/876
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-6133
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 1192 660 2627 2304 1010 4026 3802 2907 3423 1391 1455 1711 2734 2732 2724 2689 2549 1992 3859 3134 235 927 3695 2478 1707 2720 2674 2492 1763 2944 3571 1982 3819 2974 3691 2463 1646 2476 1698 2682 2523 1887 3440 1457 1719 2767 2863 3246 684 2723 2687 2544 1971 3774 2794 2969 3671 2383 1328 1204 705 2806 3017 3863 3151 302 1196 674 2683 2527 1904 3507 1727 2798 2986 3738 2651 2398 1387 1439 1647 2478 1706 2715 2656 2420 1476 1793 3061 4040 3859 3136 242 956 3812 2947 3584 2035 4030 3818 2970 3675 2398 1387 1437 1638 2441 1560 2131 318 1259 925 3687 2448 1587 2238 748 2978 3705 2520 1876 3394 1273 982 3915 3358 1131 413 1640 2450 1594 2267 864 3444 1474 1788 3042 3961 3544 1876 3394 1275 992 3954 3514 1755 2912 3443 1470 1771 2975 3693 2469 1672 2579 2110 236 932 3716 2563 2046 4076 4002 3708 2530 1916 3555 1917 3559 1936 3633 2229 711 2831 3119 175 687 2735 2736 2738 2746 2779 2909 3432 1427 1599 2287 944 3761 2743 2767 2864 3251 702 2796 2979 3712 2547 1983 3822 2986 3737 2646 2379 1311 1136 436 1730 2809 3029 3911 3342 1065 150 587 2336 1138 443 1758 2922 3484 1633 2424 1490 1851 3295 877 3493 1671 2575 2095 176 692 2754 2809 3029 3912 3345 1079 205 807 3216 561 2231 718 2858 3225 598 2379 1312 1139 447 1773 2983 3726 2604 2212 643 2557 2024 3987 3645 2280 915 3647 2285 935 3726 2604 2212 642 2553 2005 3911 3341 1064 148 577 2294 970 3865 3160 339 1341 1256 913 3640 2259 832 3313 952 3796 2882 3321 982 3916 3362 1145 472 1876 3395 1280 1012 4034 3836 3043 3966 3561 1943 3661 2344 1169 568 2258 826 3291 862 3434 1436 1633 2421 1480 1810 3132 228 898 3580 2020 3971 3583 2030 4009 3733 2631 2318 1065 151 592 2356 1219 766 3049 3991 3661 2343 1166 553 2200 593 2357 1224 788 3137 247 973 3880 3218 569 2262 842 3354 1116 356 1410 1529 2006 3915 3358 1132 419 1664 2547 1982 3819 2974 3692 2467 1662 2540 1953 3701 2504 1811 3135 237 936 3730 2618 2265 855 3407 1326 1194 667 2656 2420 1473 1781 3013 3845 3077 8 17 56 210 826 3292 868 3458 1529 2008 3923 3390 1259 926 3690 2460 1633 2422 1483 1823 3184 436 1731 2813 3045 3973 3591 2061 37 133 519 2063 45 167 655 2608 2227 702 2796 2980 3714 2553 2008 3923 3392 1268 962 3836 3044 3970 3578 2010 3930 3418 1370 1370 1372 1378 1402 1498 1884 3427 1405 1509 1928 3603 2109 232 915 3645 2280 913 3638 2250 793 3159 336 1331 1216 755 3005 3816 2961 3637 2245 773 3077 5 5 8 20 65 246 971 3870 3179 413 1637 2440 1553 2101 200 785 3126 203 799 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 920 (id = 920)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-4384
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-2633
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 143 559 2224 691 2750 2796 2977 3703 2512 1843 3264 755 3007 3823 2990 3756 2721 2679 2512 1844 3268 771 3070 4074 3996 3682 2427 1502 1900 3491 1662 2539 1951 3695 2480 1716 2755 2813 3046 3979 3615 2160 435 1726 2794 2969 3671 2381 1320 1169 567 2253 805 3208 531 2110 236 930 3708 2529 1911 3535 1840 3250 699 2782 2923 3487 1648 2484 1732 2817 3064 4051 3902 3308 931 3709 2534 1932 3618 2172 482 1915 3549 1896 3473 1592 2260 834 3322 986 3930 3419 1373 1383 1423 1584 2226 699 2781 2918 3467 1565 2151 399 1584 2225 693 2757 2823 3088 51 192 755 3008 3825 3000 3793 2871 3280 817 3253 709 2824 3092 68 259 1023 4078 4012 3747 2688 2547 1981 3814 2954 3611 2142 363 1437 1638 2442 1564 2147 381 1511 1935 3631 2221 677 2693 2566 2058 26 89 342 1354 1307 1118 362 1435 1629 2407 1421 1573 2181 517 2053 6 9 21 70 265 1045 70 265 1048 81 310 1226 794 3162 345 1366 1354 1305 1111 336 1331 1216 753 2998 3787 2848 3185 438 1738 2841 3158 330 1306 1113 342 1354 1306 1115 351 1390 1452 1697 2677 2501 1797 3079 13 37 133 518 2057 21 69 261 1029 5 5 6 11 31 111 431 1712 2739 2751 2797 2981 3717 2566 2060 36 131 509 2024 3988 3652 2305 1014 4043 3870 3178 409 1624 2385 1334 1226 795 3166 364 1442 1660 2531 1918 3562 1946 3674 2393 1365 1352 1299 1085 232 913 3640 2257 822 3274 793 3159 335 1326 1193 662 2635 2334 1129 408 1617 2359 1230 812 3235 637 2536 1940 3650 2299 992 3953 3511 1741 2853 3208 531 2110 234 924 3681 2421 1478 1802 3099 96 372 1473 1782 3019 3871 3183 430 1707 2720 2673 2488 1746 2874 3289 856 3410 1338 1244 867 3454 1513 1942 3657 2327 1101 296 1171 575 2285 936 3731 2624 2292 961 3830 3020 3873 3190 460 1826 3194 475 1885 3432 1427 1597 2280 915 3645 2280 915 3645 2280 915 3645 2280 916 3650 2299 992 3954 3516 1762 2938 3546 1884 3428 1409 1526 1994 3867 3167 366 1452 1698 2682 2523 1888 3444 1473 1782 3018 3866 3163 350 1388 1442 1658 2522 1881 3413 1350 1290 1050 90 347 1374 1388 1441 1653 2502 1801 3093 70 266 1050 90 348 1377 1397 1477 1797 3079 16 50 188 740 2946 3579 2015 3952 3508 1729 2805 3014 3849 3093 71 271 1070 172 676 2690 2555 2013 3941 3462 1548 2083 126 492 1955 3711 2544 1971 3773 2792 2961 3637 2248 787 3136 244 961 3829 3015 3853 3112 147 574 2284 932 3714 2556 2020 3969 3573 1990 3850 3098 91 352 1395 1471 1773 2982 3724 2596 2178 506 2010 3930 3419 1376 1396 1475 1789 3048 3988 3652 2307 1021 4070 3977 3607 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 2807 3021 3879 3216 563 2238 748 2977 3701 2503 1806 3114 156 610 2428 1508 1923 3583 2032 4018 3770 2778 2905 3415 1360 1330 1211 736 2931 3519 1776 2994 3771 2783 2925 3496 1683 2622 2283 928 3697 2487 1743 2862 3244 676 2689 2550 1996 3876 3204 515 2045 4071 3983 3629 2215 655 2607 2223 688 2740 2754 2812 3041 3957 3527 1805 3112 147 574 2283 927 3694 2475 1696 2675 2495 1775 2990 3754 2716 2659 2430 1515 1949 3687 2447 1581 2214 652 2596 2177 502 1994 3867 3168 371 1470 1771 2975 3695 2478 1707 2719 2672 2484 1730 2809 3031 3919 3376 1203 703 2799 2990 3754 2716 2658 2425 1495 1869 3368 1171 574 2283 928 3698 2491 1759 2925 3494 1676 2595 2175 496 1969 3768 2769 2872 3282 828 3297 886 3531 1823 3183 432 1716 2755 2816 3060 4035 3840 3060 4034 3835 3037 3943 3472 1585 2229 711 2830 3115 159 621 2472 1683 2621 2280 916 3649 2295 975 3885 3238 652 2594 2172 481 1910 3531 1824 3187 448 1779 3006 3818 2971 3678 2411 1440 1650 2490 1756 2916 3460 1540 2050 4091 4062 3946 3482 1627 2400 1393 1461 1733 2824 3091 61 230 908 3620 2177 503 1998 3884 3235 637 2535 1936 3635 2238 747 2973 3688 2452 1602 2297 984 3922 3388 1252 898 3578 2012 3938 3451 1504 1908 3524 1795 3069 4072 3987 3645 2280 915 3645 2279 912 3636 2244 772 3075 4095 4080 4018 3771 2784 2931 3519 1776 2993 3766 2764 2852 3204 516 2052 4098 4092 4066 3962 3547 1886 3436 1443 1662 2540 1956 3714 2553 2008 3922 3388 1252 898 3577 2008 3924 3395 1280 1009 4024 3795 2878 3308 931 3709 2535 1936 3635 2239 752 2995 3775 2800 2995 3775 2799 2990 3755 2720 2673 2486 1740 2850 3194 476 1890 3452 1508 1923 3584 2036 4033 3830 3019 3870 3178 412 1633 2421 1480 1810 3129 215 848 3379 1215 750 2986 3740 2657 2422 1484 1827 3199 496 1970 3770 2779 2910 3434 1435 1630 2412 1443 1662 2539 1952 3698 2491 1760 2932 3523 1791 3054 4010 3740 2657 2422 1481 1814 3145 280 1105 311 1232 818 3258 731 2911 3439 1456 1716 2756 2817 3061 4037 3847 3086 43 157 616 2450 1593 2261 837 3335 1038 43 159 622 2474 1692 2659 2431 1517 1959 3725 2599 2190 554 2203 606 2411 1437 1638 2442 1564 2145 374 1484 1828 3201 504 2001 3895 3279 815 3248 692 2753 2806 3019 3870 3179 414 1642 2459 1631 2414 1451 1695 2670 2475 1693 2662 2441 1560 2130 315 1248 882 3515 1757 2917 3461 1544 2066 58 217 855 3406 1323 1184 626 2492 1762 2939 3551 1903 3503 1709 2728 2708 2628 2307 1023 4078 4010 3738 2649 2389 1349 1287 1038 42 154 604 2404 1410 1529 2006 3916 3361 1141 456 1812 3140 257 1016 4051 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 350 (id = 350)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 927 (id = 927)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-5259
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 2670 2474 1690 2649 2392 1363 1343 1263 944 3761 2744 2772 2884 3330 1020 4067 3967 3566 1964 3747 2687 2543 1967 3757 2727 2702 2603 2206 620 2466 1660 2531 1918 3562 1946 3675 2397 1384 1428 1601 2293 965 3846 3081 24 84 321 1269 968 3859 3135 239 943 3757 2728 2707 2621 2280 916 3649 2293 966 3850 3098 90 347 1375 1389 1446 1675 2591 2159 429 1704 2708 2626 2297 983 3918 3369 1174 586 2330 1116 353 1397 1480 1809 3125 199 783 3117 167 654 2604 2211 638 2538 1945 3672 2388 1345 1269 967 3855 3119 174 683 2717 2664 2451 1598 2284 932 3716 2563 2048 4081 4024 3796 2882 3324 996 3971 3582 2027 3997 3686 2444 1571 2175 494 1961 3734 2633 2325 1094 265 1047 79 301 1192 659 2621 2279 910 3626 2202 602 2396 1380 1409 1528 2004 3907 3327 1005 4005 3720 2577 2102 204 804 3204 513 2040 4052 3905 3318 971 3869 3175 398 1578 2204 609 2424 1491 1855 3311 941 3752 2708 2625 2296 980 3906 3324 996 3969 3576 2004 3907 3326 1001 3991 3661 2344 1170 572 2273 888 3539 1854 3308 930 3708 2529 1910 3531 1821 3173 392 1555 2111 237 935 3726 2604 2211 637 2535 1934 3627 2207 621 2472 1683 2623 2286 940 3748 2692 2561 2040 4049 3895 3277 808 3218 570 2265 856 3409 1335 1231 815 3246 684 2722 2683 2526 1899 3485 1637 2437 1541 2053 7 13 37 133 519 2064 49 181 711 2829 3109 133 519 2061 37 133 519 2061 37 133 517 2053 7 15 47 174 683 2717 2661 2438 1546 2075 95 367 1453 1703 2704 2609 2229 711 2832 3123 191 751 2991 3757 2728 2708 2625 2296 977 3894 3273 789 3144 276 1092 257 1016 4051 3901 3302 908 3620 2179 511 2031 4013 3752 2708 2627 2303 1006 4010 3740 2657 2424 1491 1855 3309 936 3732 2628 2307 1022 4074 3995 3678 2412 1444 1667 2557 2024 3986 3641 2264 852 3396 1284 1025 4088 4051 3903 3310 939 3743 2671 2479 1711 2733 2726 2698 2586 2140 355 1406 1513 1941 3656 2323 1088 244 961 3831 3022 3882 3226 603 2399 1390 1451 1694 2666 2459 1631 2414 1450 1691 2654 2412 1442 1657 2520 1876 3395 1278 1002 3996 3684 2436 1539 2047 4078 4012 3748 2689 2549 1991 3853 3112 148 577 2295 973 3880 3220 579 2301 1000 3988 3652 2308 1027 4095 4079 4016 3761 2741 2760 2833 3125 197 776 3090 60 225 886 3532 1825 3189 454 1802 3098 91 349 1384 1425 1592 2259 830 3308 929 3702 2508 1826 3196 482 1914 3547 1885 3431 1423 1582 2220 676 2692 2563 2045 4072 3985 3638 2251 799 3183 431 1711 2733 2725 2693 2566 2059 31 112 436 1729 2805 3016 3858 3131 221 869 3461 1544 2065 53 200 785 3127 205 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 379 (id = 379)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-4385
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 3629 2216 660 2625 2294 971 3869 3176 402 1596 2273 885 3525 1799 3088 51 189 743 2959 3629 2216 657 2615 2253 808 3219 575 2288 947 3776 2802 3003 3805 2920 3473 1592 2259 829 3304 915 3646 2283 925 3688 2452 1602 2298 987 3934 3436 1444 1668 2561 2040 4049 3896 3284 836 3330 1017 4056 3923 3392 1267 957 3816 2964 3652 2306 1020 4068 3971 3583 2029 4007 3726 2604 2209 632 2513 1845 3271 783 3120 180 708 2819 3069 4072 3988 3650 2299 989 3943 3472 1587 2237 742 2955 3615 2159 431 1711 2735 2735 2734 2730 2715 2655 2415 1454 1707 2719 2671 2477 1703 2703 2607 2223 687 2734 2732 2723 2687 2541 1957 3720 2579 2110 235 926 3691 2463 1647 2478 1707 2719 2671 2477 1704 2708 2625 2294 971 3871 3182 427 1694 2667 2462 1644 2468 1667 2558 2027 3999 3693 2470 1675 2592 2162 441 1749 2888 3347 1085 229 901 3591 2063 46 170 665 2648 2385 1336 1236 834 3322 987 3934 3436 1444 1667 2557 2021 3976 3604 2113 248 977 3896 3281 824 3281 822 3276 804 3203 510 2027 3999 3693 2472 1684 2625 2293 965 3846 3084 36 132 516 2052 4098 4092 4066 3964 3554 1915 3549 1895 3471 1581 2216 657 2614 2249 789 3144 276 1089 245 966 3851 3102 108 419 1663 2542 1961 3733 2631 2317 1064 148 577 2296 980 3906 3324 996 3972 3588 2052 4098 4090 4057 3928 3409 1335 1231 815 3245 677 2694 2569 2070 75 285 1128 404 1601 2296 977 3895 3278 809 3224 596 2369 1269 968 3860 3137 248 980 3905 3320 980 3907 3327 1006 4009 3733 2632 2324 1089 246 972 3876 3204 516 2051 4094 4074 3994 3674 2395 1374 1388 1442 1659 2525 1895 3471 1581 2213 646 2571 2079 110 428 1698 2683 2527 1903 3502 1705 2712 2642 2362 1242 857 3413 1350 1290 1049 85 327 1295 1071 174 683 2718 2665 2456 1617 2360 1235 830 3306 921 3672 2386 1337 1239 846 3372 1186 635 2528 1905 3512 1746 2874 3290 857 3415 1358 1323 1183 623 2478 1705 2710 2635 2333 1128 402 1596 2273 886 3529 1816 3153 312 1233 821 3271 784 3122 185 726 2892 3362 1147 480 1905 3512 1746 2874 3290 857 3415 1358 1323 1183 623 2478 1705 2710 2635 2333 1128 402 1596 2273 886 3529 1816 3153 312 1233 821 3271 784 3121 182 716 2850 3195 480 1905 3512 1746 2874 3290 857 3415 1358 1323 1183 623 2478 1705 2710 2635 2333 1128 402 1596 2273 886 3529 1816 3153 312 1233 821 3271 784 3122 185 726 2892 3362 1147 480 1905 3512 1746 2874 3290 857 3415 1358 1323 1183 623 2478 1705 2710 2635 2333 1128 402 1596 2273 886 3529 1816 3153 312 1233 821 3271 784 3122 185 726 2892 3362 1147 480 1905 3512 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 656 (id = 656)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-6134
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 1328 1204 705 2806 3017 3861 3144 276 1091 256 1011 4029 3816 2963 3648 2292 962 3835 3040 3956 3524 1795 3070 4076 4001 3701 2503 1808 3124 196 772 3076 4100 4098 4090 4059 3936 3442 1468 1763 2941 3559 1933 3623 2189 552 2195 575 2287 941 3752 2707 2622 2282 924 3684 2433 1528 2003 3904 3313 949 3783 2832 3121 183 719 2862 3241 663 2637 2343 1167 560 2225 693 2759 2830 3116 161 632 2513 1846 3273 791 3151 302 1193 663 2637 2344 1171 576 2290 956 3809 2936 3539 1854 3305 918 3660 2337 1144 465 1845 3269 776 3091 64 243 959 3821 2983 3728 2611 2238 746 2971 3679 2415 1456 1713 2741 2760 2836 3140 257 1016 4049 3893 3269 776 3092 67 256 1012 4033 3831 3021 3880 3220 578 2297 982 3915 3359 1136 436 1730 2809 3029 3912 3347 1088 244 963 3837 3048 3988 3652 2306 1019 4064 3956 3521 1781 3015 3853 3112 148 577 2296 977 3896 3283 832 3315 957 3815 2960 3633 2232 724 2884 3329 1016 4051 3902 3306 923 3679 2413 1448 1684 2628 2308 1028 4097 4085 4037 3847 3088 51 191 750 2988 3748 2690 2553 2006 3915 3358 1130 410 1625 2390 1353 1304 1106 315 1247 878 3500 1698 2683 2528 1908 3524 1794 3066 4058 3931 3424 1395 1471 1773 2983 3727 2606 2219 670 2668 2465 1655 2510 1834 3228 609 2424 1491 1856 3314 955 3808 2929 3510 1738 2842 3162 346 1372 1378 1404 1505 1910 3532 1827 3198 491 1952 3698 2491 1757 2920 3476 1604 2308 1028 4100 4099 4096 4084 4033 3832 3027 3903 3310 937 3734 2636 2340 1153 501 1989 3845 3077 7 16 51 191 749 2984 3731 2621 2277 903 3600 2099 192 756 3011 3839 3054 4010 3738 2650 2394 1369 1367 1360 1332 1218 762 3035 3935 3438 1452 1700 2691 2559 2030 4010 3738 2650 2396 1379 1406 1516 1956 3715 2559 2030 4010 3738 2650 2396 1379 1406 1515 1949 3687 2445 1574 2188 546 2170 475 1886 3434 1434 1627 2399 1390 1452 1699 2688 2546 1978 3801 2902 3403 1311 1135 431 1710 2732 2721 2678 2506 1819 3166 364 1442 1660 2532 1921 3574 1993 3861 3143 271 1072 178 697 2774 2890 3353 1111 335 1328 1203 703 2798 2986 3738 2652 2401 1400 1490 1852 3297 888 3539 1854 3308 929 3702 2505 1815 3151 304 1203 702 2795 2976 3699 2495 1776 2995 3773 2792 2963 3647 2288 945 3765 2759 2832 3121 183 719 2864 3249 696 2771 2880 3315 957 3816 2963 3648 2289 952 3794 2875 3293 872 3474 1596 2273 888 3539 1856 3313 952 3796 2881 3317 968 3859 3136 244 961 3829 3016 3857 3128 211 832 3315 959 3823 2989 3749 2694 2569 2071 80 307 1213 741 2949 3591 2063 48 179 703 2798 2987 3742 2667 2463 1647 2479 1712 2739 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 187 (id = 187)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-5260
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 1967 3757 2725 2696 2580 2114 252 994 3964 3554 1913 3542 1865 3349 1094 265 1046 76 292 1156 515 2047 4078 4010 3738 2652 2402 1403 1502 1898 3482 1626 2394 1372 1378 1401 1494 1865 3349 1095 270 1067 160 625 2486 1739 2845 3173 392 1553 2103 205 808 3219 574 2284 931 3709 2536 1940 3650 2300 996 3972 3587 2045 4072 3987 3646 2284 932 3715 2559 2032 4020 3779 2815 3054 4010 3738 2650 2394 1371 1376 1394 1468 1764 2947 3583 2032 4019 3775 2800 2996 3779 2815 3054 4010 3738 2650 2396 1378 1403 1504 1907 3519 1774 2987 3743 2671 2477 1704 2707 2622 2284 929 3704 2513 1847 3277 808 3220 578 2299 992 3953 3510 1739 2847 3184 434 1724 2786 2939 3550 1899 3488 1650 2489 1751 2893 3368 1172 579 2303 1008 4020 3778 2812 3041 3958 3532 1827 3198 491 1950 3692 2468 1666 2556 2020 3969 3574 1995 3869 3176 404 1604 2306 1020 4068 3971 3584 2034 4027 3807 2925 3496 1683 2621 2279 911 3630 2219 670 2666 2458 1628 2404 1410 1532 2019 3966 3564 1956 3714 2556 2018 3961 3543 1871 3374 1195 670 2666 2459 1631 2416 1460 1730 2811 3040 3953 3510 1740 2852 3202 508 2020 3970 3580 2018 3963 3549 1893 3461 1544 2066 57 215 846 3370 1180 609 2421 1480 1812 3139 256 1012 4035 3837 3048 3988 3652 2308 1027 4094 4075 3999 3695 2477 1704 2705 2614 2250 796 3172 386 1531 2013 3944 3476 1604 2306 1017 4053 3909 3335 1037 40 148 578 2300 996 3969 3574 1996 3873 3190 457 1814 3146 283 1118 363 1440 1652 2499 1791 3054 4012 3747 2686 2539 1950 3691 2462 1644 2465 1654 2508 1828 3204 515 2046 4074 3993 3670 2379 1311 1135 432 1716 2754 2812 3043 3966 3562 1948 3682 2426 1500 1890 3449 1496 1876 3395 1280 1012 4033 3831 3021 3880 3219 573 2279 910 3626 2202 604 2402 1403 1503 1901 3496 1681 2614 2250 793 3160 339 1344 1266 955 3808 2932 3523 1791 3053 4008 3732 2625 2294 971 3869 3175 398 1579 2206 619 2462 1642 2460 1636 2433 1528 2001 3893 3271 782 3115 160 627 2494 1772 2977 3702 2507 1822 3180 419 1662 2539 1952 3697 2486 1740 2849 3190 459 1822 3179 416 1650 2491 1759 2925 3496 1684 2626 2297 984 3922 3388 1251 894 3562 1948 3682 2428 1507 1918 3564 1954 3706 2523 1887 3437 1447 1677 2597 2181 519 2061 40 147 574 2284 930 3706 2522 1883 3422 1388 1443 1662 2539 1949 3686 2442 1561 2134 331 1311 1134 427 1696 2676 2500 1796 3076 4097 4088 4051 3903 3311 942 3754 2715 2653 2408 1427 1598 2282 923 3678 2411 1437 1638 2441 1560 2130 316 1252 899 3582 2028 4004 3715 2559 2029 4008 3732 2626 2297 983 3917 3368 1172 577 2293 968 3858 3130 219 861 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 656 (id = 656)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-6135
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 3064 4051 3901 3304 916 3649 2296 980 3905 3320 979 3901 3304 915 3646 2283 928 3697 2488 1747 2880 3316 963 3840 3057 4022 3788 2852 3204 513 2040 4050 3900 3299 893 3560 1940 3650 2300 996 3969 3573 1989 3847 3087 45 166 651 2590 2155 415 1647 2479 1709 2728 2708 2625 2296 977 3895 3280 820 3268 771 3072 4083 4029 3815 2959 3630 2218 667 2655 2415 1455 1709 2725 2696 2579 2112 243 960 3828 3011 3839 3053 4008 3729 2615 2255 814 3244 675 2688 2546 1980 3812 2946 3580 2019 3965 3559 1934 3625 2199 589 2343 1167 560 2228 708 2817 3062 4044 3875 3198 490 1948 3681 2421 1480 1809 3126 204 804 3201 501 1989 3848 3089 53 197 774 3082 26 92 353 1398 1482 1819 3167 366 1451 1695 2671 2480 1716 2756 2817 3063 4045 3880 3217 565 2245 775 3085 37 136 531 2111 239 942 3754 2714 2649 2389 1352 1298 1082 218 857 3414 1356 1315 1150 489 1944 3668 2371 1277 997 3976 3603 2109 232 916 3649 2296 980 3906 3324 993 3958 3531 1823 3184 433 1720 2772 2883 3326 1004 4004 3716 2561 2037 4040 3857 3125 200 788 3140 260 1026 4090 4060 3939 3455 1519 1965 3752 2705 2614 2252 801 3192 466 1852 3298 892 3556 1924 3586 2043 4061 3944 3473 1592 2257 824 3283 831 3309 933 3717 2567 2062 44 161 631 2510 1833 3222 585 2326 1099 286 1131 415 1645 2472 1681 2614 2250 793 3158 332 1315 1151 494 1961 3734 2636 2340 1154 508 2019 3967 3565 1959 3726 2604 2212 644 2563 2045 4071 3983 3631 2221 680 2708 2627 2301 998 3979 3613 2150 395 1567 2159 429 1703 2703 2605 2215 653 2598 2188 547 2175 493 1959 3726 2603 2206 619 2464 1650 2491 1758 2922 3483 1632 2417 1462 1740 2850 3196 484 1921 3576 2003 3902 3306 923 3678 2409 1429 1605 2309 1031 14 44 164 641 2549 1992 3859 3134 235 928 3697 2488 1748 2883 3328 1011 4029 3816 2963 3645 2280 915 3648 2292 964 3841 3064 4051 3901 3304 916 3649 2296 980 3905 3320 979 3901 3304 916 3650 2299 992 3953 3510 1739 2848 3188 449 1782 3019 3870 3178 412 1635 2429 1512 1937 3639 2254 809 3223 589 2341 1160 531 2110 235 927 3696 2483 1728 2803 3008 3827 3005 3816 2963 3647 2288 947 3774 2795 2975 3694 2476 1700 2690 2556 2019 3968 3572 1988 3843 3071 4079 4013 3751 2701 2600 2195 573 2280 915 3647 2286 940 3748 2692 2563 2047 4079 4015 3760 2740 2755 2815 3056 4020 3779 2815 3056 4019 3776 2804 3009 3832 3027 3903 3311 943 3759 2734 2732 2724 2691 2559 2030 4012 3747 2688 2545 1975 3792 2865 3255 718 2860 3234 634 2523 1887 3439 1454 1706 2715 2656 2419 1470 1771 2976 3700 2499 1791 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 22 (id = 22)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-5261
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 49 181 709 2824 3089 53 200 785 3127 207 815 3247 685 2727 2704 2611 2238 748 2979 3711 2542 1963 3741 2664 2452 1604 2305 1015 4047 3888 3252 706 2811 3040 3955 3519 1773 2983 3727 2605 2214 652 2596 2178 508 2017 3960 3539 1853 3301 904 3604 2116 259 1024 4081 4024 3796 2881 3320 979 3902 3308 930 3706 2523 1885 3431 1423 1584 2228 708 2820 3074 4092 4068 3970 3580 2019 3967 3567 1965 3750 2699 2591 2158 428 1700 2690 2555 2016 3953 3512 1747 2878 3308 932 3713 2551 2000 3892 3267 768 3057 4023 3792 2866 3257 725 2885 3335 1040 52 195 767 3053 4007 3725 2597 2184 530 2106 219 861 3432 1427 1600 2290 956 3810 2939 3551 1904 3508 1731 2816 3057 4024 3796 2884 3331 1024 4081 4024 3796 2884 3331 1024 4081 4022 3788 2851 3199 493 1959 3727 2606 2217 663 2640 2356 1219 765 3045 3976 3603 2110 236 929 3703 2511 1839 3246 684 2721 2677 2504 1810 3130 219 861 3430 1419 1566 2156 419 1661 2535 1935 3629 2215 655 2608 2228 707 2813 3045 3976 3603 2110 236 931 3711 2543 1968 3762 2748 2787 2943 3567 1966 3756 2724 2691 2559 2031 4013 3751 2703 2607 2222 683 2720 2674 2492 1761 2935 3535 1837 3239 655 2607 2222 684 2721 2679 2511 1838 3241 663 2640 2356 1219 768 3058 4028 3811 2941 3560 1938 3644 2275 894 3562 1947 3677 2408 1427 1599 2288 947 3774 2793 2967 3663 2351 1199 688 2737 2743 2767 2861 3239 653 2598 2188 545 2165 456 1811 3133 232 915 3645 2279 912 3633 2231 718 2858 3227 606 2410 1435 1629 2405 1416 1554 2107 223 880 3507 1727 2797 2982 3724 2595 2175 495 1968 3761 2741 2760 2836 3139 254 1001 3991 3664 2354 1211 735 2925 3496 1684 2625 2296 979 3904 3315 957 3815 2959 3629 2214 651 2590 2154 411 1630 2410 1435 1629 2405 1416 1556 2113 247 976 3889 3255 720 2868 3267 765 3045 3975 3598 2089 151 589 2341 1160 529 2103 207 815 3248 691 2752 2803 3007 3824 2993 3768 2772 2882 3324 993 3957 3528 1810 3130 219 864 3441 1464 1748 2884 3331 1024 4081 4023 3789 2855 3215 559 2222 684 2724 2690 2556 2017 3957 3527 1807 3120 179 701 2790 2955 3616 2161 440 1747 2878 3308 929 3701 2504 1812 3140 259 1021 4070 3979 3616 2161 439 1742 2858 3227 605 2405 1416 1556 2113 248 980 3905 3319 976 3892 3267 765 3045 3975 3597 2086 139 543 2158 428 1700 2692 2564 2051 4093 4071 3981 3621 2184 531 2110 236 932 3713 2552 2002 3897 3287 845 3365 1159 526 2089 151 589 2341 1159 525 2088 147 575 2285 935 3725 2597 2183 528 2098 187 734 2921 3478 1609 2326 1099 285 1126 396 1572 2179 511 2032 4017 3767 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 295 (id = 295)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-6136
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 12 34 121 470 1868 3364 1154 505 2007 3917 3365 1158 524 2082 123 478 1899 3487 1645 2472 1681 2614 2249 792 3153 312 1233 824 3283 831 3311 943 3758 2730 2713 2646 2378 1307 1119 365 1447 1678 2604 2210 634 2522 1884 3428 1410 1530 2012 3939 3454 1515 1950 3690 2460 1636 2435 1534 2027 3999 3693 2469 1672 2577 2103 207 816 3252 708 2818 3067 4062 3947 3485 1638 2444 1572 2180 515 2045 4069 3973 3590 2060 35 125 485 1925 3591 2061 38 140 545 2165 455 1808 3122 185 726 2890 3354 1116 355 1407 1518 1963 3742 2666 2458 1628 2403 1408 1521 1973 3783 2830 3114 155 605 2406 1419 1565 2152 403 1600 2291 958 3820 2978 3708 2529 1911 3534 1834 3227 608 2419 1469 1765 2950 3596 2082 122 474 1883 3421 1381 1414 1548 2081 120 465 1848 3284 834 3324 995 3968 3572 1986 3836 3042 3961 3541 1861 3336 1042 57 215 848 3378 1211 736 2931 3518 1769 2965 3656 2321 1080 211 829 3302 906 3611 2141 360 1425 1589 2247 782 3115 159 621 2470 1674 2586 2139 352 1393 1461 1734 2826 3100 97 374 1482 1818 3163 352 1396 1476 1794 3068 4068 3970 3579 2015 3951 3502 1708 2724 2692 2561 2038 4042 3866 3162 347 1375 1391 1453 1701 2694 2571 2078 108 418 1657 2518 1865 3351 1102 299 1181 614 2442 1564 2145 374 1484 1825 3190 458 1820 3169 375 1488 1843 3261 741 2952 3601 2101 198 778 3098 91 350 1386 1435 1631 2415 1454 1708 2722 2684 2532 1921 3573 1989 3846 3083 29 102 393 1559 2125 293 1157 518 2058 26 91 352 1394 1465 1751 2895 3373 1189 647 2576 2097 183 719 2864 3249 693 2757 2824 3089 54 202 795 3166 363 1437 1638 2443 1567 2160 435 1726 2794 2970 3674 2395 1374 1386 1434 1628 2404 1409 1528 2001 3894 3276 803 3199 494 1961 3735 2638 2346 1178 603 2397 1384 1425 1590 2251 799 3182 427 1693 2662 2442 1564 2148 385 1525 1989 3846 3083 29 102 396 1570 2172 484 1922 3580 2020 3972 3585 2038 4044 3876 3201 502 1994 3867 3168 369 1464 1747 2878 3308 929 3702 2506 1819 3167 366 1449 1687 2638 2345 1176 595 2365 1253 901 3590 2059 29 101 390 1546 2074 91 350 1387 1440 1652 2497 1781 3016 3857 3128 210 828 3297 886 3531 1823 3184 434 1721 2774 2890 3356 1124 388 1538 2044 4068 3969 3576 2001 3893 3270 780 3105 118 457 1815 3150 298 1180 611 2432 1524 1986 3834 3034 3929 3414 1354 1306 1116 356 1410 1529 2006 3916 3361 1144 467 1854 3308 930 3707 2527 1901 3494 1675 2589 2149 391 1549 2085 134 523 2080 116 451 1792 3059 4032 3825 2997 3782 2827 3103 111 432 1713 2743 2765 2853 3205 517 2053 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 617 (id = 617)
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   guid: train-6137
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   input_ids: 2 1699 2688 2547 1983 3824 2996 3778 2810 3036 3939 3453 1510 1930 3611 2144 369 1462 1738 2843 3167 366 1452 1698 2682 2522 1884 3426 1401 1493 1862 3338 1052 98 379 1503 1902 3498 1690 2650 2393 1365 1351 1293 1064 147 576 2289 950 3787 2848 3187 448 1778 3001 3798 2890 3354 1115 352 1394 1467 1758 2923 3488 1651 2494 1771 2973 3688 2452 1603 2304 1011 4029 3813 2950 3595 2077 103 400 1585 2229 710 2828 3105 117 454 1801 3093 71 272 1076 194 762 3034 3932 3428 1410 1530 2012 3937 3446 1484 1827 3200 497 1976 3794 2876 3297 886 3530 1818 3162 348 1377 1398 1484 1825 3191 464 1841 3256 723 2880 3314 953 3797 2886 3340 1060 131 510 2028 4004 3715 2559 2030 4012 3746 2682 2524 1889 3445 1479 1805 3109 136 530 2107 222 876 3492 1665 2549 1989 3848 3089 53 197 774 3084 35 125 486 1929 3605 2120 275 1086 234 922 3674 2396 1379 1407 1517 1958 3722 2587 2142 363 1437 1639 2447 1584 2228 705 2806 3018 3867 3165 360 1426 1595 2272 882 3515 1757 2919 3470 1579 2205 614 2444 1572 2178 508 2017 3958 3530 1818 3163 350 1387 1437 1639 2446 1578 2204 609 2422 1481 1813 3143 271 1070 170 665 2646 2378 1306 1114 346 1372 1377 1399 1488 1841 3256 724 2884 3332 1025 4085 4037 3846 3082 25 85 326 1289 1048 84 322 1274 988 3938 3449 1494 1866 3356 1121 374 1484 1826 3194 476 1892 3457 1527 2000 3889 3256 722 2875 3296 884 3521 1781 3014 3851 3104 115 445 1768 2961 3639 2255 816 3249 694 2761 2839 3151 301 1192 660 2625 2294 971 3870 3178 412 1635 2431 1517 1958 3723 2591 2158 425 1686 2636 2340 1153 501 1991 3854 3116 163 639 2542 1963 3744 2676 2498 1788 3041 3960 3538 1850 3290 858 3419 1374 1387 1439 1646 2474 1691 2653 2406 1418 1561 2135 333 1320 1169 565 2245 775 3088 52 195 766 3050 3994 3674 2394 1371 1373 1381 1413 1541 2053 6 9 22 76 292 1154 505 2006 3914 3356 1121 374 1481 1813 3142 267 1055 110 428 1697 2678 2505 1814 3148 289 1141 454 1801 3093 69 262 1034 28 99 381 1512 1938 3642 2266 859 3421 1382 1418 1562 2140 353 1398 1484 1827 3198 491 1952 3697 2486 1740 2849 3192 466 1850 3290 858 3418 1371 1374 1385 1429 1606 2315 1053 104 402 1593 2263 846 3372 1185 631 2509 1829 3206 521 2069 69 261 1029 8 17 54 202 795 3166 362 1436 1634 2426 1498 1882 3419 1373 1381 1416 1553 2101 199 782 3114 156 610 2427 1501 1894 3466 1562 2140 354 1401 1494 1865 3352 1106 314 1242 858 3418 1370 1370 1369 1366 1353 1302 1098 284 1122 377 1496 1874 3386 1244 866 3450 1499 3 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 05:13:07 - INFO - transformers.data.processors.glue -   label: 695 (id = 695)
03/13/2022 05:13:33 - INFO - __main__ -   Saving features into cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_train_6-new-12w-0_512_dnageaall
03/13/2022 05:13:37 - INFO - __main__ -   ***** Running training *****
03/13/2022 05:13:37 - INFO - __main__ -     Num examples = 7008
03/13/2022 05:13:37 - INFO - __main__ -     Num Epochs = 5
03/13/2022 05:13:37 - INFO - __main__ -     Instantaneous batch size per GPU = 32
03/13/2022 05:13:37 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
03/13/2022 05:13:37 - INFO - __main__ -     Gradient Accumulation steps = 1
03/13/2022 05:13:37 - INFO - __main__ -     Total optimization steps = 1095
03/13/2022 05:13:37 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step
03/13/2022 05:13:37 - INFO - __main__ -     Continuing training from epoch 0
03/13/2022 05:13:37 - INFO - __main__ -     Continuing training from global step 0
03/13/2022 05:13:37 - INFO - __main__ -     Will skip the first 0 steps in the first epoch
Epoch:   0%|          | 0/5 [00:00<?, ?it/s]
Iteration:   0%|          | 0/219 [00:00<?, ?it/s][A/home/mexposit/cg/gea/dnabert/src/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811701593/work/torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)

Iteration:   0%|          | 1/219 [02:50<10:20:48, 170.86s/it][A
Iteration:   1%|          | 2/219 [05:39<10:12:28, 169.35s/it][A
Iteration:   1%|         | 3/219 [08:27<10:08:06, 168.92s/it][A
Iteration:   2%|         | 4/219 [11:17<10:06:11, 169.17s/it][A
Iteration:   2%|         | 5/219 [14:07<10:04:17, 169.43s/it][A
Iteration:   3%|         | 6/219 [16:56<10:01:31, 169.45s/it][A
Iteration:   3%|         | 7/219 [19:46<9:58:51, 169.49s/it] [A
Iteration:   4%|         | 8/219 [22:35<9:56:29, 169.62s/it][A
Iteration:   4%|         | 9/219 [25:25<9:53:53, 169.68s/it][A
Iteration:   5%|         | 10/219 [28:14<9:49:50, 169.33s/it][A
Iteration:   5%|         | 11/219 [31:03<9:46:20, 169.14s/it][A
Iteration:   5%|         | 12/219 [33:52<9:44:22, 169.38s/it][A
Iteration:   6%|         | 13/219 [36:42<9:41:49, 169.46s/it][A
Iteration:   6%|         | 14/219 [39:32<9:39:28, 169.60s/it][A
Iteration:   7%|         | 15/219 [42:21<9:36:19, 169.51s/it][A
Iteration:   7%|         | 16/219 [45:10<9:33:03, 169.38s/it][A
Iteration:   8%|         | 17/219 [48:00<9:30:07, 169.34s/it][A
Iteration:   8%|         | 18/219 [50:49<9:27:46, 169.49s/it][A
Iteration:   9%|         | 19/219 [53:39<9:24:48, 169.44s/it][A03/13/2022 06:10:05 - INFO - __main__ -   Creating features from dataset file at /home/mexposit/cg/gea/transformers/7_gea500/in_data
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   Writing example 0/656
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   guid: dev-1
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   input_ids: 2 1182 618 2459 1631 2414 1450 1690 2650 2394 1371 1373 1381 1414 1545 2070 74 281 1110 330 1308 1121 373 1480 1811 3133 230 906 3610 2137 342 1355 1309 1128 404 1604 2306 1018 4057 3926 3402 1308 1122 379 1502 1899 3485 1638 2444 1569 2168 467 1856 3316 961 3830 3017 3863 3149 294 1161 534 2122 282 1116 353 1397 1478 1804 3106 121 470 1866 3354 1113 344 1361 1333 1221 773 3077 6 9 21 69 263 1037 37 133 518 2057 24 84 324 1284 1026 4090 4059 3935 3440 1459 1728 2803 3005 3815 2957 3622 2186 538 2139 351 1391 1455 1712 2737 2741 2757 2821 3080 18 60 227 895 3565 1959 3727 2606 2220 673 2679 2512 1842 3259 734 2921 3477 1608 2321 1077 197 775 3087 45 166 650 2585 2134 330 1305 1110 331 1309 1126 396 1569 2167 461 1830 3210 537 2133 327 1295 1070 169 662 2633 2325 1093 261 1029 6 9 24 84 323 1280 1010 4025 3798 2891 3357 1127 400 1585 2232 724 2883 3327 1007 4014 3754 2714 2651 2400 1394 1467 1758 2923 3488 1651 2496 1779 3008 3826 3002 3802 2907 3424 1396 1474 1788 3041 3958 3532 1825 3191 464 1844 3266 764 3041 3957 3525 1797 3079 15 46 171 670 2668 2465 1655 2509 1831 3213 550 2188 547 2173 488 1939 3646 2283 927 3695 2480 1716 2753 2808 3025 3895 3280 820 3266 763 3037 3943 3469 1576 2195 574 2282 924 3682 2427 1502 1900 3490 1657 2517 1864 3347 1088 244 961 3830 3020 3875 3199 496 1972 3780 2817 3064 4051 3901 3304 913 3639 2253 805 3208 531 2111 239 944 3762 2747 2781 2920 3476 1604 2307 1024 4083 4032 3826 3003 3805 2920 3475 1600 2292 964 3842 3068 4066 3962 3548 1892 3459 1536 2036 4036 3842 3068 4066 3963 3552 1908 3524 1796 3075 4094 4076 4004 3715 2558 2026 3993 3669 2375 1294 1065 150 588 2339 1152 500 1987 3837 3046 3979 3613 2152 401 1592 2259 829 3304 913 3638 2250 796 3170 377 1495 1870 3372 1185 632 2513 1848 3282 828 3299 893 3559 1935 3629 2214 649 2582 2124 291 1152 500 1986 3836 3042 3964 3553 1909 3525 1798 3081 23 79 304 1203 701 2791 2957 3624 2193 566 2252 803 3200 498 1977 3797 2888 3348 1089 248 977 3893 3269 773 3078 9 23 79 304 1203 701 2790 2955 3613 2152 404 1603 2304 1011 4031 3821 2982 3722 2587 2144 371 1471 1773 2982 3722 2587 2141 360 1428 1603 2302 1004 4003 3712 2547 1981 3813 2951 3598 2092 162 634 2524 1892 3460 1537 2037 4040 3860 3140 259 1024 4081 4022 3787 2848 3188 450 1788 3043 3968 3572 1988 3843 3071 4078 4011 3742 2666 2459 1632 2419 1470 1769 2966 3658 2329 1111 336 1331 1215 749 2984 3731 2622 2284 3 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   label: 187 (id = 187)
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   Writing example 0/657
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   guid: dev-2
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   input_ids: 2 80 305 1207 718 2859 3229 615 2446 1577 2198 585 2328 1108 324 1281 1016 4049 3895 3279 813 3239 653 2597 2183 528 2100 194 762 3034 3931 3423 1391 1454 1707 2718 2665 2456 1617 2357 1221 774 3081 21 70 266 1050 90 348 1378 1402 1498 1881 3413 1351 1294 1066 154 601 2389 1352 1297 1077 200 788 3137 248 977 3894 3273 790 3145 279 1101 294 1161 534 2124 292 1154 508 2017 3959 3534 1835 3232 627 2496 1780 3012 3844 3073 4086 4044 3874 3196 482 1914 3547 1885 3431 1422 1577 2198 588 2339 1151 496 1972 3777 2808 3028 3905 3318 972 3873 3192 466 1849 3287 845 3367 1168 564 2242 763 3038 3945 3478 1612 2337 1143 464 1841 3254 716 2852 3203 512 2033 4024 3796 2881 3320 977 3893 3269 773 3077 7 13 37 134 524 2083 127 493 1959 3726 2604 2210 635 2527 1901 3494 1676 2593 2165 455 1805 3112 148 578 2300 996 3972 3588 2052 4100 4099 4095 4079 4015 3758 2731 2719 2671 2478 1708 2721 2679 2511 1838 3243 670 2668 2465 1655 2511 1838 3243 671 2669 2472 1684 2627 2303 1007 4013 3752 2706 2619 2271 877 3493 1669 2568 2068 68 257 1013 4038 3851 3103 110 428 1697 2680 2515 1853 3304 913 3639 2253 807 3215 558 2220 674 2682 2523 1886 3436 1441 1653 2501 1799 3087 46 172 673 2680 2516 1857 3317 968 3857 3128 212 835 3327 1007 4015 3758 2732 2723 2688 2547 1983 3822 2988 3745 2680 2516 1858 3324 996 3972 3587 2048 4083 4031 3822 2987 3742 2665 2453 1608 2323 1087 238 940 3745 2680 2516 1860 3332 1025 4086 4041 3864 3153 311 1230 811 3229 613 2440 1556 2115 255 1006 4012 3745 2680 2513 1847 3279 815 3246 682 2715 2653 2406 1419 1567 2157 424 1684 2628 2305 1016 4049 3895 3279 814 3243 669 2664 2451 1599 2287 943 3759 2733 2728 2707 2621 2280 913 3640 2260 833 3320 980 3905 3320 979 3902 3308 930 3708 2531 1917 3560 1938 3644 2276 900 3585 2037 4040 3859 3135 239 942 3754 2715 2656 2417 1463 1744 2867 3263 750 2986 3739 2653 2407 1423 1584 2225 695 2767 2862 3243 669 2661 2440 1553 2101 199 784 3124 194 762 3035 3935 3439 1454 1707 2718 2666 2458 1628 2403 1407 1518 1962 3739 2655 2416 1457 1720 2772 2884 3331 1021 4072 3986 3641 2263 846 3372 1187 638 2537 1942 3660 2337 1141 455 1806 3116 164 641 2551 2000 3889 3253 709 2821 3080 20 67 253 1000 3986 3644 2273 888 3540 1859 3327 1006 4012 3748 2692 2562 2041 4055 3919 3375 1199 685 2725 2696 2579 2110 235 925 3686 2443 1567 2160 433 1720 2769 2870 3276 802 3195 478 1900 3492 1668 2564 2051 4093 4070 3979 3616 2161 440 1748 2884 3331 1023 3 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   label: 451 (id = 451)
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   guid: dev-657
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   input_ids: 2 4032 3825 3000 3796 2883 3328 1012 4035 3840 3060 4035 3840 3060 4033 3832 3027 3904 3316 964 3844 3075 4093 4071 3984 3636 2244 772 3075 4096 4081 4021 3784 2836 3139 253 1000 3987 3648 2291 960 3827 3005 3816 2963 3648 2289 951 3790 2859 3231 623 2480 1715 2751 2799 2992 3763 2751 2800 2995 3776 2803 3008 3827 3006 3818 2971 3680 2419 1470 1770 2970 3674 2394 1369 1366 1353 1304 1108 324 1283 1023 4080 4019 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2798 2987 3744 2675 2495 1773 2982 3721 2581 2117 261 1032 20 65 245 965 3847 3086 42 154 603 2400 1396 1473 1784 3027 3904 3315 960 3827 3007 3824 2995 3774 2795 2974 3692 2465 1654 2506 1820 3172 387 1534 2028 4003 3711 2544 1971 3775 2800 2995 3773 2791 2959 3630 2219 670 2667 2463 1648 2483 1727 2798 2987 3744 2675 2495 1775 2991 3760 2739 2751 2799 2991 3760 2739 2751 2799 2991 3758 2731 2720 2675 2495 1775 2991 3760 2739 2751 2799 2991 3760 2739 2751 2799 2991 3760 2739 2751 2798 2988 3748 2691 2560 2035 4032 3827 3008 3827 3007 3823 2991 3759 2735 2735 2735 2735 2735 2735 2735 2735 2735 2735 2735 2736 2739 2751 2799 2991 3759 2733 2726 2699 2592 2163 446 1772 2979 3709 2535 1933 3621 2181 517 2054 9 21 70 266 1049 85 325 1285 1029 5 6 9 21 69 262 1033 21 69 262 1033 23 77 293 1157 517 2054 10 28 100 388 1540 2052 4098 4092 4068 3972 3588 2049 4088 4052 3908 3332 1028 4100 4100 4100 4097 4088 4049 3894 3276 804 3204 516 2049 4088 4049 3896 3282 828 3297 885 3528 1811 3133 232 913 3637 2247 784 3122 188 740 2948 3588 2051 4094 4075 3997 3687 2447 1582 2219 672 2673 2487 1743 2861 3238 652 2596 2178 505 2005 3910 3337 1048 83 320 1265 950 3788 2849 3191 462 1833 3221 582 2313 1047 80 306 1209 728 2897 3382 1228 802 3193 471 1870 3372 1187 639 2541 1957 3720 2578 2105 216 852 3393 1269 965 3848 3090 59 223 879 3501 1702 2697 2581 2120 276 1090 251 989 3942 3468 1570 2169 471 1870 3372 1188 644 2563 2045 4070 3977 3605 2118 268 1059 127 493 1960 3732 2627 2304 1012 4036 3843 3071 4077 4006 3722 2586 2137 343 1359 1328 1202 699 2781 2918 3466 1564 2145 375 1488 1842 3259 733 2917 3462 1545 2072 84 324 1284 1028 4099 4096 4082 4025 3799 2894 3370 1180 612 2435 1533 2022 3977 3606 2124 289 1142 457 1815 3149 295 1166 554 2204 609 2422 1484 1826 3193 471 1870 3372 1187 639 2541 1957 3720 2578 2108 228 900 3587 2045 4072 3986 3642 2266 857 3415 1359 1328 1202 697 2773 2885 3334 1033 23 78 299 1183 3 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   label: 1078 (id = 1078)
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   guid: dev-658
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   input_ids: 2 233 917 3653 2312 1044 67 253 998 3979 3615 2157 424 1683 2621 2277 904 3601 2103 208 818 3259 735 2928 3507 1727 2799 2990 3756 2723 2686 2539 1950 3691 2463 1648 2484 1729 2806 3018 3867 3168 371 1471 1773 2982 3724 2596 2178 508 2020 3971 3584 2033 4022 3788 2852 3202 508 2020 3969 3576 2004 3906 3324 995 3965 3557 1927 3598 2092 164 641 2550 1995 3869 3175 400 1585 2230 713 2839 3152 305 1205 710 2828 3106 121 471 1871 3373 1191 655 2608 2228 708 2819 3069 4070 3980 3619 2174 492 1953 3702 2505 1816 3155 319 1262 938 3739 2656 2419 1471 1773 2982 3723 2590 2156 419 1661 2535 1935 3629 2215 655 2607 2222 683 2719 2670 2476 1700 2690 2556 2020 3971 3584 2036 4034 3836 3043 3965 3559 1933 3622 2188 547 2174 492 1956 3715 2559 2031 4014 3756 2721 2678 2508 1825 3190 459 1821 3176 403 1597 2279 911 3630 2220 674 2681 2518 1867 3359 1134 428 1699 2687 2541 1957 3717 2566 2057 22 74 284 1121 376 1489 1847 3280 820 3266 764 3042 3964 3554 1913 3541 1862 3338 1050 92 355 1405 1510 1929 3608 2130 313 1238 842 3354 1115 351 1391 1454 1708 2724 2690 2555 2015 3949 3495 1680 2609 2229 710 2827 3104 115 447 1773 2983 3725 2599 2192 561 2232 723 2880 3314 955 3806 2923 3487 1645 2470 1674 2588 2148 386 1529 2007 3917 3366 1162 540 2145 373 1477 1799 3088 52 195 768 3058 4028 3812 2948 3587 2045 4070 3978 3611 2142 363 1439 1645 2471 1680 2611 2238 748 2979 3710 2540 1956 3716 2561 2039 4046 3883 3229 614 2441 1559 2126 299 1182 618 2458 1627 2398 1385 1431 1614 2348 1188 641 2552 2001 3894 3273 792 3155 319 1261 934 3723 2591 2158 428 1698 2684 2531 1918 3564 1956 3716 2562 2044 4065 3957 3525 1798 3082 27 94 361 1430 1612 2337 1143 463 1838 3241 661 2632 2322 1083 223 880 3507 1727 2800 2996 3779 2816 3060 4035 3838 3050 3996 3684 2434 1531 2013 3944 3475 1600 2290 956 3810 2940 3554 1916 3556 1922 3579 2015 3950 3499 1693 2662 2441 1559 2127 304 1204 706 2812 3041 3958 3532 1825 3190 459 1821 3174 395 1566 2154 410 1625 2390 1356 1316 1155 511 2030 4010 3739 2656 2419 1471 1773 2982 3722 2587 2141 359 1422 1578 2203 606 2409 1430 1611 2336 1139 446 1771 2975 3695 2478 1708 2724 2690 2556 2018 3963 3552 1907 3517 1767 2957 3621 2181 518 2057 22 76 289 1144 468 1858 3324 993 3959 3533 1832 3218 571 2270 875 3488 1652 2500 1795 3069 4070 3979 3615 2160 434 1724 2785 2936 3539 1854 3308 932 3713 2552 2001 3894 3276 803 3198 491 1949 3685 2440 1556 2113 248 979 3901 3304 913 3638 2252 804 3201 3 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   label: 131 (id = 131)
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   guid: dev-3
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3742 2666 2459 1632 2419 1470 1769 2966 3658 2329 1111 336 1331 1215 749 2984 3731 2623 2287 941 3749 2696 2579 2110 233 919 3663 2349 1190 652 2593 2166 457 1813 3144 274 1081 213 840 3346 1081 213 838 3337 1046 74 281 1109 328 1300 1090 249 983 3920 3378 1212 740 2945 3576 2004 3906 3322 986 3930 3417 1367 1358 1322 1180 611 2430 1514 1946 3673 2389 1349 1285 1029 5 7 15 46 171 671 2671 2477 1703 2701 2599 2191 558 2219 671 2671 2479 1711 2734 2732 2721 2677 2503 1807 3118 172 673 2677 2501 1799 3085 38 137 533 2117 261 1030 12 33 117 454 1804 3107 125 485 1926 3594 2076 98 378 1500 1890 3450 1500 1890 3450 1497 1877 3399 1294 1066 156 610 2426 1498 1881 3414 1354 1308 1123 381 1512 1939 3646 2282 921 3670 2377 1301 1094 268 1060 130 506 2009 3927 3405 1317 1157 518 2057 21 69 264 1043 61 229 902 3593 2072 83 317 1254 907 3613 2151 397 1573 2181 518 2058 26 91 349 1383 1421 1573 2181 518 2057 21 69 264 1043 61 230 906 3610 2138 346 1370 1370 1371 1373 1383 1422 1580 2211 637 2534 1930 3611 2142 361 1432 1618 2362 1244 866 3452 1508 1922 3578 2010 3932 3426 1403 1503 1901 3493 1669 2567 2062 43 157 614 2443 1565 2149 390 1548 2082 121 470 1867 3358 1130 409 1622 2380 1316 1154 505 2007 3918 3372 1186 633 2517 1863 3342 1068 161 632 2515 1854 3305 917 3655 2317 1062 137 533 2119 271 1071 176 692 2756 2817 3064 4052 3906 3321 983 3919 3375 1199 688 2738 2746 2778 2907 3422 1386 1434 1627 2398 1386 1433 1621 2373 1287 1038 42 154 603 2398 1387 1438 1643 2461 1640 2450 1595 2270 875 3486 1644 2465 1656 2516 1858 3323 990 3947 3488 1649 2485 1733 2822 3083 29 103 400 1585 2232 724 2883 3326 1002 3995 3680 2417 1463 1743 2863 3247 686 2732 2722 2684 2532 1921 3575 1999 3885 3240 657 2614 2252 803 3199 495 1965 3752 2707 2622 2281 920 3666 2364 1252 899 3583 2030 4010 3738 2651 2398 1387 1439 1645 2472 1683 2623 2287 943 3758 2731 2717 2664 2449 1590 2252 804 3203 509 2023 3981 3624 2193 565 2247 782 3113 151 589 2341 1157 519 2063 47 175 685 2728 2707 2621 2278 908 3619 2173 487 1934 3627 2206 620 2468 1667 2559 2030 4012 3745 2677 2504 1810 3132 227 895 3566 1964 3748 2689 2552 2001 3896 3282 828 3299 894 3564 1956 3714 2556 2018 3961 3543 1871 3375 1199 685 2727 2703 2606 2220 675 2685 2534 1930 3611 2142 364 1444 1668 2561 2037 4039 3854 3116 162 633 2520 1874 3386 1242 859 3423 1391 1454 1705 2712 2642 2363 1247 879 3503 1711 2733 2726 3 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   label: 724 (id = 724)
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   guid: dev-659
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   input_ids: 2 1518 1962 3739 2654 2412 1443 1664 2546 1979 3807 2928 3508 1730 2811 3040 3953 3510 1739 2845 3176 404 1604 2305 1016 4052 3905 3318 969 3862 3147 288 1140 452 1796 3073 4085 4040 3857 3125 199 781 3112 146 569 2262 844 3362 1147 480 1905 3512 1747 2878 3305 918 3658 2330 1114 346 1370 1372 1377 1399 1486 1834 3225 599 2382 1324 1188 644 2564 2049 4086 4043 3869 3173 392 1555 2111 238 940 3745 2678 2506 1820 3172 388 1537 2040 4049 3893 3269 773 3078 9 21 69 261 1030 9 22 74 281 1110 329 1302 1098 282 1114 345 1367 1358 1324 1188 641 2550 1996 3873 3189 454 1802 3100 98 378 1498 1882 3417 1368 1362 1337 1239 847 3374 1193 664 2641 2357 1222 780 3107 125 486 1932 3617 2167 463 1837 3237 645 2565 2054 11 31 111 430 1706 2713 2645 2375 1296 1074 188 737 2936 3538 1850 3290 858 3419 1376 1394 1466 1755 2911 3437 1447 1678 2604 2209 632 2515 1856 3314 955 3805 2920 3473 1591 2255 815 3247 688 2738 2745 2776 2897 3381 1221 773 3080 17 54 203 797 3173 389 1544 2068 65 246 971 3870 3178 411 1630 2410 1436 1633 2424 1489 1846 3275 799 3182 426 1690 2650 2394 1370 1370 1371 1374 1388 1443 1664 2547 1984 3826 3001 3797 2886 3339 1054 108 419 1662 2540 1955 3710 2538 1948 3683 2429 1509 1925 3591 2061 37 133 517 2053 5 5 7 15 45 167 655 2608 2227 702 2793 2967 3663 2349 1192 659 2624 2292 962 3836 3044 3970 3578 2010 3932 3426 1402 1498 1884 3427 1407 1520 1972 3777 2806 3019 3869 3173 392 1553 2104 211 830 3305 919 3663 2349 1189 647 2574 2091 158 618 2458 1626 2394 1371 1375 1392 1457 1717 2760 2836 3138 249 981 3911 3342 1068 164 643 2558 2026 3995 3677 2408 1427 1597 2280 913 3640 2259 832 3315 957 3816 2961 3638 2249 791 3151 301 1189 645 2566 2057 23 78 300 1186 635 2527 1902 3498 1691 2654 2409 1432 1618 2364 1250 889 3544 1875 3391 1264 946 3769 2776 2898 3386 1241 856 3412 1347 1279 1005 4007 3727 2605 2215 654 2602 2203 605 2405 1416 1553 2101 199 782 3115 158 620 2466 1657 2520 1875 3389 1255 911 3632 2227 703 2798 2985 3735 2637 2342 1161 535 2127 302 1195 672 2675 2494 1771 2974 3692 2467 1662 2537 1941 3654 2315 1055 110 428 1698 2682 2521 1879 3407 1325 1192 658 2620 2276 899 3582 2028 4003 3710 2540 1955 3711 2541 1960 3730 2620 2276 899 3584 2033 4022 3785 2837 3144 274 1083 224 882 3516 1762 2939 3550 1898 3481 1623 2383 1328 1204 708 2818 3066 4060 3940 3457 1527 1998 3883 3229 613 2440 1553 2103 208 817 3254 713 2840 3154 314 1241 3 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   label: 1106 (id = 1106)
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   guid: dev-4
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3022 3884 3234 634 2524 1892 3457 1526 1996 3873 3191 463 1837 3240 657 2615 2256 818 3258 730 2907 3422 1385 1429 1607 2319 1070 170 665 2646 2379 1311 1134 427 1694 2666 2458 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1386 1434 1627 2398 1385 1429 1606 2314 1050 89 341 1349 1288 1043 63 237 935 3725 2597 2183 525 2087 141 551 2189 549 2183 527 2093 165 647 2573 2087 141 551 2189 552 2193 568 2257 824 3281 821 3269 776 3089 53 197 774 3084 35 125 485 1925 3589 2053 6 11 30 107 414 1643 2463 1648 2482 1724 2787 2941 3560 1940 3652 2305 1015 4045 3877 3205 520 2065 56 212 835 3327 1006 4010 3738 2649 2389 1351 1295 1069 166 652 2596 2178 508 2019 3966 3562 1948 3682 2426 1497 1877 3399 1296 1075 190 746 2970 3675 2398 1388 1441 1653 2504 1811 3134 234 922 3673 2391 1359 1325 1192 659 2622 2281 919 3661 2341 1160 530 2106 220 868 3460 1537 2039 4046 3882 3226 604 2404 1409 1528 2001 3895 3279 813 3240 657 2613 2248 788 3138 249 984 3921 3383 1229 808 3220 580 2307 1023 4080 4017 3765 2760 2833 3128 211 831 3310 940 3747 2688 2547 1983 3822 2988 3748 2692 2564 2051 4095 4080 4019 3774 2794 2972 3684 2434 1531 2015 3949 3496 1683 2623 2286 940 3748 2690 2556 2018 3961 3544 1875 3391 1262 940 3748 2692 2562 2044 4066 3963 3552 1907 3518 1772 2980 3716 2562 2044 4066 3964 3556 1922 3580 2017 3957 3527 1807 3119 173 680 2705 2615 2253 807 3213 550 2187 541 2151 397 1575 2190 556 2210 636 2532 1921 3574 1994 3865 3158 330 1306 1115 351 1390 1450 1690 2650 2394 1369 1365 1349 1285 1032 17 56 211 832 3313 949 3782 2828 3105 118 457 1814 3148 290 1145 470 1867 3357 1128 401 1592 2257 824 3283 831 3312 947 3776 2802 3003 3806 2924 3491 1662 2539 1949 3687 2448 1587 2237 744 2964 3649 2295 973 3879 3214 554 2202 604 2401 1400 1489 1848 3281 821 3271 781 3110 138 540 2145 374 1484 1827 3197 488 1938 3643 2270 876 3490 1658 2523 1888 3444 1473 1784 3028 3905 3317 965 3845 3077 6 12 33 117 453 1799 3085 39 143 557 2216 657 2613 2245 773 3079 16 50 186 730 2906 3418 1372 1378 1402 1498 1881 3413 1349 1287 1038 42 153 598 2379 1309 1125 392 1554 2107 221 872 3475 1597 2277 903 3599 2093 165 647 2573 2085 135 527 2095 173 3 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   label: 896 (id = 896)
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   guid: dev-660
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   input_ids: 2 886 3532 1825 3190 460 1825 3192 468 1859 3326 1001 3991 3662 2348 1187 638 2540 1953 3703 2510 1835 3230 619 2461 1637 2439 1549 2086 138 539 2142 361 1431 1614 2347 1183 622 2475 1695 2669 2469 1669 2565 2053 5 8 17 53 200 785 3128 209 821 3269 776 3092 66 249 984 3921 3381 1224 785 3127 207 815 3247 685 2725 2696 2580 2113 247 974 3882 3226 603 2399 1390 1450 1691 2653 2408 1425 1589 2246 778 3100 99 382 1513 1941 3656 2322 1082 218 858 3418 1370 1372 1377 1400 1490 1851 3293 870 3468 1571 2174 492 1954 3708 2530 1914 3546 1881 3416 1362 1337 1237 838 3337 1048 81 309 1223 782 3115 158 618 2460 1635 2430 1514 1948 3683 2430 1514 1946 3676 2403 1406 1513 1942 3658 2330 1113 343 1357 1319 1167 557 2215 653 2597 2181 520 2068 65 245 965 3845 3077 8 19 62 236 931 3709 2535 1934 3628 2211 638 2537 1942 3657 2327 1101 293 1160 529 2101 197 773 3078 10 25 86 332 1316 1153 501 1989 3845 3077 6 9 22 74 282 1116 353 1398 1484 1826 3193 470 1865 3352 1106 316 1251 895 3566 1962 3740 2657 2423 1486 1833 3224 593 2360 1233 822 3275 797 3174 393 1557 2118 267 1053 104 403 1599 2285 934 3721 2583 2127 301 1191 653 2598 2186 538 2140 354 1401 1496 1873 3384 1236 834 3322 986 3930 3417 1367 1358 1322 1180 611 2430 1514 1946 3673 2389 1349 1285 1029 5 7 15 46 171 671 2671 2477 1703 2701 2599 2191 558 2219 671 2671 2479 1711 2734 2732 2721 2677 2503 1807 3118 172 673 2677 2501 1799 3085 38 137 533 2117 261 1030 12 33 117 454 1804 3107 125 485 1926 3594 2076 98 378 1500 1890 3450 1500 1890 3450 1497 1877 3399 1294 1066 156 610 2426 1498 1881 3414 1354 1308 1123 381 1512 1939 3646 2282 921 3670 2377 1301 1094 268 1060 130 506 2009 3927 3405 1317 1157 518 2057 21 69 264 1043 61 229 902 3593 2072 83 317 1254 907 3613 2151 397 1573 2181 518 2058 26 91 349 1383 1421 1573 2181 518 2057 21 69 264 1043 61 230 906 3610 2138 346 1370 1370 1371 1373 1383 1422 1580 2211 637 2534 1930 3611 2142 361 1432 1618 2362 1244 866 3452 1508 1922 3578 2010 3932 3426 1403 1503 1901 3493 1669 2567 2062 43 157 614 2443 1565 2149 390 1548 2082 121 470 1867 3358 1130 409 1622 2379 1309 1126 396 1570 2171 478 1900 3492 1665 2550 1995 3871 3181 423 1678 2601 2200 593 2357 1224 788 3139 255 1006 4011 3744 2673 2488 1748 2882 3323 992 3953 3511 1743 2862 3244 675 2685 2536 1939 3647 2285 933 3720 2579 2110 234 922 3676 2403 1408 1522 1977 3 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   label: 426 (id = 426)
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   guid: dev-5
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   input_ids: 2 1812 3140 259 1021 4069 3974 3595 2077 104 403 1598 2284 930 3706 2524 1891 3455 1519 1968 3762 2747 2782 2923 3485 1639 2446 1580 2212 642 2556 2017 3957 3525 1797 3080 17 53 197 773 3077 7 15 45 167 655 2607 2222 684 2724 2691 2560 2035 4031 3823 2989 3749 2694 2569 2071 80 307 1213 741 2949 3591 2063 48 179 703 2798 2987 3742 2667 2463 1647 2479 1712 2739 2752 2803 3008 3826 3002 3804 2916 3459 1535 2032 4017 3766 2762 2843 3165 358 1418 1561 2133 326 1292 1059 125 488 1939 3646 2284 932 3715 2557 2023 3984 3633 2231 717 2856 3220 578 2298 986 3931 3423 1391 1456 1713 2743 2766 2860 3236 641 2549 1989 3848 3091 64 244 964 3843 3069 4072 3986 3644 2273 888 3539 1856 3315 957 3813 2951 3600 2099 189 741 2950 3594 2073 85 326 1292 1058 121 469 1864 3346 1082 217 856 3411 1342 1259 925 3687 2446 1579 2205 614 2442 1561 2136 340 1347 1277 999 3981 3621 2182 522 2075 94 363 1437 1638 2444 1570 2170 474 1884 3425 1399 1485 1832 3219 574 2282 921 3670 2379 1309 1126 395 1568 2161 439 1742 2860 3235 637 2535 1936 3634 2233 725 2886 3339 1054 105 408 1617 2360 1236 836 3331 1024 4084 4033 3830 3018 3866 3164 354 1403 1503 1902 3497 1687 2638 2347 1181 616 2452 1601 2296 977 3896 3283 832 3314 954 3803 2909 3431 1423 1584 2225 695 2765 2853 3205 519 2061 37 135 525 2088 145 566 2249 789 3141 261 1031 16 49 181 709 2824 3092 67 255 1007 4013 3752 2706 2619 2270 874 3482 1627 2400 1393 1463 1742 2860 3233 632 2515 1855 3310 938 3738 2651 2400 1394 1466 1754 2906 3417 1366 1354 1306 1116 353 1398 1484 1827 3199 494 1963 3741 2661 2440 1555 2110 233 920 3665 2360 1233 824 3282 827 3293 870 3466 1561 2135 335 1327 1199 685 2728 2708 2627 2304 1010 4026 3802 2905 3413 1352 1300 1092 259 1021 4071 3983 3629 2213 646 2569 2069 71 270 1068 163 639 2542 1962 3737 2645 2373 1285 1029 5 5 6 10 25 87 336 1331 1215 751 2991 3760 2739 2751 2799 2990 3756 2723 2687 2541 1959 3726 2603 2205 614 2443 1568 2163 445 1768 2962 3641 2263 846 3372 1186 634 2524 1890 3449 1493 1862 3338 1051 93 358 1418 1561 2133 328 1299 1085 230 906 3611 2142 364 1443 1663 2544 1969 3767 2765 2854 3212 548 2177 501 1992 3859 3135 237 934 3723 2589 2151 397 1573 2181 519 2064 52 195 765 3046 3980 3617 2166 460 1825 3189 455 1807 3118 172 673 2677 2502 1803 3104 115 447 1773 2984 3731 2624 2292 963 3837 3046 3979 3613 2152 403 1597 2279 911 3630 2218 668 2658 2427 1504 1907 3519 3 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   label: 302 (id = 302)
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   *** Example ***
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   guid: dev-661
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   input_ids: 2 1031 16 49 183 720 2868 3267 767 3053 4008 3730 2620 2273 888 3539 1856 3315 960 3827 3008 3826 3001 3797 2886 3337 1047 80 305 1207 718 2859 3229 615 2446 1577 2198 585 2328 1108 324 1283 1024 4081 4021 3782 2826 3100 100 388 1538 2041 4055 3920 3378 1211 735 2927 3502 1705 2712 2644 2371 1279 1006 4011 3743 2669 2469 1669 2565 2053 5 8 19 63 238 939 3743 2670 2475 1693 2663 2446 1577 2199 590 2346 1179 606 2412 1444 1665 2549 1990 3849 3096 83 318 1259 925 3688 2449 1592 2260 835 3327 1008 4017 3768 2772 2883 3328 1012 4035 3839 3054 4011 3744 2676 2499 1791 3054 4011 3742 2668 2467 1661 2534 1929 3605 2117 262 1033 21 69 261 1029 5 5 5 6 10 25 88 338 1339 1245 872 3475 1599 2285 934 3724 2596 2180 516 2051 4096 4084 4033 3832 3025 3893 3270 780 3108 132 515 2048 4084 4033 3829 3015 3854 3116 164 644 2563 2048 4084 4033 3832 3026 3898 3289 856 3412 1348 1284 1027 4096 4084 4036 3841 3062 4044 3876 3204 515 2048 4084 4033 3832 3026 3898 3289 856 3412 1348 1284 1027 4096 4084 4036 3841 3062 4041 3864 3155 318 1257 920 3665 2360 1235 831 3309 936 3729 2615 2253 806 3212 545 2166 457 1813 3144 273 1078 201 791 3149 294 1162 540 2145 374 1484 1825 3192 466 1850 3290 860 3428 1409 1527 1997 3877 3205 519 2063 45 167 653 2597 2183 526 2089 152 593 2357 1222 780 3107 125 488 1938 3644 2273 885 3525 1797 3077 5 5 6 12 35 126 490 1946 3673 2390 1354 1306 1116 354 1404 1505 1909 3525 1798 3082 26 92 354 1404 1505 1910 3532 1827 3198 489 1942 3658 2332 1123 382 1514 1946 3673 2390 1354 1306 1116 354 1401 1493 1863 3343 1069 166 650 2585 2134 329 1301 1096 275 1086 236 931 3709 2533 1926 3593 2069 69 263 1037 37 136 530 2106 219 863 3438 1451 1694 2667 2461 1639 2446 1579 2206 619 2462 1644 2465 1654 2505 1814 3146 283 1117 358 1418 1562 2139 350 1386 1434 1628 2403 1405 1509 1928 3602 2106 217 854 3401 1301 1093 262 1033 23 78 300 1185 629 2502 1801 3093 70 265 1045 72 273 1078 204 801 3191 461 1830 3212 545 2165 455 1806 3113 151 590 2345 1174 585 2327 1104 306 1209 727 2894 3372 1187 638 2537 1944 3665 2360 1233 822 3274 794 3162 347 1375 1389 1447 1677 2599 2190 556 2209 631 2510 1833 3221 581 2309 1032 20 68 258 1019 4062 3948 3489 1656 2516 1860 3329 1014 4043 3870 3179 414 1641 2456 1618 2362 1241 855 3407 1325 1192 657 2616 2258 827 3293 871 3469 1575 2189 549 2183 525 2088 145 567 2256 820 3268 771 3069 3 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/13/2022 06:10:05 - INFO - transformers.data.processors.glue -   label: 68 (id = 68)
03/13/2022 06:10:10 - INFO - __main__ -   Saving features into cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_dev_6-new-12w-0_512_dnageaall
03/13/2022 06:10:11 - INFO - __main__ -   ***** Running evaluation  *****
03/13/2022 06:10:11 - INFO - __main__ -     Num examples = 1313
03/13/2022 06:10:11 - INFO - __main__ -     Batch size = 32


Evaluating:   0%|          | 0/42 [00:00<?, ?it/s][A[A

Evaluating:   2%|         | 1/42 [00:51<35:13, 51.54s/it][A[A

Evaluating:   5%|         | 2/42 [01:43<34:20, 51.51s/it][A[A

Evaluating:   7%|         | 3/42 [02:34<33:27, 51.48s/it][A[A

Evaluating:  10%|         | 4/42 [03:25<32:35, 51.47s/it][A[A

Evaluating:  12%|        | 5/42 [04:17<31:43, 51.44s/it][A[A

Evaluating:  14%|        | 6/42 [05:08<30:51, 51.43s/it][A[A

Evaluating:  17%|        | 7/42 [06:00<29:59, 51.42s/it][A[A

Evaluating:  19%|        | 8/42 [06:51<29:08, 51.41s/it][A[A

Evaluating:  21%|       | 9/42 [07:42<28:17, 51.43s/it][A[A

Evaluating:  24%|       | 10/42 [08:34<27:26, 51.44s/it][A[A

Evaluating:  26%|       | 11/42 [09:25<26:34, 51.43s/it][A[A

Evaluating:  29%|       | 12/42 [10:17<25:42, 51.43s/it][A[A

Evaluating:  31%|       | 13/42 [11:08<24:51, 51.42s/it][A[A

Evaluating:  33%|      | 14/42 [12:00<23:59, 51.42s/it][A[A

Evaluating:  36%|      | 15/42 [12:51<23:07, 51.39s/it][A[A

Evaluating:  38%|      | 16/42 [13:42<22:16, 51.40s/it][A[A

Evaluating:  40%|      | 17/42 [14:34<21:25, 51.42s/it][A[A

Evaluating:  43%|     | 18/42 [15:26<20:37, 51.58s/it][A[A

Evaluating:  45%|     | 19/42 [16:17<19:45, 51.55s/it][A[A

Evaluating:  48%|     | 20/42 [17:09<18:53, 51.51s/it][A[A

Evaluating:  50%|     | 21/42 [18:00<18:01, 51.48s/it][A[A

Evaluating:  52%|    | 22/42 [18:52<17:09, 51.48s/it][A[A

Evaluating:  55%|    | 23/42 [19:43<16:17, 51.45s/it][A[A

Evaluating:  57%|    | 24/42 [20:34<15:25, 51.43s/it][A[A

Evaluating:  60%|    | 25/42 [21:26<14:34, 51.42s/it][A[A

Evaluating:  62%|   | 26/42 [22:17<13:42, 51.42s/it][A[A

Evaluating:  64%|   | 27/42 [23:09<12:51, 51.44s/it][A[A

Evaluating:  67%|   | 28/42 [24:00<11:59, 51.42s/it][A[A

Evaluating:  69%|   | 29/42 [24:51<11:08, 51.42s/it][A[A

Evaluating:  71%|  | 30/42 [25:43<10:16, 51.42s/it][A[A

Evaluating:  74%|  | 31/42 [26:34<09:25, 51.39s/it][A[A

Evaluating:  76%|  | 32/42 [27:26<08:34, 51.41s/it][A[A

Evaluating:  79%|  | 33/42 [28:17<07:42, 51.40s/it][A[A

Evaluating:  81%|  | 34/42 [29:08<06:51, 51.42s/it][A[A

Evaluating:  83%| | 35/42 [30:00<05:59, 51.40s/it][A[A

Evaluating:  86%| | 36/42 [30:51<05:08, 51.41s/it][A[A

Evaluating:  88%| | 37/42 [31:43<04:17, 51.43s/it][A[A

Evaluating:  90%| | 38/42 [32:34<03:25, 51.42s/it][A[A

Evaluating:  93%|| 39/42 [33:26<02:34, 51.42s/it][A[A

Evaluating:  95%|| 40/42 [34:17<01:42, 51.41s/it][A[A

Evaluating:  98%|| 41/42 [35:08<00:51, 51.40s/it][A[A

Evaluating: 100%|| 42/42 [35:10<00:00, 36.40s/it][A[AEvaluating: 100%|| 42/42 [35:10<00:00, 50.24s/it]
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
03/13/2022 06:56:01 - INFO - __main__ -   ***** Eval results  *****
03/13/2022 06:56:01 - INFO - __main__ -     acc = 0.0015232292460015233
03/13/2022 06:56:01 - INFO - __main__ -     auc = 0.5126734530863968
03/13/2022 06:56:01 - INFO - __main__ -     f1 = 0.000979218801000979
03/13/2022 06:56:01 - INFO - __main__ -     mcc = 0.0007750124112295877
03/13/2022 06:56:01 - INFO - __main__ -     precision = 0.0008885503935008886
03/13/2022 06:56:01 - INFO - __main__ -     recall = 0.0015232292460015233
03/13/2022 06:56:01 - INFO - __main__ -     top10acc = 0.010662604722010662
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
03/13/2022 06:56:01 - INFO - transformers.configuration_utils -   Configuration saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-20/config.json
03/13/2022 06:56:02 - INFO - transformers.modeling_utils -   Model weights saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-20/pytorch_model.bin
03/13/2022 06:56:02 - INFO - __main__ -   Saving model checkpoint to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-20
03/13/2022 06:56:04 - INFO - __main__ -   Saving optimizer and scheduler states to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-20

Iteration:   9%|         | 20/219 [1:42:26<55:08:01, 997.39s/it][A
Iteration:  10%|         | 21/219 [1:45:12<41:07:35, 747.75s/it][A
Iteration:  10%|         | 22/219 [1:47:59<31:23:39, 573.70s/it][A
Iteration:  11%|         | 23/219 [1:50:49<24:38:04, 452.47s/it][A
Iteration:  11%|         | 24/219 [1:53:39<19:54:47, 367.63s/it][A
Iteration:  11%|        | 25/219 [1:56:28<16:36:28, 308.19s/it][A
Iteration:  12%|        | 26/219 [1:59:18<14:17:39, 266.63s/it][A
Iteration:  12%|        | 27/219 [2:02:08<12:40:29, 237.65s/it][A
Iteration:  13%|        | 28/219 [2:04:58<11:32:06, 217.41s/it][A
Iteration:  13%|        | 29/219 [2:07:46<10:41:27, 202.57s/it][A
Iteration:  14%|        | 30/219 [2:10:34<10:05:36, 192.26s/it][A
Iteration:  14%|        | 31/219 [2:13:24<9:41:10, 185.48s/it] [A
Iteration:  15%|        | 32/219 [2:16:14<9:23:27, 180.79s/it][A
Iteration:  15%|        | 33/219 [2:19:04<9:10:27, 177.57s/it][A
Iteration:  16%|        | 34/219 [2:21:54<9:00:13, 175.21s/it][A
Iteration:  16%|        | 35/219 [2:24:43<8:51:58, 173.47s/it][A
Iteration:  16%|        | 36/219 [2:27:32<8:44:32, 171.98s/it][A
Iteration:  17%|        | 37/219 [2:30:17<8:35:23, 169.91s/it][A
Iteration:  17%|        | 38/219 [2:33:05<8:31:16, 169.48s/it][A
Iteration:  18%|        | 39/219 [2:35:54<8:28:07, 169.38s/it][A03/13/2022 07:52:20 - INFO - __main__ -   Loading features from cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_dev_6-new-12w-0_512_dnageaall
03/13/2022 07:52:21 - INFO - __main__ -   ***** Running evaluation  *****
03/13/2022 07:52:21 - INFO - __main__ -     Num examples = 1313
03/13/2022 07:52:21 - INFO - __main__ -     Batch size = 32


Evaluating:   0%|          | 0/42 [00:00<?, ?it/s][A[A

Evaluating:   2%|         | 1/42 [00:51<35:07, 51.41s/it][A[A

Evaluating:   5%|         | 2/42 [01:42<34:15, 51.39s/it][A[A

Evaluating:   7%|         | 3/42 [02:34<33:24, 51.39s/it][A[A

Evaluating:  10%|         | 4/42 [03:25<32:31, 51.36s/it][A[A

Evaluating:  12%|        | 5/42 [04:16<31:40, 51.37s/it][A[A

Evaluating:  14%|        | 6/42 [05:08<30:49, 51.38s/it][A[A

Evaluating:  17%|        | 7/42 [05:59<29:57, 51.35s/it][A[A

Evaluating:  19%|        | 8/42 [06:50<29:05, 51.34s/it][A[A

Evaluating:  21%|       | 9/42 [07:42<28:13, 51.33s/it][A[A

Evaluating:  24%|       | 10/42 [08:33<27:23, 51.35s/it][A[A

Evaluating:  26%|       | 11/42 [09:24<26:32, 51.36s/it][A[A

Evaluating:  29%|       | 12/42 [10:16<25:40, 51.33s/it][A[A

Evaluating:  31%|       | 13/42 [11:07<24:48, 51.31s/it][A[A

Evaluating:  33%|      | 14/42 [11:58<23:57, 51.35s/it][A[A

Evaluating:  36%|      | 15/42 [12:50<23:06, 51.35s/it][A[A

Evaluating:  38%|      | 16/42 [13:41<22:16, 51.39s/it][A[A

Evaluating:  40%|      | 17/42 [14:33<21:25, 51.40s/it][A[A

Evaluating:  43%|     | 18/42 [15:24<20:33, 51.39s/it][A[A

Evaluating:  45%|     | 19/42 [16:15<19:42, 51.39s/it][A[A

Evaluating:  48%|     | 20/42 [17:07<18:50, 51.39s/it][A[A

Evaluating:  50%|     | 21/42 [17:58<17:59, 51.40s/it][A[A

Evaluating:  52%|    | 22/42 [18:50<17:07, 51.38s/it][A[A

Evaluating:  55%|    | 23/42 [19:41<16:15, 51.36s/it][A[A

Evaluating:  57%|    | 24/42 [20:32<15:23, 51.32s/it][A[A

Evaluating:  60%|    | 25/42 [21:24<14:32, 51.34s/it][A[A

Evaluating:  62%|   | 26/42 [22:15<13:41, 51.33s/it][A[A

Evaluating:  64%|   | 27/42 [23:06<12:50, 51.34s/it][A[A

Evaluating:  67%|   | 28/42 [23:58<11:58, 51.35s/it][A[A

Evaluating:  69%|   | 29/42 [24:49<11:07, 51.35s/it][A[A

Evaluating:  71%|  | 30/42 [25:40<10:16, 51.38s/it][A[A

Evaluating:  74%|  | 31/42 [26:32<09:24, 51.35s/it][A[A

Evaluating:  76%|  | 32/42 [27:23<08:33, 51.36s/it][A[A

Evaluating:  79%|  | 33/42 [28:14<07:42, 51.37s/it][A[A

Evaluating:  81%|  | 34/42 [29:06<06:51, 51.39s/it][A[A

Evaluating:  83%| | 35/42 [29:57<05:59, 51.37s/it][A[A

Evaluating:  86%| | 36/42 [30:49<05:08, 51.38s/it][A[A

Evaluating:  88%| | 37/42 [31:40<04:16, 51.39s/it][A[A

Evaluating:  90%| | 38/42 [32:31<03:25, 51.37s/it][A[A

Evaluating:  93%|| 39/42 [33:23<02:34, 51.38s/it][A[A

Evaluating:  95%|| 40/42 [34:14<01:42, 51.38s/it][A[A

Evaluating:  98%|| 41/42 [35:05<00:51, 51.38s/it][A[A

Evaluating: 100%|| 42/42 [35:07<00:00, 36.39s/it][A[AEvaluating: 100%|| 42/42 [35:07<00:00, 50.18s/it]
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
03/13/2022 08:38:06 - INFO - __main__ -   ***** Eval results  *****
03/13/2022 08:38:06 - INFO - __main__ -     acc = 0.0015232292460015233
03/13/2022 08:38:06 - INFO - __main__ -     auc = 0.5096972349673992
03/13/2022 08:38:06 - INFO - __main__ -     f1 = 0.00022377109802451529
03/13/2022 08:38:06 - INFO - __main__ -     mcc = 0.0007838513276826677
03/13/2022 08:38:06 - INFO - __main__ -     precision = 0.00013003176490256903
03/13/2022 08:38:06 - INFO - __main__ -     recall = 0.0015232292460015233
03/13/2022 08:38:06 - INFO - __main__ -     top10acc = 0.006854531607006854
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
03/13/2022 08:38:06 - INFO - transformers.configuration_utils -   Configuration saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-40/config.json
03/13/2022 08:38:07 - INFO - transformers.modeling_utils -   Model weights saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-40/pytorch_model.bin
03/13/2022 08:38:07 - INFO - __main__ -   Saving model checkpoint to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-40
03/13/2022 08:38:08 - INFO - __main__ -   Saving optimizer and scheduler states to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-40

Iteration:  18%|        | 40/219 [3:24:31<49:23:43, 993.43s/it][A
Iteration:  19%|        | 41/219 [3:27:16<36:50:30, 745.11s/it][A
Iteration:  19%|        | 42/219 [3:30:04<28:07:15, 571.95s/it][A
Iteration:  20%|        | 43/219 [3:32:53<22:02:45, 450.94s/it][A
Iteration:  20%|        | 44/219 [3:35:42<17:49:05, 366.54s/it][A
Iteration:  21%|        | 45/219 [3:38:32<14:51:46, 307.51s/it][A
Iteration:  21%|        | 46/219 [3:41:21<12:47:01, 266.02s/it][A
Iteration:  21%|       | 47/219 [3:44:09<11:18:18, 236.62s/it][A
Iteration:  22%|       | 48/219 [3:46:58<10:16:28, 216.31s/it][A
Iteration:  22%|       | 49/219 [3:49:48<9:33:15, 202.33s/it] [A
Iteration:  23%|       | 50/219 [3:52:36<9:01:06, 192.11s/it][A
Iteration:  23%|       | 51/219 [3:55:25<8:38:05, 185.03s/it][A
Iteration:  24%|       | 52/219 [3:58:13<8:21:03, 180.02s/it][A
Iteration:  24%|       | 53/219 [4:01:02<8:08:43, 176.65s/it][A
Iteration:  25%|       | 54/219 [4:03:50<7:58:30, 174.00s/it][A
Iteration:  25%|       | 55/219 [4:06:38<7:51:06, 172.36s/it][A
Iteration:  26%|       | 56/219 [4:09:26<7:44:30, 170.99s/it][A
Iteration:  26%|       | 57/219 [4:12:07<7:33:15, 167.88s/it][A
Iteration:  26%|       | 58/219 [4:14:46<7:24:01, 165.47s/it][A
Iteration:  27%|       | 59/219 [4:17:27<7:17:00, 163.88s/it][A03/13/2022 09:33:43 - INFO - __main__ -   Loading features from cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_dev_6-new-12w-0_512_dnageaall
03/13/2022 09:33:43 - INFO - __main__ -   ***** Running evaluation  *****
03/13/2022 09:33:43 - INFO - __main__ -     Num examples = 1313
03/13/2022 09:33:43 - INFO - __main__ -     Batch size = 32


Evaluating:   0%|          | 0/42 [00:00<?, ?it/s][A[A

Evaluating:   2%|         | 1/42 [00:49<33:41, 49.31s/it][A[A

Evaluating:   5%|         | 2/42 [01:38<32:54, 49.36s/it][A[A

Evaluating:   7%|         | 3/42 [02:28<32:04, 49.34s/it][A[A

Evaluating:  10%|         | 4/42 [03:17<31:13, 49.31s/it][A[A

Evaluating:  12%|        | 5/42 [04:06<30:25, 49.34s/it][A[A

Evaluating:  14%|        | 6/42 [04:55<29:33, 49.27s/it][A[A

Evaluating:  17%|        | 7/42 [05:44<28:43, 49.24s/it][A[A

Evaluating:  19%|        | 8/42 [06:34<27:53, 49.22s/it][A[A

Evaluating:  21%|       | 9/42 [07:23<27:03, 49.21s/it][A[A

Evaluating:  24%|       | 10/42 [08:12<26:14, 49.21s/it][A[A

Evaluating:  26%|       | 11/42 [09:01<25:24, 49.19s/it][A[A

Evaluating:  29%|       | 12/42 [09:50<24:35, 49.20s/it][A[A

Evaluating:  31%|       | 13/42 [10:40<23:46, 49.19s/it][A[A

Evaluating:  33%|      | 14/42 [11:29<22:57, 49.19s/it][A[A

Evaluating:  36%|      | 15/42 [12:18<22:08, 49.20s/it][A[A

Evaluating:  38%|      | 16/42 [13:08<21:22, 49.34s/it][A[A

Evaluating:  40%|      | 17/42 [13:57<20:34, 49.39s/it][A[A

Evaluating:  43%|     | 18/42 [14:46<19:44, 49.35s/it][A[A

Evaluating:  45%|     | 19/42 [15:36<18:54, 49.34s/it][A[A

Evaluating:  48%|     | 20/42 [16:25<18:04, 49.30s/it][A[A

Evaluating:  50%|     | 21/42 [17:14<17:14, 49.28s/it][A[A

Evaluating:  52%|    | 22/42 [18:04<16:26, 49.30s/it][A[A

Evaluating:  55%|    | 23/42 [18:53<15:36, 49.29s/it][A[A

Evaluating:  57%|    | 24/42 [19:42<14:48, 49.34s/it][A[A

Evaluating:  60%|    | 25/42 [20:32<13:59, 49.38s/it][A[A

Evaluating:  62%|   | 26/42 [21:21<13:09, 49.35s/it][A[A

Evaluating:  64%|   | 27/42 [22:10<12:20, 49.35s/it][A[A

Evaluating:  67%|   | 28/42 [23:00<11:30, 49.32s/it][A[A

Evaluating:  69%|   | 29/42 [23:49<10:40, 49.27s/it][A[A

Evaluating:  71%|  | 30/42 [24:38<09:51, 49.27s/it][A[A

Evaluating:  74%|  | 31/42 [25:27<09:01, 49.26s/it][A[A

Evaluating:  76%|  | 32/42 [26:16<08:12, 49.22s/it][A[A

Evaluating:  79%|  | 33/42 [27:06<07:23, 49.25s/it][A[A

Evaluating:  81%|  | 34/42 [27:55<06:34, 49.27s/it][A[A

Evaluating:  83%| | 35/42 [28:44<05:44, 49.26s/it][A[A

Evaluating:  86%| | 36/42 [29:33<04:55, 49.25s/it][A[A

Evaluating:  88%| | 37/42 [30:23<04:06, 49.24s/it][A[A

Evaluating:  90%| | 38/42 [31:12<03:17, 49.32s/it][A[A

Evaluating:  93%|| 39/42 [32:02<02:28, 49.39s/it][A[A

Evaluating:  95%|| 40/42 [32:51<01:38, 49.33s/it][A[A

Evaluating:  98%|| 41/42 [33:40<00:49, 49.30s/it][A[A

Evaluating: 100%|| 42/42 [33:42<00:00, 34.91s/it][A[AEvaluating: 100%|| 42/42 [33:42<00:00, 48.14s/it]
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
03/13/2022 10:17:59 - INFO - __main__ -   ***** Eval results  *****
03/13/2022 10:17:59 - INFO - __main__ -     acc = 0.002284843869002285
03/13/2022 10:17:59 - INFO - __main__ -     auc = 0.5087933981015362
03/13/2022 10:17:59 - INFO - __main__ -     f1 = 0.0005532717014391497
03/13/2022 10:17:59 - INFO - __main__ -     mcc = 0.0015386581080609136
03/13/2022 10:17:59 - INFO - __main__ -     precision = 0.00040392775541290394
03/13/2022 10:17:59 - INFO - __main__ -     recall = 0.002284843869002285
03/13/2022 10:17:59 - INFO - __main__ -     top10acc = 0.010662604722010662
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
03/13/2022 10:17:59 - INFO - transformers.configuration_utils -   Configuration saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-60/config.json
03/13/2022 10:18:00 - INFO - transformers.modeling_utils -   Model weights saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-60/pytorch_model.bin
03/13/2022 10:18:00 - INFO - __main__ -   Saving model checkpoint to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-60
03/13/2022 10:18:02 - INFO - __main__ -   Saving optimizer and scheduler states to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-60

Iteration:  27%|       | 60/219 [5:04:24<42:23:27, 959.80s/it][A
Iteration:  28%|       | 61/219 [5:07:01<31:33:36, 719.09s/it][A
Iteration:  28%|       | 62/219 [5:09:39<24:01:32, 550.91s/it][A
Iteration:  29%|       | 63/219 [5:12:18<18:46:36, 433.31s/it][A
Iteration:  29%|       | 64/219 [5:14:59<15:07:50, 351.42s/it][A
Iteration:  30%|       | 65/219 [5:17:24<12:23:21, 289.62s/it][A
Iteration:  30%|       | 66/219 [5:19:48<10:27:02, 245.90s/it][A
Iteration:  31%|       | 67/219 [5:22:13<9:05:50, 215.46s/it] [A
Iteration:  31%|       | 68/219 [5:24:36<8:08:05, 193.94s/it][A
Iteration:  32%|      | 69/219 [5:26:59<7:26:50, 178.74s/it][A
Iteration:  32%|      | 70/219 [5:29:27<7:00:54, 169.49s/it][A
Iteration:  32%|      | 71/219 [5:32:09<6:52:23, 167.18s/it][A
Iteration:  33%|      | 72/219 [5:34:52<6:46:11, 165.79s/it][A
Iteration:  33%|      | 73/219 [5:37:32<6:39:41, 164.26s/it][A
Iteration:  34%|      | 74/219 [5:40:12<6:33:15, 162.72s/it][A
Iteration:  34%|      | 75/219 [5:42:53<6:29:27, 162.27s/it][A
Iteration:  35%|      | 76/219 [5:45:33<6:25:11, 161.62s/it][A
Iteration:  35%|      | 77/219 [5:48:18<6:24:40, 162.54s/it][A
Iteration:  36%|      | 78/219 [5:51:01<6:22:31, 162.77s/it][A
Iteration:  36%|      | 79/219 [5:53:44<6:19:41, 162.73s/it][A03/13/2022 11:10:06 - INFO - __main__ -   Loading features from cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_dev_6-new-12w-0_512_dnageaall
03/13/2022 11:10:06 - INFO - __main__ -   ***** Running evaluation  *****
03/13/2022 11:10:06 - INFO - __main__ -     Num examples = 1313
03/13/2022 11:10:06 - INFO - __main__ -     Batch size = 32


Evaluating:   0%|          | 0/42 [00:00<?, ?it/s][A[A

Evaluating:   2%|         | 1/42 [00:49<34:07, 49.93s/it][A[A

Evaluating:   5%|         | 2/42 [01:39<33:01, 49.53s/it][A[A

Evaluating:   7%|         | 3/42 [02:28<32:06, 49.40s/it][A[A

Evaluating:  10%|         | 4/42 [03:17<31:11, 49.25s/it][A[A

Evaluating:  12%|        | 5/42 [04:04<29:51, 48.42s/it][A[A

Evaluating:  14%|        | 6/42 [04:48<28:14, 47.08s/it][A[A

Evaluating:  17%|        | 7/42 [05:33<26:58, 46.24s/it][A[A

Evaluating:  19%|        | 8/42 [06:17<25:52, 45.67s/it][A[A

Evaluating:  21%|       | 9/42 [07:05<25:26, 46.26s/it][A[A

Evaluating:  24%|       | 10/42 [07:54<25:04, 47.01s/it][A[A

Evaluating:  26%|       | 11/42 [08:41<24:18, 47.06s/it][A[A

Evaluating:  29%|       | 12/42 [09:31<24:02, 48.09s/it][A[A

Evaluating:  31%|       | 13/42 [10:21<23:32, 48.71s/it][A[A

Evaluating:  33%|      | 14/42 [11:11<22:48, 48.89s/it][A[A

Evaluating:  36%|      | 15/42 [12:02<22:16, 49.51s/it][A[A

Evaluating:  38%|      | 16/42 [12:51<21:24, 49.40s/it][A[A

Evaluating:  40%|      | 17/42 [13:40<20:32, 49.30s/it][A[A

Evaluating:  43%|     | 18/42 [14:27<19:29, 48.72s/it][A[A

Evaluating:  45%|     | 19/42 [15:16<18:40, 48.72s/it][A[A

Evaluating:  48%|     | 20/42 [16:02<17:36, 48.04s/it][A[A

Evaluating:  50%|     | 21/42 [16:47<16:26, 46.98s/it][A[A

Evaluating:  52%|    | 22/42 [17:31<15:24, 46.23s/it][A[A

Evaluating:  55%|    | 23/42 [18:20<14:54, 47.08s/it][A[A

Evaluating:  57%|    | 24/42 [19:05<13:53, 46.31s/it][A[A

Evaluating:  60%|    | 25/42 [19:52<13:12, 46.62s/it][A[A

Evaluating:  62%|   | 26/42 [20:42<12:40, 47.54s/it][A[A

Evaluating:  64%|   | 27/42 [21:30<11:54, 47.62s/it][A[A

Evaluating:  67%|   | 28/42 [22:20<11:16, 48.29s/it][A[A

Evaluating:  69%|   | 29/42 [23:08<10:26, 48.20s/it][A[A

Evaluating:  71%|  | 30/42 [23:52<09:25, 47.11s/it][A[A

Evaluating:  74%|  | 31/42 [24:38<08:33, 46.71s/it][A[A

Evaluating:  76%|  | 32/42 [25:27<07:54, 47.47s/it][A[A

Evaluating:  79%|  | 33/42 [26:16<07:10, 47.79s/it][A[A

Evaluating:  81%|  | 34/42 [27:04<06:24, 48.02s/it][A[A

Evaluating:  83%| | 35/42 [27:53<05:37, 48.17s/it][A[A

Evaluating:  86%| | 36/42 [28:38<04:43, 47.26s/it][A[A

Evaluating:  88%| | 37/42 [29:26<03:57, 47.58s/it][A[A

Evaluating:  90%| | 38/42 [30:14<03:10, 47.72s/it][A[A

Evaluating:  93%|| 39/42 [30:59<02:20, 46.77s/it][A[A

Evaluating:  95%|| 40/42 [31:43<01:32, 46.08s/it][A[A

Evaluating:  98%|| 41/42 [32:30<00:46, 46.38s/it][A[A

Evaluating: 100%|| 42/42 [32:32<00:00, 32.87s/it][A[AEvaluating: 100%|| 42/42 [32:32<00:00, 46.48s/it]
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
03/13/2022 11:52:37 - INFO - __main__ -   ***** Eval results  *****
03/13/2022 11:52:37 - INFO - __main__ -     acc = 0.0015232292460015233
03/13/2022 11:52:37 - INFO - __main__ -     auc = 0.5039044359407798
03/13/2022 11:52:37 - INFO - __main__ -     f1 = 3.4151158720356084e-05
03/13/2022 11:52:37 - INFO - __main__ -     mcc = 0.0008426808084451158
03/13/2022 11:52:37 - INFO - __main__ -     precision = 1.7402484665339983e-05
03/13/2022 11:52:37 - INFO - __main__ -     recall = 0.0015232292460015233
03/13/2022 11:52:37 - INFO - __main__ -     top10acc = 0.011424219345011425
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
03/13/2022 11:52:37 - INFO - transformers.configuration_utils -   Configuration saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-80/config.json
03/13/2022 11:52:38 - INFO - transformers.modeling_utils -   Model weights saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-80/pytorch_model.bin
03/13/2022 11:52:38 - INFO - __main__ -   Saving model checkpoint to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-80
03/13/2022 11:52:40 - INFO - __main__ -   Saving optimizer and scheduler states to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-80

Iteration:  37%|      | 80/219 [6:39:02<35:53:13, 929.45s/it][A
Iteration:  37%|      | 81/219 [6:41:30<26:38:40, 695.07s/it][A
Iteration:  37%|      | 82/219 [6:44:01<20:14:13, 531.78s/it][A
Iteration:  38%|      | 83/219 [6:46:24<15:41:00, 415.15s/it][A
Iteration:  38%|      | 84/219 [6:49:01<12:40:11, 337.87s/it][A
Iteration:  39%|      | 85/219 [6:51:39<10:33:54, 283.84s/it][A
Iteration:  39%|      | 86/219 [6:54:13<9:02:51, 244.90s/it] [A
Iteration:  40%|      | 87/219 [6:56:47<7:58:49, 217.65s/it][A
Iteration:  40%|      | 88/219 [6:59:13<7:07:50, 195.96s/it][A
Iteration:  41%|      | 89/219 [7:01:46<6:37:06, 183.28s/it][A
Iteration:  41%|      | 90/219 [7:04:25<6:18:12, 175.91s/it][A
Iteration:  42%|     | 91/219 [7:07:04<6:04:33, 170.89s/it][A
Iteration:  42%|     | 92/219 [7:09:44<5:54:36, 167.53s/it][A
Iteration:  42%|     | 93/219 [7:12:23<5:46:08, 164.83s/it][A
Iteration:  43%|     | 94/219 [7:15:01<5:39:40, 163.05s/it][A
Iteration:  43%|     | 95/219 [7:17:41<5:34:42, 161.96s/it][A
Iteration:  44%|     | 96/219 [7:20:19<5:29:38, 160.80s/it][A
Iteration:  44%|     | 97/219 [7:22:58<5:25:39, 160.16s/it][A
Iteration:  45%|     | 98/219 [7:25:37<5:22:39, 160.00s/it][A
Iteration:  45%|     | 99/219 [7:28:17<5:19:38, 159.82s/it][A03/13/2022 12:44:24 - INFO - __main__ -   Loading features from cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_dev_6-new-12w-0_512_dnageaall
03/13/2022 12:44:25 - INFO - __main__ -   ***** Running evaluation  *****
03/13/2022 12:44:25 - INFO - __main__ -     Num examples = 1313
03/13/2022 12:44:25 - INFO - __main__ -     Batch size = 32


Evaluating:   0%|          | 0/42 [00:00<?, ?it/s][A[A

Evaluating:   2%|         | 1/42 [00:51<35:18, 51.67s/it][A[A

Evaluating:   5%|         | 2/42 [01:40<33:28, 50.21s/it][A[A

Evaluating:   7%|         | 3/42 [02:25<31:06, 47.86s/it][A[A

Evaluating:  10%|         | 4/42 [03:10<29:24, 46.44s/it][A[A

Evaluating:  12%|        | 5/42 [03:54<28:08, 45.63s/it][A[A

Evaluating:  14%|        | 6/42 [04:38<27:04, 45.14s/it][A[A

Evaluating:  17%|        | 7/42 [05:27<26:59, 46.28s/it][A[A

Evaluating:  19%|        | 8/42 [06:16<26:50, 47.36s/it][A[A

Evaluating:  21%|       | 9/42 [07:01<25:34, 46.50s/it][A[A

Evaluating:  24%|       | 10/42 [07:45<24:25, 45.80s/it][A[A

Evaluating:  26%|       | 11/42 [08:29<23:24, 45.30s/it][A[A

Evaluating:  29%|       | 12/42 [09:14<22:29, 44.98s/it][A[A

Evaluating:  31%|       | 13/42 [09:58<21:37, 44.75s/it][A[A

Evaluating:  33%|      | 14/42 [10:42<20:48, 44.59s/it][A[A

Evaluating:  36%|      | 15/42 [11:26<20:00, 44.47s/it][A[A

Evaluating:  38%|      | 16/42 [12:10<19:13, 44.38s/it][A[A

Evaluating:  40%|      | 17/42 [12:55<18:28, 44.35s/it][A[A

Evaluating:  43%|     | 18/42 [13:39<17:45, 44.40s/it][A[A

Evaluating:  45%|     | 19/42 [14:29<17:39, 46.08s/it][A[A

Evaluating:  48%|     | 20/42 [15:21<17:29, 47.69s/it][A[A

Evaluating:  50%|     | 21/42 [16:10<16:53, 48.28s/it][A[A

Evaluating:  52%|    | 22/42 [16:56<15:52, 47.63s/it][A[A

Evaluating:  55%|    | 23/42 [17:41<14:45, 46.62s/it][A[A

Evaluating:  57%|    | 24/42 [18:25<13:45, 45.89s/it][A[A

Evaluating:  60%|    | 25/42 [19:10<12:54, 45.53s/it][A[A

Evaluating:  62%|   | 26/42 [19:59<12:25, 46.60s/it][A[A

Evaluating:  64%|   | 27/42 [20:44<11:32, 46.18s/it][A[A

Evaluating:  67%|   | 28/42 [21:28<10:38, 45.59s/it][A[A

Evaluating:  69%|   | 29/42 [22:12<09:47, 45.17s/it][A[A

Evaluating:  71%|  | 30/42 [22:56<08:58, 44.87s/it][A[A

Evaluating:  74%|  | 31/42 [23:41<08:11, 44.67s/it][A[A

Evaluating:  76%|  | 32/42 [24:25<07:25, 44.52s/it][A[A

Evaluating:  79%|  | 33/42 [25:09<06:39, 44.41s/it][A[A

Evaluating:  81%|  | 34/42 [25:53<05:54, 44.34s/it][A[A

Evaluating:  83%| | 35/42 [26:37<05:10, 44.29s/it][A[A

Evaluating:  86%| | 36/42 [27:22<04:25, 44.26s/it][A[A

Evaluating:  88%| | 37/42 [28:06<03:41, 44.26s/it][A[A

Evaluating:  90%| | 38/42 [28:50<02:56, 44.25s/it][A[A

Evaluating:  93%|| 39/42 [29:39<02:17, 45.69s/it][A[A

Evaluating:  95%|| 40/42 [30:29<01:33, 46.94s/it][A[A

Evaluating:  98%|| 41/42 [31:17<00:47, 47.40s/it][A[A

Evaluating: 100%|| 42/42 [31:19<00:00, 33.57s/it][A[AEvaluating: 100%|| 42/42 [31:19<00:00, 44.74s/it]
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
03/13/2022 13:26:04 - INFO - __main__ -   ***** Eval results  *****
03/13/2022 13:26:04 - INFO - __main__ -     acc = 0.0007616146230007616
03/13/2022 13:26:04 - INFO - __main__ -     auc = 0.5111293258781788
03/13/2022 13:26:04 - INFO - __main__ -     f1 = 1.2343835056738437e-06
03/13/2022 13:26:04 - INFO - __main__ -     mcc = 0.0
03/13/2022 13:26:04 - INFO - __main__ -     precision = 6.176923138692308e-07
03/13/2022 13:26:04 - INFO - __main__ -     recall = 0.0007616146230007616
03/13/2022 13:26:04 - INFO - __main__ -     top10acc = 0.007616146230007616
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
03/13/2022 13:26:04 - INFO - transformers.configuration_utils -   Configuration saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-100/config.json
03/13/2022 13:26:05 - INFO - transformers.modeling_utils -   Model weights saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-100/pytorch_model.bin
03/13/2022 13:26:05 - INFO - __main__ -   Saving model checkpoint to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-100
03/13/2022 13:26:07 - INFO - __main__ -   Saving optimizer and scheduler states to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-100

Iteration:  46%|     | 100/219 [8:12:29<30:00:02, 907.58s/it][A
Iteration:  46%|     | 101/219 [8:15:09<22:23:45, 683.27s/it][A
Iteration:  47%|     | 102/219 [8:17:47<17:05:16, 525.79s/it][A
Iteration:  47%|     | 103/219 [8:20:22<13:21:26, 414.54s/it][A
Iteration:  47%|     | 104/219 [8:23:00<10:47:11, 337.67s/it][A
Iteration:  48%|     | 105/219 [8:25:43<9:01:41, 285.10s/it] [A
Iteration:  48%|     | 106/219 [8:28:22<7:45:49, 247.34s/it][A
Iteration:  49%|     | 107/219 [8:31:02<6:52:39, 221.07s/it][A
Iteration:  49%|     | 108/219 [8:33:45<6:16:53, 203.73s/it][A
Iteration:  50%|     | 109/219 [8:36:28<5:51:14, 191.59s/it][A
Iteration:  50%|     | 110/219 [8:39:07<5:30:17, 181.81s/it][A
Iteration:  51%|     | 111/219 [8:41:47<5:15:01, 175.01s/it][A
Iteration:  51%|     | 112/219 [8:44:24<5:02:34, 169.67s/it][A
Iteration:  52%|    | 113/219 [8:47:02<4:53:39, 166.22s/it][A
Iteration:  52%|    | 114/219 [8:49:41<4:47:02, 164.02s/it][A
Iteration:  53%|    | 115/219 [8:52:14<4:38:38, 160.75s/it][A
Iteration:  53%|    | 116/219 [8:54:46<4:31:34, 158.20s/it][A
Iteration:  53%|    | 117/219 [8:57:16<4:24:46, 155.75s/it][A
Iteration:  54%|    | 118/219 [8:59:37<4:14:29, 151.18s/it][A
Iteration:  54%|    | 119/219 [9:01:52<4:04:02, 146.43s/it][A03/13/2022 14:17:45 - INFO - __main__ -   Loading features from cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_dev_6-new-12w-0_512_dnageaall
03/13/2022 14:17:45 - INFO - __main__ -   ***** Running evaluation  *****
03/13/2022 14:17:45 - INFO - __main__ -     Num examples = 1313
03/13/2022 14:17:45 - INFO - __main__ -     Batch size = 32


Evaluating:   0%|          | 0/42 [00:00<?, ?it/s][A[A

Evaluating:   2%|         | 1/42 [00:45<31:09, 45.61s/it][A[A

Evaluating:   5%|         | 2/42 [01:30<30:14, 45.36s/it][A[A

Evaluating:   7%|         | 3/42 [02:16<29:26, 45.29s/it][A[A

Evaluating:  10%|         | 4/42 [03:01<28:37, 45.19s/it][A[A

Evaluating:  12%|        | 5/42 [03:46<27:50, 45.14s/it][A[A

Evaluating:  14%|        | 6/42 [04:31<27:05, 45.16s/it][A[A

Evaluating:  17%|        | 7/42 [05:16<26:20, 45.16s/it][A[A

Evaluating:  19%|        | 8/42 [06:01<25:37, 45.21s/it][A[A

Evaluating:  21%|       | 9/42 [06:47<24:52, 45.23s/it][A[A

Evaluating:  24%|       | 10/42 [07:32<24:08, 45.28s/it][A[A

Evaluating:  26%|       | 11/42 [08:17<23:23, 45.28s/it][A[A

Evaluating:  29%|       | 12/42 [09:03<22:38, 45.28s/it][A[A

Evaluating:  31%|       | 13/42 [09:48<21:53, 45.28s/it][A[A

Evaluating:  33%|      | 14/42 [10:33<21:08, 45.32s/it][A[A

Evaluating:  36%|      | 15/42 [11:18<20:23, 45.32s/it][A[A

Evaluating:  38%|      | 16/42 [12:03<19:35, 45.21s/it][A[A

Evaluating:  40%|      | 17/42 [12:49<18:50, 45.23s/it][A[A

Evaluating:  43%|     | 18/42 [13:34<18:04, 45.17s/it][A[A

Evaluating:  45%|     | 19/42 [14:19<17:18, 45.16s/it][A[A

Evaluating:  48%|     | 20/42 [15:04<16:33, 45.17s/it][A[A

Evaluating:  50%|     | 21/42 [15:49<15:48, 45.15s/it][A[A

Evaluating:  52%|    | 22/42 [16:34<15:01, 45.08s/it][A[A

Evaluating:  55%|    | 23/42 [17:19<14:15, 45.04s/it][A[A

Evaluating:  57%|    | 24/42 [18:04<13:30, 45.01s/it][A[A

Evaluating:  60%|    | 25/42 [18:49<12:44, 44.99s/it][A[A

Evaluating:  62%|   | 26/42 [19:35<12:05, 45.37s/it][A[A

Evaluating:  64%|   | 27/42 [20:23<11:31, 46.09s/it][A[A

Evaluating:  67%|   | 28/42 [21:11<10:52, 46.62s/it][A[A

Evaluating:  69%|   | 29/42 [21:58<10:06, 46.66s/it][A[A

Evaluating:  71%|  | 30/42 [22:43<09:14, 46.20s/it][A[A

Evaluating:  74%|  | 31/42 [23:28<08:24, 45.90s/it][A[A

Evaluating:  76%|  | 32/42 [24:13<07:36, 45.68s/it][A[A

Evaluating:  79%|  | 33/42 [24:58<06:49, 45.51s/it][A[A

Evaluating:  81%|  | 34/42 [25:44<06:04, 45.54s/it][A[A

Evaluating:  83%| | 35/42 [26:29<05:18, 45.46s/it][A[A

Evaluating:  86%| | 36/42 [27:14<04:32, 45.38s/it][A[A

Evaluating:  88%| | 37/42 [28:00<03:46, 45.34s/it][A[A

Evaluating:  90%| | 38/42 [28:45<03:01, 45.31s/it][A[A

Evaluating:  93%|| 39/42 [29:30<02:15, 45.26s/it][A[A

Evaluating:  95%|| 40/42 [30:15<01:30, 45.25s/it][A[A

Evaluating:  98%|| 41/42 [31:00<00:45, 45.24s/it][A[A

Evaluating: 100%|| 42/42 [31:02<00:00, 32.02s/it][A[AEvaluating: 100%|| 42/42 [31:02<00:00, 44.33s/it]
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
03/13/2022 14:58:43 - INFO - __main__ -   ***** Eval results  *****
03/13/2022 14:58:43 - INFO - __main__ -     acc = 0.0007616146230007616
03/13/2022 14:58:43 - INFO - __main__ -     auc = 0.49534410816785246
03/13/2022 14:58:43 - INFO - __main__ -     f1 = 1.159230780823077e-06
03/13/2022 14:58:43 - INFO - __main__ -     mcc = 0.0
03/13/2022 14:58:43 - INFO - __main__ -     precision = 5.800568339685923e-07
03/13/2022 14:58:43 - INFO - __main__ -     recall = 0.0007616146230007616
03/13/2022 14:58:43 - INFO - __main__ -     top10acc = 0.007616146230007616
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
03/13/2022 14:58:43 - INFO - transformers.configuration_utils -   Configuration saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-120/config.json
03/13/2022 14:58:44 - INFO - transformers.modeling_utils -   Model weights saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-120/pytorch_model.bin
03/13/2022 14:58:44 - INFO - __main__ -   Saving model checkpoint to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-120
03/13/2022 14:58:46 - INFO - __main__ -   Saving optimizer and scheduler states to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-120

Iteration:  55%|    | 120/219 [9:45:08<24:14:03, 881.25s/it][A
Iteration:  55%|    | 121/219 [9:47:19<17:51:38, 656.11s/it][A
Iteration:  56%|    | 122/219 [9:49:32<13:27:08, 499.26s/it][A
Iteration:  56%|    | 123/219 [9:51:47<10:23:51, 389.91s/it][A
Iteration:  57%|    | 124/219 [9:54:01<8:15:47, 313.13s/it] [A
Iteration:  57%|    | 125/219 [9:56:14<6:46:06, 259.22s/it][A
Iteration:  58%|    | 126/219 [9:58:30<5:44:18, 222.13s/it][A
Iteration:  58%|    | 127/219 [10:00:44<4:59:58, 195.63s/it][A
Iteration:  58%|    | 128/219 [10:03:00<4:29:44, 177.86s/it][A
Iteration:  59%|    | 129/219 [10:05:17<4:08:20, 165.56s/it][A
Iteration:  59%|    | 130/219 [10:07:33<3:52:19, 156.63s/it][A
Iteration:  60%|    | 131/219 [10:09:47<3:39:55, 149.95s/it][A
Iteration:  60%|    | 132/219 [10:12:03<3:31:27, 145.84s/it][A
Iteration:  61%|    | 133/219 [10:14:17<3:24:03, 142.37s/it][A
Iteration:  61%|    | 134/219 [10:16:32<3:18:13, 139.93s/it][A
Iteration:  62%|   | 135/219 [10:18:45<3:13:16, 138.05s/it][A
Iteration:  62%|   | 136/219 [10:21:01<3:09:56, 137.30s/it][A
Iteration:  63%|   | 137/219 [10:23:16<3:06:37, 136.56s/it][A
Iteration:  63%|   | 138/219 [10:25:30<3:03:21, 135.82s/it][A
Iteration:  63%|   | 139/219 [10:27:45<3:00:49, 135.62s/it][A03/13/2022 15:43:38 - INFO - __main__ -   Loading features from cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_dev_6-new-12w-0_512_dnageaall
03/13/2022 15:43:38 - INFO - __main__ -   ***** Running evaluation  *****
03/13/2022 15:43:38 - INFO - __main__ -     Num examples = 1313
03/13/2022 15:43:38 - INFO - __main__ -     Batch size = 32


Evaluating:   0%|          | 0/42 [00:00<?, ?it/s][A[A

Evaluating:   2%|         | 1/42 [00:45<31:24, 45.96s/it][A[A

Evaluating:   5%|         | 2/42 [01:31<30:37, 45.94s/it][A[A

Evaluating:   7%|         | 3/42 [02:17<29:51, 45.93s/it][A[A

Evaluating:  10%|         | 4/42 [03:03<29:04, 45.92s/it][A[A

Evaluating:  12%|        | 5/42 [03:49<28:20, 45.95s/it][A[A

Evaluating:  14%|        | 6/42 [04:35<27:34, 45.95s/it][A[A

Evaluating:  17%|        | 7/42 [05:21<26:47, 45.93s/it][A[A

Evaluating:  19%|        | 8/42 [06:07<26:01, 45.92s/it][A[A

Evaluating:  21%|       | 9/42 [06:53<25:14, 45.90s/it][A[A

Evaluating:  24%|       | 10/42 [07:39<24:28, 45.89s/it][A[A

Evaluating:  26%|       | 11/42 [08:25<23:42, 45.88s/it][A[A

Evaluating:  29%|       | 12/42 [09:10<22:56, 45.88s/it][A[A

Evaluating:  31%|       | 13/42 [09:56<22:10, 45.88s/it][A[A

Evaluating:  33%|      | 14/42 [10:42<21:25, 45.89s/it][A[A

Evaluating:  36%|      | 15/42 [11:28<20:39, 45.91s/it][A[A

Evaluating:  38%|      | 16/42 [12:14<19:52, 45.88s/it][A[A

Evaluating:  40%|      | 17/42 [13:00<19:06, 45.88s/it][A[A

Evaluating:  43%|     | 18/42 [13:46<18:21, 45.88s/it][A[A

Evaluating:  45%|     | 19/42 [14:32<17:34, 45.87s/it][A[A

Evaluating:  48%|     | 20/42 [15:17<16:48, 45.85s/it][A[A

Evaluating:  50%|     | 21/42 [16:03<16:03, 45.86s/it][A[A

Evaluating:  52%|    | 22/42 [16:49<15:17, 45.87s/it][A[A

Evaluating:  55%|    | 23/42 [17:35<14:31, 45.86s/it][A[A

Evaluating:  57%|    | 24/42 [18:21<13:45, 45.86s/it][A[A

Evaluating:  60%|    | 25/42 [19:07<12:59, 45.86s/it][A[A

Evaluating:  62%|   | 26/42 [19:53<12:13, 45.87s/it][A[A

Evaluating:  64%|   | 27/42 [20:38<11:27, 45.86s/it][A[A

Evaluating:  67%|   | 28/42 [21:24<10:42, 45.87s/it][A[A

Evaluating:  69%|   | 29/42 [22:10<09:55, 45.83s/it][A[A

Evaluating:  71%|  | 30/42 [22:56<09:10, 45.86s/it][A[A

Evaluating:  74%|  | 31/42 [23:42<08:24, 45.89s/it][A[A

Evaluating:  76%|  | 32/42 [24:28<07:39, 45.90s/it][A[A

Evaluating:  79%|  | 33/42 [25:14<06:52, 45.88s/it][A[A

Evaluating:  81%|  | 34/42 [26:00<06:07, 45.88s/it][A[A

Evaluating:  83%| | 35/42 [26:46<05:21, 45.89s/it][A[A

Evaluating:  86%| | 36/42 [27:31<04:35, 45.89s/it][A[A

Evaluating:  88%| | 37/42 [28:17<03:49, 45.89s/it][A[A

Evaluating:  90%| | 38/42 [29:03<03:03, 45.89s/it][A[A

Evaluating:  93%|| 39/42 [29:49<02:17, 45.90s/it][A[A

Evaluating:  95%|| 40/42 [30:35<01:31, 45.88s/it][A[A

Evaluating:  98%|| 41/42 [31:21<00:45, 45.88s/it][A[A

Evaluating: 100%|| 42/42 [31:22<00:00, 32.48s/it][A[AEvaluating: 100%|| 42/42 [31:22<00:00, 44.82s/it]
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
03/13/2022 16:25:39 - INFO - __main__ -   ***** Eval results  *****
03/13/2022 16:25:39 - INFO - __main__ -     acc = 0.0007616146230007616
03/13/2022 16:25:39 - INFO - __main__ -     auc = 0.4958584302379581
03/13/2022 16:25:39 - INFO - __main__ -     f1 = 1.159230780823077e-06
03/13/2022 16:25:39 - INFO - __main__ -     mcc = 0.0
03/13/2022 16:25:39 - INFO - __main__ -     precision = 5.800568339685923e-07
03/13/2022 16:25:39 - INFO - __main__ -     recall = 0.0007616146230007616
03/13/2022 16:25:39 - INFO - __main__ -     top10acc = 0.007616146230007616
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
03/13/2022 16:25:39 - INFO - transformers.configuration_utils -   Configuration saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-140/config.json
03/13/2022 16:25:40 - INFO - transformers.modeling_utils -   Model weights saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-140/pytorch_model.bin
03/13/2022 16:25:40 - INFO - __main__ -   Saving model checkpoint to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-140
03/13/2022 16:25:42 - INFO - __main__ -   Saving optimizer and scheduler states to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-140

Iteration:  64%|   | 140/219 [11:12:04<19:35:11, 892.56s/it][A
Iteration:  64%|   | 141/219 [11:14:16<14:23:56, 664.57s/it][A
Iteration:  65%|   | 142/219 [11:16:31<10:48:59, 505.71s/it][A
Iteration:  65%|   | 143/219 [11:18:47<8:19:51, 394.62s/it] [A
Iteration:  66%|   | 144/219 [11:21:01<6:35:41, 316.55s/it][A
Iteration:  66%|   | 145/219 [11:23:16<5:23:19, 262.16s/it][A
Iteration:  67%|   | 146/219 [11:25:32<4:32:39, 224.11s/it][A
Iteration:  67%|   | 147/219 [11:27:47<3:57:00, 197.51s/it][A
Iteration:  68%|   | 148/219 [11:30:01<3:31:15, 178.53s/it][A
Iteration:  68%|   | 149/219 [11:32:16<3:12:50, 165.30s/it][A
Iteration:  68%|   | 150/219 [11:34:31<2:59:32, 156.12s/it][A
Iteration:  69%|   | 151/219 [11:36:45<2:49:28, 149.54s/it][A
Iteration:  69%|   | 152/219 [11:38:59<2:41:54, 144.99s/it][A
Iteration:  70%|   | 153/219 [11:41:13<2:35:52, 141.70s/it][A
Iteration:  70%|   | 154/219 [11:43:29<2:31:28, 139.82s/it][A
Iteration:  71%|   | 155/219 [11:45:44<2:27:40, 138.45s/it][A
Iteration:  71%|   | 156/219 [11:47:59<2:24:21, 137.48s/it][A
Iteration:  72%|  | 157/219 [11:50:15<2:21:26, 136.88s/it][A
Iteration:  72%|  | 158/219 [11:52:29<2:18:25, 136.15s/it][A
Iteration:  73%|  | 159/219 [11:54:44<2:15:46, 135.77s/it][A03/13/2022 17:10:36 - INFO - __main__ -   Loading features from cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_dev_6-new-12w-0_512_dnageaall
03/13/2022 17:10:36 - INFO - __main__ -   ***** Running evaluation  *****
03/13/2022 17:10:36 - INFO - __main__ -     Num examples = 1313
03/13/2022 17:10:36 - INFO - __main__ -     Batch size = 32


Evaluating:   0%|          | 0/42 [00:00<?, ?it/s][A[A

Evaluating:   2%|         | 1/42 [00:45<31:14, 45.71s/it][A[A

Evaluating:   5%|         | 2/42 [01:31<30:27, 45.70s/it][A[A

Evaluating:   7%|         | 3/42 [02:17<29:42, 45.70s/it][A[A

Evaluating:  10%|         | 4/42 [03:02<28:54, 45.65s/it][A[A

Evaluating:  12%|        | 5/42 [03:48<28:08, 45.65s/it][A[A

Evaluating:  14%|        | 6/42 [04:33<27:23, 45.64s/it][A[A

Evaluating:  17%|        | 7/42 [05:19<26:36, 45.62s/it][A[A

Evaluating:  19%|        | 8/42 [06:05<25:50, 45.59s/it][A[A

Evaluating:  21%|       | 9/42 [06:50<25:04, 45.60s/it][A[A

Evaluating:  24%|       | 10/42 [07:36<24:18, 45.59s/it][A[A

Evaluating:  26%|       | 11/42 [08:21<23:33, 45.59s/it][A[A

Evaluating:  29%|       | 12/42 [09:07<22:47, 45.57s/it][A[A

Evaluating:  31%|       | 13/42 [09:53<22:02, 45.60s/it][A[A

Evaluating:  33%|      | 14/42 [10:38<21:17, 45.61s/it][A[A

Evaluating:  36%|      | 15/42 [11:24<20:31, 45.60s/it][A[A

Evaluating:  38%|      | 16/42 [12:09<19:45, 45.61s/it][A[A

Evaluating:  40%|      | 17/42 [12:55<19:01, 45.67s/it][A[A

Evaluating:  43%|     | 18/42 [13:41<18:17, 45.71s/it][A[A

Evaluating:  45%|     | 19/42 [14:27<17:30, 45.67s/it][A[A

Evaluating:  48%|     | 20/42 [15:12<16:44, 45.66s/it][A[A

Evaluating:  50%|     | 21/42 [15:58<15:58, 45.66s/it][A[A

Evaluating:  52%|    | 22/42 [16:44<15:14, 45.72s/it][A[A

Evaluating:  55%|    | 23/42 [17:29<14:28, 45.71s/it][A[A

Evaluating:  57%|    | 24/42 [18:15<13:42, 45.69s/it][A[A

Evaluating:  60%|    | 25/42 [19:01<12:56, 45.66s/it][A[A

Evaluating:  62%|   | 26/42 [19:46<12:10, 45.67s/it][A[A

Evaluating:  64%|   | 27/42 [20:32<11:24, 45.65s/it][A[A

Evaluating:  67%|   | 28/42 [21:18<10:39, 45.65s/it][A[A

Evaluating:  69%|   | 29/42 [22:03<09:53, 45.66s/it][A[A

Evaluating:  71%|  | 30/42 [22:49<09:07, 45.64s/it][A[A

Evaluating:  74%|  | 31/42 [23:35<08:22, 45.66s/it][A[A

Evaluating:  76%|  | 32/42 [24:20<07:36, 45.66s/it][A[A

Evaluating:  79%|  | 33/42 [25:06<06:50, 45.63s/it][A[A

Evaluating:  81%|  | 34/42 [25:51<06:04, 45.59s/it][A[A

Evaluating:  83%| | 35/42 [26:37<05:19, 45.62s/it][A[A

Evaluating:  86%| | 36/42 [27:23<04:33, 45.62s/it][A[A

Evaluating:  88%| | 37/42 [28:08<03:48, 45.65s/it][A[A

Evaluating:  90%| | 38/42 [28:54<03:02, 45.62s/it][A[A

Evaluating:  93%|| 39/42 [29:40<02:16, 45.65s/it][A[A

Evaluating:  95%|| 40/42 [30:25<01:31, 45.67s/it][A[A

Evaluating:  98%|| 41/42 [31:11<00:45, 45.66s/it][A[A

Evaluating: 100%|| 42/42 [31:12<00:00, 32.32s/it][A[AEvaluating: 100%|| 42/42 [31:12<00:00, 44.59s/it]
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
03/13/2022 17:52:27 - INFO - __main__ -   ***** Eval results  *****
03/13/2022 17:52:27 - INFO - __main__ -     acc = 0.0007616146230007616
03/13/2022 17:52:27 - INFO - __main__ -     auc = 0.5026731976668586
03/13/2022 17:52:27 - INFO - __main__ -     f1 = 1.159230780823077e-06
03/13/2022 17:52:27 - INFO - __main__ -     mcc = 0.0
03/13/2022 17:52:27 - INFO - __main__ -     precision = 5.800568339685923e-07
03/13/2022 17:52:27 - INFO - __main__ -     recall = 0.0007616146230007616
03/13/2022 17:52:27 - INFO - __main__ -     top10acc = 0.007616146230007616
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
03/13/2022 17:52:27 - INFO - transformers.configuration_utils -   Configuration saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-160/config.json
03/13/2022 17:52:28 - INFO - transformers.modeling_utils -   Model weights saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-160/pytorch_model.bin
03/13/2022 17:52:28 - INFO - __main__ -   Saving model checkpoint to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-160
03/13/2022 17:52:30 - INFO - __main__ -   Saving optimizer and scheduler states to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-160

Iteration:  73%|  | 160/219 [12:38:52<14:34:37, 889.44s/it][A
Iteration:  74%|  | 161/219 [12:41:05<10:40:30, 662.59s/it][A
Iteration:  74%|  | 162/219 [12:43:19<7:58:50, 504.05s/it] [A
Iteration:  74%|  | 163/219 [12:45:33<6:06:49, 393.03s/it][A
Iteration:  75%|  | 164/219 [12:47:50<4:49:41, 316.03s/it][A
Iteration:  75%|  | 165/219 [12:50:05<3:55:33, 261.73s/it][A
Iteration:  76%|  | 166/219 [12:52:19<3:17:25, 223.50s/it][A
Iteration:  76%|  | 167/219 [12:54:34<2:50:37, 196.88s/it][A
Iteration:  77%|  | 168/219 [12:56:49<2:31:31, 178.26s/it][A
Iteration:  77%|  | 169/219 [12:59:03<2:17:34, 165.08s/it][A
Iteration:  78%|  | 170/219 [13:01:17<2:07:17, 155.87s/it][A
Iteration:  78%|  | 171/219 [13:03:32<1:59:34, 149.46s/it][A
Iteration:  79%|  | 172/219 [13:05:46<1:53:29, 144.89s/it][A
Iteration:  79%|  | 173/219 [13:08:01<1:48:54, 142.05s/it][A
Iteration:  79%|  | 174/219 [13:10:16<1:44:45, 139.68s/it][A
Iteration:  80%|  | 175/219 [13:12:30<1:41:14, 138.06s/it][A
Iteration:  80%|  | 176/219 [13:14:44<1:38:06, 136.89s/it][A
Iteration:  81%|  | 177/219 [13:16:58<1:35:14, 136.05s/it][A
Iteration:  81%| | 178/219 [13:19:12<1:32:38, 135.56s/it][A
Iteration:  82%| | 179/219 [13:21:27<1:30:07, 135.19s/it][A03/13/2022 18:37:19 - INFO - __main__ -   Loading features from cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_dev_6-new-12w-0_512_dnageaall
03/13/2022 18:37:19 - INFO - __main__ -   ***** Running evaluation  *****
03/13/2022 18:37:19 - INFO - __main__ -     Num examples = 1313
03/13/2022 18:37:19 - INFO - __main__ -     Batch size = 32


Evaluating:   0%|          | 0/42 [00:00<?, ?it/s][A[A

Evaluating:   2%|         | 1/42 [00:45<31:19, 45.84s/it][A[A

Evaluating:   5%|         | 2/42 [01:31<30:33, 45.84s/it][A[A

Evaluating:   7%|         | 3/42 [02:17<29:47, 45.84s/it][A[A

Evaluating:  10%|         | 4/42 [03:03<29:01, 45.83s/it][A[A

Evaluating:  12%|        | 5/42 [03:49<28:15, 45.81s/it][A[A

Evaluating:  14%|        | 6/42 [04:34<27:29, 45.81s/it][A[A

Evaluating:  17%|        | 7/42 [05:20<26:43, 45.83s/it][A[A

Evaluating:  19%|        | 8/42 [06:06<25:57, 45.79s/it][A[A

Evaluating:  21%|       | 9/42 [06:52<25:11, 45.81s/it][A[A

Evaluating:  24%|       | 10/42 [07:38<24:25, 45.80s/it][A[A

Evaluating:  26%|       | 11/42 [08:23<23:39, 45.79s/it][A[A

Evaluating:  29%|       | 12/42 [09:09<22:53, 45.78s/it][A[A

Evaluating:  31%|       | 13/42 [09:55<22:07, 45.78s/it][A[A

Evaluating:  33%|      | 14/42 [10:41<21:22, 45.79s/it][A[A

Evaluating:  36%|      | 15/42 [11:27<20:36, 45.79s/it][A[A

Evaluating:  38%|      | 16/42 [12:12<19:50, 45.77s/it][A[A

Evaluating:  40%|      | 17/42 [12:58<19:04, 45.78s/it][A[A

Evaluating:  43%|     | 18/42 [13:44<18:18, 45.77s/it][A[A

Evaluating:  45%|     | 19/42 [14:30<17:32, 45.77s/it][A[A

Evaluating:  48%|     | 20/42 [15:15<16:47, 45.78s/it][A[A

Evaluating:  50%|     | 21/42 [16:01<16:01, 45.78s/it][A[A

Evaluating:  52%|    | 22/42 [16:47<15:15, 45.79s/it][A[A

Evaluating:  55%|    | 23/42 [17:33<14:29, 45.78s/it][A[A

Evaluating:  57%|    | 24/42 [18:19<13:43, 45.77s/it][A[A

Evaluating:  60%|    | 25/42 [19:04<12:58, 45.78s/it][A[A

Evaluating:  62%|   | 26/42 [19:50<12:12, 45.77s/it][A[A

Evaluating:  64%|   | 27/42 [20:36<11:26, 45.76s/it][A[A

Evaluating:  67%|   | 28/42 [21:21<10:40, 45.74s/it][A[A

Evaluating:  69%|   | 29/42 [22:07<09:55, 45.78s/it][A[A

Evaluating:  71%|  | 30/42 [22:53<09:09, 45.78s/it][A[A

Evaluating:  74%|  | 31/42 [23:39<08:23, 45.76s/it][A[A

Evaluating:  76%|  | 32/42 [24:25<07:37, 45.77s/it][A[A

Evaluating:  79%|  | 33/42 [25:11<06:52, 45.86s/it][A[A

Evaluating:  81%|  | 34/42 [25:57<06:06, 45.84s/it][A[A

Evaluating:  83%| | 35/42 [26:42<05:20, 45.82s/it][A[A

Evaluating:  86%| | 36/42 [27:28<04:34, 45.81s/it][A[A

Evaluating:  88%| | 37/42 [28:14<03:49, 45.82s/it][A[A

Evaluating:  90%| | 38/42 [29:00<03:03, 45.82s/it][A[A

Evaluating:  93%|| 39/42 [29:46<02:17, 45.81s/it][A[A

Evaluating:  95%|| 40/42 [30:31<01:31, 45.81s/it][A[A

Evaluating:  98%|| 41/42 [31:18<00:46, 46.13s/it][A[A

Evaluating: 100%|| 42/42 [31:19<00:00, 32.66s/it][A[AEvaluating: 100%|| 42/42 [31:19<00:00, 44.76s/it]
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
03/13/2022 19:19:11 - INFO - __main__ -   ***** Eval results  *****
03/13/2022 19:19:11 - INFO - __main__ -     acc = 0.0007616146230007616
03/13/2022 19:19:11 - INFO - __main__ -     auc = 0.4794131852209611
03/13/2022 19:19:11 - INFO - __main__ -     f1 = 1.159230780823077e-06
03/13/2022 19:19:11 - INFO - __main__ -     mcc = 0.0
03/13/2022 19:19:11 - INFO - __main__ -     precision = 5.800568339685923e-07
03/13/2022 19:19:11 - INFO - __main__ -     recall = 0.0007616146230007616
03/13/2022 19:19:11 - INFO - __main__ -     top10acc = 0.007616146230007616
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
03/13/2022 19:19:11 - INFO - transformers.configuration_utils -   Configuration saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-180/config.json
03/13/2022 19:19:12 - INFO - transformers.modeling_utils -   Model weights saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-180/pytorch_model.bin
03/13/2022 19:19:12 - INFO - __main__ -   Saving model checkpoint to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-180
03/13/2022 19:19:15 - INFO - __main__ -   Saving optimizer and scheduler states to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-180

Iteration:  82%| | 180/219 [14:05:37<9:38:13, 889.58s/it][A
Iteration:  83%| | 181/219 [14:07:49<6:59:35, 662.51s/it][A
Iteration:  83%| | 182/219 [14:10:05<5:11:04, 504.44s/it][A
Iteration:  84%| | 183/219 [14:12:21<3:56:18, 393.84s/it][A
Iteration:  84%| | 184/219 [14:14:36<3:04:26, 316.17s/it][A
Iteration:  84%| | 185/219 [14:16:51<2:28:23, 261.88s/it][A
Iteration:  85%| | 186/219 [14:19:05<2:02:57, 223.55s/it][A
Iteration:  85%| | 187/219 [14:21:19<1:44:53, 196.68s/it][A
Iteration:  86%| | 188/219 [14:23:34<1:32:05, 178.23s/it][A
Iteration:  86%| | 189/219 [14:25:49<1:22:38, 165.27s/it][A
Iteration:  87%| | 190/219 [14:28:03<1:15:23, 155.97s/it][A
Iteration:  87%| | 191/219 [14:30:19<1:09:56, 149.87s/it][A
Iteration:  88%| | 192/219 [14:32:33<1:05:18, 145.15s/it][A
Iteration:  88%| | 193/219 [14:34:48<1:01:33, 142.05s/it][A
Iteration:  89%| | 194/219 [14:37:02<58:12, 139.70s/it]  [A
Iteration:  89%| | 195/219 [14:39:16<55:12, 138.03s/it][A
Iteration:  89%| | 196/219 [14:41:32<52:35, 137.22s/it][A
Iteration:  90%| | 197/219 [14:43:46<49:58, 136.30s/it][A
Iteration:  90%| | 198/219 [14:46:00<47:28, 135.64s/it][A
Iteration:  91%| | 199/219 [14:48:15<45:08, 135.45s/it][A03/13/2022 20:04:08 - INFO - __main__ -   Loading features from cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_dev_6-new-12w-0_512_dnageaall
03/13/2022 20:04:08 - INFO - __main__ -   ***** Running evaluation  *****
03/13/2022 20:04:08 - INFO - __main__ -     Num examples = 1313
03/13/2022 20:04:08 - INFO - __main__ -     Batch size = 32


Evaluating:   0%|          | 0/42 [00:00<?, ?it/s][A[A

Evaluating:   2%|         | 1/42 [00:45<31:10, 45.63s/it][A[A

Evaluating:   5%|         | 2/42 [01:31<30:23, 45.59s/it][A[A

Evaluating:   7%|         | 3/42 [02:16<29:32, 45.44s/it][A[A

Evaluating:  10%|         | 4/42 [03:01<28:39, 45.25s/it][A[A

Evaluating:  12%|        | 5/42 [03:46<27:53, 45.23s/it][A[A

Evaluating:  14%|        | 6/42 [04:32<27:11, 45.32s/it][A[A

Evaluating:  17%|        | 7/42 [05:17<26:28, 45.40s/it][A[A

Evaluating:  19%|        | 8/42 [06:03<25:44, 45.43s/it][A[A

Evaluating:  21%|       | 9/42 [06:48<25:00, 45.47s/it][A[A

Evaluating:  24%|       | 10/42 [07:34<24:16, 45.51s/it][A[A

Evaluating:  26%|       | 11/42 [08:19<23:30, 45.51s/it][A[A

Evaluating:  29%|       | 12/42 [09:05<22:45, 45.51s/it][A[A

Evaluating:  31%|       | 13/42 [09:50<21:59, 45.49s/it][A[A

Evaluating:  33%|      | 14/42 [10:36<21:13, 45.50s/it][A[A

Evaluating:  36%|      | 15/42 [11:21<20:28, 45.51s/it][A[A

Evaluating:  38%|      | 16/42 [12:07<19:42, 45.48s/it][A[A

Evaluating:  40%|      | 17/42 [12:52<18:57, 45.49s/it][A[A

Evaluating:  43%|     | 18/42 [13:38<18:11, 45.50s/it][A[A

Evaluating:  45%|     | 19/42 [14:23<17:26, 45.50s/it][A[A

Evaluating:  48%|     | 20/42 [15:09<16:40, 45.49s/it][A[A

Evaluating:  50%|     | 21/42 [15:54<15:55, 45.50s/it][A[A

Evaluating:  52%|    | 22/42 [16:40<15:10, 45.50s/it][A[A

Evaluating:  55%|    | 23/42 [17:25<14:24, 45.50s/it][A[A

Evaluating:  57%|    | 24/42 [18:11<13:40, 45.57s/it][A[A

Evaluating:  60%|    | 25/42 [18:57<12:54, 45.56s/it][A[A

Evaluating:  62%|   | 26/42 [19:42<12:08, 45.50s/it][A[A

Evaluating:  64%|   | 27/42 [20:27<11:22, 45.51s/it][A[A

Evaluating:  67%|   | 28/42 [21:13<10:37, 45.53s/it][A[A

Evaluating:  69%|   | 29/42 [21:59<09:51, 45.54s/it][A[A

Evaluating:  71%|  | 30/42 [22:44<09:06, 45.53s/it][A[A

Evaluating:  74%|  | 31/42 [23:30<08:20, 45.53s/it][A[A

Evaluating:  76%|  | 32/42 [24:15<07:35, 45.51s/it][A[A

Evaluating:  79%|  | 33/42 [25:01<06:49, 45.51s/it][A[A

Evaluating:  81%|  | 34/42 [25:46<06:04, 45.53s/it][A[A

Evaluating:  83%| | 35/42 [26:32<05:18, 45.52s/it][A[A

Evaluating:  86%| | 36/42 [27:17<04:33, 45.54s/it][A[A

Evaluating:  88%| | 37/42 [28:03<03:47, 45.54s/it][A[A

Evaluating:  90%| | 38/42 [28:48<03:02, 45.53s/it][A[A

Evaluating:  93%|| 39/42 [29:34<02:16, 45.53s/it][A[A

Evaluating:  95%|| 40/42 [30:19<01:31, 45.52s/it][A[A

Evaluating:  98%|| 41/42 [31:05<00:45, 45.51s/it][A[A

Evaluating: 100%|| 42/42 [31:06<00:00, 32.21s/it][A[AEvaluating: 100%|| 42/42 [31:06<00:00, 44.44s/it]
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
03/13/2022 20:45:46 - INFO - __main__ -   ***** Eval results  *****
03/13/2022 20:45:46 - INFO - __main__ -     acc = 0.0007616146230007616
03/13/2022 20:45:46 - INFO - __main__ -     auc = 0.49567586331803914
03/13/2022 20:45:46 - INFO - __main__ -     f1 = 1.159230780823077e-06
03/13/2022 20:45:46 - INFO - __main__ -     mcc = 0.0
03/13/2022 20:45:46 - INFO - __main__ -     precision = 5.800568339685923e-07
03/13/2022 20:45:46 - INFO - __main__ -     recall = 0.0007616146230007616
03/13/2022 20:45:46 - INFO - __main__ -     top10acc = 0.007616146230007616
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
03/13/2022 20:45:46 - INFO - transformers.configuration_utils -   Configuration saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-200/config.json
03/13/2022 20:45:47 - INFO - transformers.modeling_utils -   Model weights saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-200/pytorch_model.bin
03/13/2022 20:45:47 - INFO - __main__ -   Saving model checkpoint to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-200
03/13/2022 20:45:49 - INFO - __main__ -   Saving optimizer and scheduler states to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-200

Iteration:  91%|| 200/219 [15:32:11<4:40:28, 885.69s/it][A
Iteration:  92%|| 201/219 [15:34:24<3:17:58, 659.90s/it][A
Iteration:  92%|| 202/219 [15:36:39<2:22:22, 502.49s/it][A
Iteration:  93%|| 203/219 [15:38:55<1:44:36, 392.29s/it][A
Iteration:  93%|| 204/219 [15:41:09<1:18:45, 315.06s/it][A
Iteration:  94%|| 205/219 [15:43:30<1:01:16, 262.62s/it][A
Iteration:  94%|| 206/219 [15:45:46<48:39, 224.58s/it]  [A
Iteration:  95%|| 207/219 [15:48:07<39:55, 199.59s/it][A
Iteration:  95%|| 208/219 [15:50:28<33:23, 182.13s/it][A
Iteration:  95%|| 209/219 [15:52:51<28:23, 170.33s/it][A
Iteration:  96%|| 210/219 [15:55:13<24:16, 161.81s/it][A
Iteration:  96%|| 211/219 [15:57:35<20:47, 155.97s/it][A
Iteration:  97%|| 212/219 [15:59:57<17:42, 151.76s/it][A
Iteration:  97%|| 213/219 [16:02:18<14:51, 148.55s/it][A
Iteration:  98%|| 214/219 [16:04:40<12:12, 146.44s/it][A
Iteration:  98%|| 215/219 [16:07:02<09:40, 145.21s/it][A
Iteration:  99%|| 216/219 [16:09:24<07:12, 144.33s/it][A
Iteration:  99%|| 217/219 [16:11:47<04:47, 143.81s/it][A
Iteration: 100%|| 218/219 [16:14:10<02:23, 143.51s/it][A
Iteration: 100%|| 219/219 [16:16:32<00:00, 143.26s/it][AIteration: 100%|| 219/219 [16:16:32<00:00, 267.55s/it]
Epoch:  20%|        | 1/5 [16:16:33<65:06:12, 58593.00s/it]
Iteration:   0%|          | 0/219 [00:00<?, ?it/s][A03/13/2022 21:32:32 - INFO - __main__ -   Loading features from cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_dev_6-new-12w-0_512_dnageaall
03/13/2022 21:32:32 - INFO - __main__ -   ***** Running evaluation  *****
03/13/2022 21:32:32 - INFO - __main__ -     Num examples = 1313
03/13/2022 21:32:32 - INFO - __main__ -     Batch size = 32


Evaluating:   0%|          | 0/42 [00:00<?, ?it/s][A[A

Evaluating:   2%|         | 1/42 [00:47<32:47, 47.98s/it][A[A

Evaluating:   5%|         | 2/42 [01:35<31:58, 47.97s/it][A[A

Evaluating:   7%|         | 3/42 [02:23<31:09, 47.93s/it][A[A

Evaluating:  10%|         | 4/42 [03:11<30:20, 47.90s/it][A[A

Evaluating:  12%|        | 5/42 [03:59<29:31, 47.88s/it][A[A

Evaluating:  14%|        | 6/42 [04:47<28:41, 47.82s/it][A[A

Evaluating:  17%|        | 7/42 [05:34<27:42, 47.49s/it][A[A

Evaluating:  19%|        | 8/42 [06:21<26:58, 47.61s/it][A[A

Evaluating:  21%|       | 9/42 [07:09<26:13, 47.69s/it][A[A

Evaluating:  24%|       | 10/42 [07:57<25:27, 47.74s/it][A[A

Evaluating:  26%|       | 11/42 [08:45<24:40, 47.77s/it][A[A

Evaluating:  29%|       | 12/42 [09:33<23:53, 47.78s/it][A[A

Evaluating:  31%|       | 13/42 [10:21<23:07, 47.83s/it][A[A

Evaluating:  33%|      | 14/42 [11:09<22:19, 47.85s/it][A[A

Evaluating:  36%|      | 15/42 [11:56<21:31, 47.84s/it][A[A

Evaluating:  38%|      | 16/42 [12:44<20:43, 47.84s/it][A[A

Evaluating:  40%|      | 17/42 [13:32<19:56, 47.84s/it][A[A

Evaluating:  43%|     | 18/42 [14:20<19:08, 47.86s/it][A[A

Evaluating:  45%|     | 19/42 [15:08<18:20, 47.85s/it][A[A

Evaluating:  48%|     | 20/42 [15:56<17:33, 47.87s/it][A[A

Evaluating:  50%|     | 21/42 [16:44<16:44, 47.85s/it][A[A

Evaluating:  52%|    | 22/42 [17:31<15:56, 47.84s/it][A[A

Evaluating:  55%|    | 23/42 [18:19<15:07, 47.74s/it][A[A

Evaluating:  57%|    | 24/42 [19:07<14:19, 47.78s/it][A[A

Evaluating:  60%|    | 25/42 [19:55<13:32, 47.82s/it][A[A

Evaluating:  62%|   | 26/42 [20:43<12:45, 47.84s/it][A[A

Evaluating:  64%|   | 27/42 [21:30<11:57, 47.86s/it][A[A

Evaluating:  67%|   | 28/42 [22:18<11:09, 47.84s/it][A[A

Evaluating:  69%|   | 29/42 [23:06<10:21, 47.83s/it][A[A

Evaluating:  71%|  | 30/42 [23:54<09:34, 47.84s/it][A[A

Evaluating:  74%|  | 31/42 [24:42<08:46, 47.83s/it][A[A

Evaluating:  76%|  | 32/42 [25:30<07:58, 47.84s/it][A[A

Evaluating:  79%|  | 33/42 [26:18<07:10, 47.86s/it][A[A

Evaluating:  81%|  | 34/42 [27:05<06:22, 47.86s/it][A[A

Evaluating:  83%| | 35/42 [27:53<05:34, 47.82s/it][A[A

Evaluating:  86%| | 36/42 [28:40<04:46, 47.67s/it][A[A

Evaluating:  88%| | 37/42 [29:28<03:57, 47.57s/it][A[A

Evaluating:  90%| | 38/42 [30:16<03:10, 47.65s/it][A[A

Evaluating:  93%|| 39/42 [31:03<02:23, 47.71s/it][A[A

Evaluating:  95%|| 40/42 [31:51<01:35, 47.76s/it][A[A

Evaluating:  98%|| 41/42 [32:39<00:47, 47.80s/it][A[A

Evaluating: 100%|| 42/42 [32:41<00:00, 33.85s/it][A[AEvaluating: 100%|| 42/42 [32:41<00:00, 46.69s/it]
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
03/13/2022 22:15:45 - INFO - __main__ -   ***** Eval results  *****
03/13/2022 22:15:45 - INFO - __main__ -     acc = 0.0007616146230007616
03/13/2022 22:15:45 - INFO - __main__ -     auc = 0.5037947216391433
03/13/2022 22:15:45 - INFO - __main__ -     f1 = 1.159230780823077e-06
03/13/2022 22:15:45 - INFO - __main__ -     mcc = 0.0
03/13/2022 22:15:45 - INFO - __main__ -     precision = 5.800568339685923e-07
03/13/2022 22:15:45 - INFO - __main__ -     recall = 0.0007616146230007616
03/13/2022 22:15:45 - INFO - __main__ -     top10acc = 0.007616146230007616
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
03/13/2022 22:15:45 - INFO - transformers.configuration_utils -   Configuration saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-220/config.json
03/13/2022 22:15:46 - INFO - transformers.modeling_utils -   Model weights saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-220/pytorch_model.bin
03/13/2022 22:15:46 - INFO - __main__ -   Saving model checkpoint to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-220
03/13/2022 22:15:48 - INFO - __main__ -   Saving optimizer and scheduler states to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-220

Iteration:   0%|          | 1/219 [45:37<165:45:51, 2737.39s/it][A
Iteration:   1%|          | 2/219 [47:56<72:52:36, 1209.02s/it] [A
Iteration:   1%|         | 3/219 [50:17<43:16:43, 721.31s/it] [A
Iteration:   2%|         | 4/219 [52:39<29:25:04, 492.58s/it][A
Iteration:   2%|         | 5/219 [55:01<21:45:52, 366.13s/it][A
Iteration:   3%|         | 6/219 [57:22<17:08:23, 289.69s/it][A
Iteration:   3%|         | 7/219 [59:45<14:13:36, 241.59s/it][A
Iteration:   4%|         | 8/219 [1:02:07<12:18:08, 209.90s/it][A
Iteration:   4%|         | 9/219 [1:04:28<10:59:15, 188.36s/it][A
Iteration:   5%|         | 10/219 [1:06:49<10:05:18, 173.77s/it][A
Iteration:   5%|         | 11/219 [1:09:11<9:29:16, 164.21s/it] [A
Iteration:   5%|         | 12/219 [1:11:33<9:02:45, 157.32s/it][A
Iteration:   6%|         | 13/219 [1:13:56<8:44:55, 152.89s/it][A
Iteration:   6%|         | 14/219 [1:16:17<8:30:37, 149.45s/it][A
Iteration:   7%|         | 15/219 [1:18:39<8:19:50, 147.01s/it][A
Iteration:   7%|         | 16/219 [1:21:00<8:11:31, 145.28s/it][A
Iteration:   8%|         | 17/219 [1:23:21<8:05:01, 144.07s/it][A
Iteration:   8%|         | 18/219 [1:25:42<7:59:54, 143.26s/it][A
Iteration:   9%|         | 19/219 [1:28:03<7:55:11, 142.56s/it][A
Iteration:   9%|         | 20/219 [1:30:25<7:51:42, 142.23s/it][A03/13/2022 23:02:57 - INFO - __main__ -   Loading features from cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_dev_6-new-12w-0_512_dnageaall
03/13/2022 23:02:58 - INFO - __main__ -   ***** Running evaluation  *****
03/13/2022 23:02:58 - INFO - __main__ -     Num examples = 1313
03/13/2022 23:02:58 - INFO - __main__ -     Batch size = 32


Evaluating:   0%|          | 0/42 [00:00<?, ?it/s][A[A

Evaluating:   2%|         | 1/42 [00:47<32:47, 47.99s/it][A[A

Evaluating:   5%|         | 2/42 [01:35<31:55, 47.89s/it][A[A

Evaluating:   7%|         | 3/42 [02:23<31:06, 47.86s/it][A[A

Evaluating:  10%|         | 4/42 [03:11<30:17, 47.84s/it][A[A

Evaluating:  12%|        | 5/42 [03:59<29:29, 47.82s/it][A[A

Evaluating:  14%|        | 6/42 [04:47<28:41, 47.83s/it][A[A

Evaluating:  17%|        | 7/42 [05:34<27:53, 47.80s/it][A[A

Evaluating:  19%|        | 8/42 [06:22<27:04, 47.79s/it][A[A

Evaluating:  21%|       | 9/42 [07:10<26:17, 47.79s/it][A[A

Evaluating:  24%|       | 10/42 [07:58<25:29, 47.78s/it][A[A

Evaluating:  26%|       | 11/42 [08:45<24:40, 47.77s/it][A[A

Evaluating:  29%|       | 12/42 [09:33<23:53, 47.77s/it][A[A

Evaluating:  31%|       | 13/42 [10:21<23:05, 47.79s/it][A[A

Evaluating:  33%|      | 14/42 [11:09<22:17, 47.79s/it][A[A

Evaluating:  36%|      | 15/42 [11:57<21:30, 47.78s/it][A[A

Evaluating:  38%|      | 16/42 [12:44<20:42, 47.77s/it][A[A

Evaluating:  40%|      | 17/42 [13:32<19:54, 47.77s/it][A[A

Evaluating:  43%|     | 18/42 [14:20<19:06, 47.78s/it][A[A

Evaluating:  45%|     | 19/42 [15:08<18:18, 47.78s/it][A[A

Evaluating:  48%|     | 20/42 [15:55<17:31, 47.78s/it][A[A

Evaluating:  50%|     | 21/42 [16:43<16:43, 47.80s/it][A[A

Evaluating:  52%|    | 22/42 [17:31<15:56, 47.81s/it][A[A

Evaluating:  55%|    | 23/42 [18:19<15:07, 47.79s/it][A[A

Evaluating:  57%|    | 24/42 [19:07<14:20, 47.79s/it][A[A

Evaluating:  60%|    | 25/42 [19:54<13:32, 47.78s/it][A[A

Evaluating:  62%|   | 26/42 [20:42<12:44, 47.79s/it][A[A

Evaluating:  64%|   | 27/42 [21:30<11:57, 47.80s/it][A[A

Evaluating:  67%|   | 28/42 [22:18<11:09, 47.79s/it][A[A

Evaluating:  69%|   | 29/42 [23:06<10:21, 47.81s/it][A[A

Evaluating:  71%|  | 30/42 [23:53<09:33, 47.79s/it][A[A

Evaluating:  74%|  | 31/42 [24:41<08:45, 47.81s/it][A[A

Evaluating:  76%|  | 32/42 [25:29<07:58, 47.81s/it][A[A

Evaluating:  79%|  | 33/42 [26:17<07:10, 47.79s/it][A[A

Evaluating:  81%|  | 34/42 [27:05<06:22, 47.79s/it][A[A

Evaluating:  83%| | 35/42 [27:52<05:34, 47.79s/it][A[A

Evaluating:  86%| | 36/42 [28:40<04:46, 47.79s/it][A[A

Evaluating:  88%| | 37/42 [29:28<03:58, 47.79s/it][A[A

Evaluating:  90%| | 38/42 [30:16<03:11, 47.79s/it][A[A

Evaluating:  93%|| 39/42 [31:04<02:23, 47.79s/it][A[A

Evaluating:  95%|| 40/42 [31:51<01:35, 47.80s/it][A[A

Evaluating:  98%|| 41/42 [32:39<00:47, 47.80s/it][A[A

Evaluating: 100%|| 42/42 [32:40<00:00, 33.84s/it][A[AEvaluating: 100%|| 42/42 [32:40<00:00, 46.69s/it]
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
03/13/2022 23:46:08 - INFO - __main__ -   ***** Eval results  *****
03/13/2022 23:46:08 - INFO - __main__ -     acc = 0.0007616146230007616
03/13/2022 23:46:08 - INFO - __main__ -     auc = 0.5148285554399717
03/13/2022 23:46:08 - INFO - __main__ -     f1 = 1.159230780823077e-06
03/13/2022 23:46:08 - INFO - __main__ -     mcc = 0.0
03/13/2022 23:46:08 - INFO - __main__ -     precision = 5.800568339685923e-07
03/13/2022 23:46:08 - INFO - __main__ -     recall = 0.0007616146230007616
03/13/2022 23:46:08 - INFO - __main__ -     top10acc = 0.007616146230007616
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
03/13/2022 23:46:08 - INFO - transformers.configuration_utils -   Configuration saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-240/config.json
03/13/2022 23:46:09 - INFO - transformers.modeling_utils -   Model weights saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-240/pytorch_model.bin
03/13/2022 23:46:09 - INFO - __main__ -   Saving model checkpoint to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-240
03/13/2022 23:46:11 - INFO - __main__ -   Saving optimizer and scheduler states to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-240

Iteration:  10%|         | 21/219 [2:16:00<50:38:01, 920.62s/it][A
Iteration:  10%|         | 22/219 [2:18:20<37:33:16, 686.28s/it][A
Iteration:  11%|         | 23/219 [2:20:40<28:26:49, 522.50s/it][A
Iteration:  11%|         | 24/219 [2:23:03<22:07:41, 408.52s/it][A
Iteration:  11%|        | 25/219 [2:25:25<17:42:22, 328.57s/it][A
Iteration:  12%|        | 26/219 [2:27:48<14:37:38, 272.84s/it][A
Iteration:  12%|        | 27/219 [2:30:10<12:27:20, 233.54s/it][A
Iteration:  13%|        | 28/219 [2:32:32<10:56:24, 206.20s/it][A
Iteration:  13%|        | 29/219 [2:34:55<9:52:21, 187.06s/it] [A
Iteration:  14%|        | 30/219 [2:37:17<9:06:59, 173.65s/it][A
Iteration:  14%|        | 31/219 [2:39:39<8:34:15, 164.13s/it][A
Iteration:  15%|        | 32/219 [2:42:01<8:11:21, 157.66s/it][A
Iteration:  15%|        | 33/219 [2:44:23<7:54:03, 152.92s/it][A
Iteration:  16%|        | 34/219 [2:46:46<7:41:50, 149.79s/it][A
Iteration:  16%|        | 35/219 [2:49:08<7:32:44, 147.63s/it][A
Iteration:  16%|        | 36/219 [2:51:30<7:24:28, 145.73s/it][A
Iteration:  17%|        | 37/219 [2:53:51<7:18:01, 144.40s/it][A
Iteration:  17%|        | 38/219 [2:56:13<7:13:31, 143.71s/it][A
Iteration:  18%|        | 39/219 [2:58:35<7:09:05, 143.03s/it][A
Iteration:  18%|        | 40/219 [3:00:57<7:05:52, 142.75s/it][A03/14/2022 00:33:29 - INFO - __main__ -   Loading features from cached file /home/mexposit/cg/gea/transformers/7_gea500/in_data/cached_dev_6-new-12w-0_512_dnageaall
03/14/2022 00:33:30 - INFO - __main__ -   ***** Running evaluation  *****
03/14/2022 00:33:30 - INFO - __main__ -     Num examples = 1313
03/14/2022 00:33:30 - INFO - __main__ -     Batch size = 32


Evaluating:   0%|          | 0/42 [00:00<?, ?it/s][A[A

Evaluating:   2%|         | 1/42 [00:47<32:42, 47.87s/it][A[A

Evaluating:   5%|         | 2/42 [01:35<31:53, 47.85s/it][A[A

Evaluating:   7%|         | 3/42 [02:23<31:05, 47.82s/it][A[A

Evaluating:  10%|         | 4/42 [03:11<30:17, 47.83s/it][A[A

Evaluating:  12%|        | 5/42 [03:59<29:29, 47.83s/it][A[A

Evaluating:  14%|        | 6/42 [04:46<28:40, 47.80s/it][A[A

Evaluating:  17%|        | 7/42 [05:34<27:52, 47.80s/it][A[A

Evaluating:  19%|        | 8/42 [06:22<27:04, 47.78s/it][A[A

Evaluating:  21%|       | 9/42 [07:10<26:16, 47.77s/it][A[A

Evaluating:  24%|       | 10/42 [07:58<25:29, 47.80s/it][A[A

Evaluating:  26%|       | 11/42 [08:45<24:42, 47.81s/it][A[A

Evaluating:  29%|       | 12/42 [09:33<23:53, 47.80s/it][A[A

Evaluating:  31%|       | 13/42 [10:21<23:05, 47.79s/it][A[A

Evaluating:  33%|      | 14/42 [11:09<22:18, 47.81s/it][A[A

Evaluating:  36%|      | 15/42 [11:57<21:30, 47.80s/it][A[A

Evaluating:  38%|      | 16/42 [12:44<20:42, 47.80s/it][A[A

Evaluating:  40%|      | 17/42 [13:32<19:55, 47.80s/it][A[A

Evaluating:  43%|     | 18/42 [14:20<19:07, 47.80s/it][A[A

Evaluating:  45%|     | 19/42 [15:08<18:19, 47.81s/it][A[A

Evaluating:  48%|     | 20/42 [15:56<17:31, 47.80s/it][A[A

Evaluating:  50%|     | 21/42 [16:43<16:43, 47.78s/it][A[A

Evaluating:  52%|    | 22/42 [17:31<15:55, 47.79s/it][A[A

Evaluating:  55%|    | 23/42 [18:19<15:07, 47.79s/it][A[A

Evaluating:  57%|    | 24/42 [19:07<14:20, 47.79s/it][A[A

Evaluating:  60%|    | 25/42 [19:54<13:32, 47.79s/it][A[A

Evaluating:  62%|   | 26/42 [20:42<12:44, 47.78s/it][A[A

Evaluating:  64%|   | 27/42 [21:30<11:56, 47.79s/it][A[A

Evaluating:  67%|   | 28/42 [22:18<11:08, 47.78s/it][A[A

Evaluating:  69%|   | 29/42 [23:06<10:21, 47.78s/it][A[A

Evaluating:  71%|  | 30/42 [23:53<09:33, 47.78s/it][A[A

Evaluating:  74%|  | 31/42 [24:41<08:45, 47.80s/it][A[A

Evaluating:  76%|  | 32/42 [25:29<07:57, 47.78s/it][A[A

Evaluating:  79%|  | 33/42 [26:17<07:10, 47.78s/it][A[A

Evaluating:  81%|  | 34/42 [27:05<06:22, 47.78s/it][A[A

Evaluating:  83%| | 35/42 [27:52<05:34, 47.77s/it][A[A

Evaluating:  86%| | 36/42 [28:40<04:46, 47.79s/it][A[A

Evaluating:  88%| | 37/42 [29:28<03:58, 47.78s/it][A[A

Evaluating:  90%| | 38/42 [30:16<03:11, 47.81s/it][A[A

Evaluating:  93%|| 39/42 [31:03<02:23, 47.79s/it][A[A

Evaluating:  95%|| 40/42 [31:51<01:35, 47.79s/it][A[A

Evaluating:  98%|| 41/42 [32:39<00:47, 47.79s/it][A[A

Evaluating: 100%|| 42/42 [32:40<00:00, 33.84s/it][A[AEvaluating: 100%|| 42/42 [32:40<00:00, 46.69s/it]
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
03/14/2022 01:16:49 - INFO - __main__ -   ***** Eval results  *****
03/14/2022 01:16:49 - INFO - __main__ -     acc = 0.0007616146230007616
03/14/2022 01:16:49 - INFO - __main__ -     auc = 0.5091785591551651
03/14/2022 01:16:49 - INFO - __main__ -     f1 = 1.159230780823077e-06
03/14/2022 01:16:49 - INFO - __main__ -     mcc = 0.0
03/14/2022 01:16:49 - INFO - __main__ -     precision = 5.800568339685923e-07
03/14/2022 01:16:49 - INFO - __main__ -     recall = 0.0007616146230007616
03/14/2022 01:16:49 - INFO - __main__ -     top10acc = 0.007616146230007616
/home/mexposit/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
03/14/2022 01:16:49 - INFO - transformers.configuration_utils -   Configuration saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-260/config.json
03/14/2022 01:16:49 - INFO - transformers.modeling_utils -   Model weights saved in /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-260/pytorch_model.bin
03/14/2022 01:16:49 - INFO - __main__ -   Saving model checkpoint to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-260
03/14/2022 01:16:51 - INFO - __main__ -   Saving optimizer and scheduler states to /home/mexposit/cg/gea/transformers/7_gea500/model/ft_7_gea500/checkpoint-260

Iteration:  19%|        | 41/219 [3:46:40<45:38:07, 922.96s/it][A
Iteration:  19%|        | 42/219 [3:49:00<33:49:44, 688.05s/it][A
Iteration:  20%|        | 43/219 [3:51:21<25:36:28, 523.80s/it][A
Iteration:  20%|        | 44/219 [3:53:41<19:52:18, 408.79s/it][A
Iteration:  21%|        | 45/219 [3:56:03<15:53:23, 328.76s/it][A
Iteration:  21%|        | 46/219 [3:58:24<13:05:43, 272.51s/it][A
Iteration:  21%|       | 47/219 [4:00:47<11:09:23, 233.51s/it][A
Iteration:  22%|       | 48/219 [4:03:08<9:46:57, 205.95s/it] [Aslurmstepd: error: *** JOB 23901176 ON gpu13 CANCELLED AT 2022-03-14T01:33:31 ***
